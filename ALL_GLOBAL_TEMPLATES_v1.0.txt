# VoiceBM v1.0 Global Templates - Complete Reference
# Generated: December 17, 2025
# Total Files: 32

This document contains all global templates used by VoiceBM v1.0 for the main processing system.
Each template uses placeholders that are replaced during deployment:
  {VOICEBM_BASE} - Installation directory
  {CONDA_PATH} - Path to Miniforge/conda
  {SHERPA_BIN} - Path to sherpa_embed.py executable
  {SHERPA_MODEL} - Path to Sherpa-ONNX model (nemo_en_titanet_small.onnx)
  {MQTT_BROKER} - MQTT broker IP
  {MQTT_PORT} - MQTT port
  {MQTT_USER} - MQTT username
  {MQTT_PASS} - MQTT password
  {AUDIO_HOST} - Audio server host
  {AUDIO_PORT} - Audio server port

## Changes in v1.0:
- Migrated from WeSpeaker to Sherpa-ONNX (60-162x faster)
- Added Thing Engine (identity management)
- Added VoiceBM Dashboard (Flask web UI)
- Added Global Publisher (unified Home Assistant device)
- Added voicebm_config.py (centralized configuration)
- All services now use centralized MQTT config
- Path-agnostic deployment

================================================================================


################################################################################
# FILE: approve.sh.template
# TYPE: script
################################################################################

#!/usr/bin/env bash
REF_BASENAME="$1"   # e.g. living_20250926_144705.txt
SID="$2"            # e.g. david
NAME="$3"           # e.g. David
echo -e "${REF_BASENAME}\t${SID}\t${NAME}" >> {VOICEBM_BASE}/map/living_gallery.map




################################################################################
# FILE: audio_server.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
Simple HTTP server for voice recording playback
Serves both /recordings/ and /pending/ paths
"""

import http.server
import socketserver
import os
import json
from pathlib import Path
from urllib.parse import unquote

# Load configuration
CONFIG_FILE = "{VOICEBM_BASE}/config.json"
try:
    with open(CONFIG_FILE, 'r') as f:
        config = json.load(f)
        PORT = config['audio_server']['port']
except:
    PORT = 9090  # Fallback

BASE_DIR = "{VOICEBM_BASE}"


class VoiceBMHTTPRequestHandler(http.server.SimpleHTTPRequestHandler):
    """Custom handler that routes to different directories based on path"""
    
    def __init__(self, *args, **kwargs):
        # Don't set directory in parent - we handle routing manually
        super().__init__(*args, **kwargs)
    
    def translate_path(self, path):
        """Translate URL path to filesystem path"""
        # Decode URL encoding
        path = unquote(path)
        
        # Remove leading slash
        path = path.lstrip('/')
        
        # Route based on first path component
        if path.startswith('pending/'):
            # Serve from pending_active/recordings
            relative = path[8:]  # Remove 'pending/'
            return os.path.join(BASE_DIR, 'pending_active', 'recordings', relative)
        
        elif path.startswith('living/'):
            # Serve from recordings/living
            relative = path[7:]  # Remove 'living/'
            return os.path.join(BASE_DIR, 'recordings', 'living', relative)
        
        elif path.startswith('recordings/'):
            # Direct recordings path
            relative = path[11:]  # Remove 'recordings/'
            return os.path.join(BASE_DIR, 'recordings', relative)
        
        else:
            # Default to recordings directory
            return os.path.join(BASE_DIR, 'recordings', path)
    
    def end_headers(self):
        # Add CORS headers so Home Assistant can access
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', '*')
        super().end_headers()
    
    def do_OPTIONS(self):
        """Handle CORS preflight requests"""
        self.send_response(200)
        self.end_headers()
    
    def log_message(self, format, *args):
        """Custom logging"""
        print(f"[{self.log_date_time_string()}] {args[0]}")


def main():
    # Ensure directories exist
    Path(f"{BASE_DIR}/recordings/living").mkdir(parents=True, exist_ok=True)
    Path(f"{BASE_DIR}/pending_active/recordings").mkdir(parents=True, exist_ok=True)
    
    with socketserver.TCPServer(("", PORT), VoiceBMHTTPRequestHandler) as httpd:
        print(f"=" * 60)
        print(f"VoiceBM Audio Server")
        print(f"=" * 60)
        print(f"Listening on port {PORT}")
        print(f"")
        print(f"URL Paths:")
        print(f"  /living/          -> {BASE_DIR}/recordings/living/")
        print(f"  /recordings/      -> {BASE_DIR}/recordings/")
        print(f"  /pending/         -> {BASE_DIR}/pending_active/recordings/")
        print(f"")
        print(f"Example URLs:")
        print(f"  http://10.50.60.58:{PORT}/living/living_20251128_120000.wav")
        print(f"  http://10.50.60.58:{PORT}/pending/active_1732825200000.wav")
        print(f"=" * 60)
        print(f"Press Ctrl+C to stop")
        
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\nShutting down server...")


if __name__ == "__main__":
    main()



################################################################################
# FILE: cleanup_recordings.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
VoiceBM Recording Cleanup - Delete expired WAV files after 3-day retention period

PURPOSE:
- WAV files take up space, keep them for 3 days for manual review
- After 3 days, delete the WAV but keep the embedding
- Embeddings stay forever (small files, needed for recognition)

BEHAVIOR:
- Scans all person folders in /enroll/
- Reads metadata.json for each person
- Checks expire_at timestamp for each sample
- Deletes WAV if past expiration
- Updates metadata to mark recording as deleted
- Keeps embedding file

RUN AS:
- Systemd timer (daily)
- Or cron job: 0 2 * * * {VOICEBM_BASE}/bin/cleanup_recordings.py
"""

import os
import json
import datetime
from pathlib import Path

ENROLL_DIR = "{VOICEBM_BASE}/enroll"


def cleanup_expired_recordings():
    """
    Delete WAV files past their 3-day retention period.
    Keep embeddings forever.
    """
    enroll_path = Path(ENROLL_DIR)
    
    if not enroll_path.exists():
        print(f"Enrollment directory not found: {ENROLL_DIR}")
        return
    
    total_deleted = 0
    total_kept = 0
    
    print(f"Starting cleanup scan: {datetime.datetime.now().isoformat()}")
    print(f"Scanning: {ENROLL_DIR}\n")
    
    # Scan each person folder
    for person_dir in enroll_path.iterdir():
        if not person_dir.is_dir():
            continue
        
        person_id = person_dir.name
        metadata_file = person_dir / 'metadata.json'
        
        if not metadata_file.exists():
            print(f"âš  No metadata for {person_id}, skipping")
            continue
        
        # Load metadata
        try:
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
        except Exception as e:
            print(f"âœ— Failed to load metadata for {person_id}: {e}")
            continue
        
        samples = metadata.get('samples', [])
        if not samples:
            continue
        
        print(f"Checking {person_id} ({len(samples)} samples)...")
        
        updated_samples = []
        person_deleted = 0
        person_kept = 0
        
        now_utc = datetime.datetime.now(datetime.timezone.utc)
        
        for sample in samples:
            expire_at = sample.get('expire_at')
            recording_path = sample.get('recording')
            
            # If already marked as deleted, keep as-is
            if recording_path is None:
                updated_samples.append(sample)
                continue
            
            # If no expiration, keep forever
            if not expire_at:
                updated_samples.append(sample)
                person_kept += 1
                continue
            
            # Parse expiration timestamp
            try:
                # Handle ISO format with 'Z' suffix
                expire_dt = datetime.datetime.fromisoformat(expire_at.replace('Z', '+00:00'))
            except Exception as e:
                print(f"  âš  Invalid expire_at for {sample['event_id']}: {e}")
                updated_samples.append(sample)
                person_kept += 1
                continue
            
            # Check if expired
            if now_utc > expire_dt:
                # Delete WAV file
                wav_file = person_dir / recording_path
                
                if wav_file.exists():
                    try:
                        wav_file.unlink()
                        print(f"  âœ“ Deleted: {wav_file.name}")
                        person_deleted += 1
                    except Exception as e:
                        print(f"  âœ— Failed to delete {wav_file.name}: {e}")
                        updated_samples.append(sample)
                        person_kept += 1
                        continue
                else:
                    print(f"  âš  Already gone: {wav_file.name}")
                    person_deleted += 1
                
                # Update sample to mark recording as deleted
                sample['recording'] = None
                sample['recording_deleted_at'] = now_utc.isoformat()
                updated_samples.append(sample)
            else:
                # Not expired yet, keep it
                time_left = expire_dt - now_utc
                days_left = time_left.days
                # Don't print for every file, just count
                updated_samples.append(sample)
                person_kept += 1
        
        if person_deleted > 0:
            print(f"  Deleted {person_deleted} recording(s), kept {person_kept}")
        
        # Save updated metadata
        metadata['samples'] = updated_samples
        metadata['last_cleanup'] = now_utc.isoformat()
        
        try:
            with open(metadata_file, 'w') as f:
                json.dump(metadata, f, indent=2)
        except Exception as e:
            print(f"  âœ— Failed to save metadata: {e}")
        
        total_deleted += person_deleted
        total_kept += person_kept
    
    print(f"\nCleanup complete:")
    print(f"  Deleted: {total_deleted} recording(s)")
    print(f"  Kept: {total_kept} recording(s)")
    print(f"  Time: {datetime.datetime.now().isoformat()}")


if __name__ == "__main__":
    cleanup_expired_recordings()



################################################################################
# FILE: cluster_publisher.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
Cluster Publisher - Publishes voice cluster data to MQTT for Home Assistant automations.

MQTT DISCOVERY PATTERN:
Follows the EXACT same pattern as enrollment_watcher.py person device creation.
- Publishes discovery configs with retain=True
- HA auto-creates sensors
- State updates published to state topics

Workflow:
1. Clustering service groups similar unprocessed voices
2. This publisher sends cluster metadata to HA via MQTT
3. HA automations make enrollment decisions
4. When enrollment happens, enrollment_watcher.py handles device creation
"""

import os
import sys
import json
import time
import datetime
import paho.mqtt.client as mqtt
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Import clustering logic
try:
    import voice_clustering
except ImportError:
    print("Error: voice_clustering.py not found in same directory")
    sys.exit(1)

# MQTT Configuration
# MQTT Configuration (centralized)
import sys
sys.path.insert(0, '{VOICEBM_BASE}')
from voicebm_config import get_mqtt_config

mqtt_config = get_mqtt_config()
BROKER = mqtt_config['broker']
PORT = mqtt_config['port']
USER = mqtt_config['user']
PASS = mqtt_config['password']

# Topics
ROOM = "living"
CLUSTERS_TOPIC = f"voicebm/{ROOM}/clusters"
CLUSTER_DETAIL_TOPIC = f"voicebm/{ROOM}/cluster"
ENROLL_COMMAND_TOPIC = f"voicebm/{ROOM}/enroll_cluster"
REJECT_COMMAND_TOPIC = f"voicebm/{ROOM}/reject_cluster"

# State
last_cluster_count = 0
mqtt_client = None


def publish_discovery(client):
    """
    Publish Home Assistant MQTT Discovery configs for clustering sensors.
    
    PATTERN: Matches enrollment_watcher.py person device creation EXACTLY.
    - Discovery configs published with retain=True
    - State updates published separately to state topics
    """
    discovery_prefix = "homeassistant"
    
    # Device info (matches Voice Biometrics Living Room device)
    device = {
        "identifiers": ["voicebm_living"],
        "name": "Voice Biometrics Living Room",
        "manufacturer": "David M. Dryver Sr.",
        "model": "VoiceBM Voice ID System"
    }
    
    # Sensor: Pending cluster count
    cluster_count_config = {
        "name": "Living Room Pending Clusters",
        "unique_id": "voicebm_living_pending_clusters",
        "state_topic": CLUSTERS_TOPIC,
        "value_template": "{{ value_json.count }}",
        "json_attributes_topic": CLUSTERS_TOPIC,
        "icon": "mdi:account-multiple",
        "device": device
    }
    
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_living_pending_clusters/config",
        json.dumps(cluster_count_config),
        qos=1,
        retain=True
    )
    
    # Sensor: Total unprocessed samples
    samples_config = {
        "name": "Living Room Unprocessed Samples",
        "unique_id": "voicebm_living_unprocessed_samples",
        "state_topic": CLUSTERS_TOPIC,
        "value_template": "{{ value_json.total_samples }}",
        "icon": "mdi:voice",
        "device": device
    }
    
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_living_unprocessed_samples/config",
        json.dumps(samples_config),
        qos=1,
        retain=True
    )
    
    print("âœ“ Published MQTT Discovery configs for cluster sensors")


def publish_cluster_summary(client, clusters):
    """
    Publish summary of all pending clusters to state topic.
    
    This updates the STATE for sensors created by publish_discovery().
    """
    if not clusters:
        summary = {
            "count": 0,
            "total_samples": 0,
            "clusters": []
        }
    else:
        summary = {
            "count": len(clusters),
            "total_samples": sum(c['stats']['count'] for c in clusters),
            "clusters": [
                {
                    "cluster_id": c['cluster_id'],
                    "sample_count": c['stats']['count'],
                    "avg_similarity": round(c['stats']['avg_similarity'], 3),
                    "time_range": c['stats']['time_range']
                }
                for c in clusters
            ]
        }
    
    result = client.publish(
        CLUSTERS_TOPIC,
        json.dumps(summary),
        qos=1,
        retain=True
    )
    
    return result.rc == mqtt.MQTT_ERR_SUCCESS


def publish_cluster_details(client, cluster):
    """
    Publish detailed info for a specific cluster WITH AUDIO URLS.
    
    ENHANCEMENT: Removes 10-sample limit, adds audio URLs for Frigate-style review.
    """
    detail = {
        "cluster_id": cluster['cluster_id'],
        "sample_count": cluster['stats']['count'],
        "avg_similarity": round(cluster['stats']['avg_similarity'], 3),
        "time_range": cluster['stats']['time_range'],
        "samples": [
            {
                "id": s['id'],
                "timestamp": s['timestamp'],
                "wav_url": f"http://10.50.60.58:9090/living/{s['id']}.wav",
                "wav_filename": f"{s['id']}.wav"
            }
            for s in cluster['samples']  # ALL samples, no 10-sample limit
        ],
        # Playlist array for "play all" workflows
        "audio_urls": [
            f"http://10.50.60.58:9090/living/{s['id']}.wav"
            for s in cluster['samples']
        ]
    }
    
    topic = f"{CLUSTER_DETAIL_TOPIC}/{cluster['cluster_id']}"
    result = client.publish(
        topic,
        json.dumps(detail),
        qos=1,
        retain=True
    )
    
    return result.rc == mqtt.MQTT_ERR_SUCCESS


def handle_enroll_command(client, userdata, msg):
    """Handle enrollment command from HA automation"""
    try:
        data = json.loads(msg.payload.decode('utf-8'))
        cluster_id = data.get('cluster_id')
        person_id = data.get('person_id')
        display_name = data.get('display_name')
        
        if not person_id or not display_name:
            print(f"âœ— Invalid enroll command: missing person_id or display_name")
            return
        
        print(f"\nâ†’ Enrollment command received:")
        print(f"  Cluster: {cluster_id}")
        print(f"  Person: {display_name} ({person_id})")
        
        cluster = voice_clustering.get_cluster_by_id(cluster_id)
        if not cluster:
            print(f"âœ— Cluster {cluster_id} not found")
            return
        
        samples = cluster['samples']
        
        enroll_dir = Path(f"{VOICEBM_BASE}/enroll/{person_id}")
        embeddings_dir = enroll_dir / "embeddings"
        recordings_dir = enroll_dir / "recordings"
        
        enroll_dir.mkdir(parents=True, exist_ok=True)
        embeddings_dir.mkdir(exist_ok=True)
        recordings_dir.mkdir(exist_ok=True)
        
        metadata_file = enroll_dir / 'metadata.json'
        if metadata_file.exists():
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
                existing_samples = metadata.get('samples', [])
        else:
            metadata = {
                'person_id': person_id,
                'display_name': display_name,
                'created_at': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            existing_samples = []
        
        emb_src_dir = Path("{VOICEBM_BASE}/embeddings/living")
        rec_src_dir = Path("{VOICEBM_BASE}/recordings/living")
        
        import shutil
        enrolled_samples = []
        enrolled_ids = []
        
        ts_enroll = int(time.time())
        expire_at_iso = datetime.datetime.utcfromtimestamp(
            ts_enroll + 3*24*3600
        ).replace(microsecond=0).isoformat() + "Z"
        
        for sample in samples:
            event_id = sample['id']
            emb_src = emb_src_dir / f"{event_id}.txt"
            rec_src = rec_src_dir / f"{event_id}.wav"
            
            emb_dst = embeddings_dir / f"{event_id}.txt"
            rec_dst = recordings_dir / f"{event_id}.wav"
            
            if emb_src.exists() and not emb_dst.exists():
                try:
                    shutil.move(str(emb_src), str(emb_dst))
                    print(f"  âœ“ Moved embedding: {event_id}.txt")
                except Exception as e:
                    print(f"  âœ— Failed to move embedding: {e}")
                    continue
            elif emb_dst.exists():
                print(f"  âš  Embedding already exists: {event_id}.txt")
            else:
                print(f"  âœ— Embedding NOT FOUND at: {emb_src}")
                continue
            
            wav_moved = False
            if rec_src.exists():
                if not rec_dst.exists():
                    try:
                        shutil.move(str(rec_src), str(rec_dst))
                        print(f"  âœ“ Moved recording: {event_id}.wav")
                        wav_moved = True
                    except Exception as e:
                        print(f"  âœ— Failed to move recording: {e}")
                else:
                    print(f"  âš  Recording already exists: {event_id}.wav")
                    wav_moved = True
            else:
                print(f"  âœ— Recording NOT FOUND at: {rec_src}")
            
            sample_entry = {
                'event_id': event_id,
                'embedding': f"embeddings/{event_id}.txt",
                'recording': f"recordings/{event_id}.wav" if wav_moved else None,
                'enrolled_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                'expire_at': expire_at_iso,
                'retention_days': 3
            }
            enrolled_samples.append(sample_entry)
            enrolled_ids.append(event_id)
        
        metadata['samples'] = existing_samples + enrolled_samples
        metadata['last_updated'] = time.strftime('%Y-%m-%d %H:%M:%S')
        metadata['total_samples'] = len(metadata['samples'])
        
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        processed_file = Path("{VOICEBM_BASE}/meta/processed.txt")
        processed_file.parent.mkdir(exist_ok=True)
        with open(processed_file, 'a') as f:
            for eid in enrolled_ids:
                f.write(f"{eid}\n")
        
        cache_file = Path("{VOICEBM_BASE}/meta/clusters.json")
        cache_file.unlink(missing_ok=True)
        
        print(f"âœ“ Enrolled {len(enrolled_samples)} samples for {display_name}")
        print(f"  Total samples for {person_id}: {metadata['total_samples']}")
        
        response = {
            "success": True,
            "person_id": person_id,
            "enrolled_count": len(enrolled_samples),
            "total_samples": metadata['total_samples']
        }
        client.publish(
            f"{ENROLL_COMMAND_TOPIC}/response",
            json.dumps(response),
            qos=1
        )
        
    except Exception as e:
        print(f"âœ— Error handling enroll command: {e}")
        import traceback
        traceback.print_exc()
        response = {
            "success": False,
            "error": str(e)
        }
        client.publish(
            f"{ENROLL_COMMAND_TOPIC}/response",
            json.dumps(response),
            qos=1
        )


def handle_reject_command(client, userdata, msg):
    """Handle rejection command from HA automation"""
    try:
        data = json.loads(msg.payload.decode('utf-8'))
        cluster_id = data.get('cluster_id')
        
        print(f"\nâ†’ Rejection command received for cluster {cluster_id}")
        
        cluster = voice_clustering.get_cluster_by_id(cluster_id)
        if not cluster:
            print(f"âœ— Cluster {cluster_id} not found")
            return
        
        samples = cluster['samples']
        event_ids = [s['id'] for s in samples]
        
        processed_file = Path("{VOICEBM_BASE}/meta/processed.txt")
        processed_file.parent.mkdir(exist_ok=True)
        with open(processed_file, 'a') as f:
            for eid in event_ids:
                f.write(f"{eid}\n")
        
        cache_file = Path("{VOICEBM_BASE}/meta/clusters.json")
        cache_file.unlink(missing_ok=True)
        
        print(f"âœ“ Rejected {len(event_ids)} samples from cluster {cluster_id}")
        
        response = {
            "success": True,
            "rejected_count": len(event_ids)
        }
        client.publish(
            f"{REJECT_COMMAND_TOPIC}/response",
            json.dumps(response),
            qos=1
        )
        
    except Exception as e:
        print(f"âœ— Error handling reject command: {e}")
        response = {
            "success": False,
            "error": str(e)
        }
        client.publish(
            f"{REJECT_COMMAND_TOPIC}/response",
            json.dumps(response),
            qos=1
        )


def on_connect(client, userdata, flags, reason_code, properties):
    if reason_code == 0:
        print(f"âœ“ Connected to MQTT broker at {BROKER}:{PORT}")
        
        client.subscribe(ENROLL_COMMAND_TOPIC, qos=1)
        client.subscribe(REJECT_COMMAND_TOPIC, qos=1)
        
        print(f"âœ“ Subscribed to command topics")
    else:
        print(f"âœ— Failed to connect, reason code: {reason_code}")


def on_message(client, userdata, msg):
    """Route messages to appropriate handlers"""
    if msg.topic == ENROLL_COMMAND_TOPIC:
        handle_enroll_command(client, userdata, msg)
    elif msg.topic == REJECT_COMMAND_TOPIC:
        handle_reject_command(client, userdata, msg)


def main():
    """Main cluster publisher loop"""
    global last_cluster_count, mqtt_client
    
    print("=" * 60)
    print("VoiceBM Cluster Publisher")
    print("=" * 60)
    print(f"Room: {ROOM}")
    print(f"MQTT Broker: {BROKER}:{PORT}")
    print("=" * 60)
    
    mqtt_client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
    mqtt_client.username_pw_set(USER, PASS)
    mqtt_client.on_connect = on_connect
    mqtt_client.on_message = on_message
    
    try:
        mqtt_client.connect(BROKER, PORT, 60)
    except Exception as e:
        print(f"âœ— MQTT connection failed: {e}")
        return
    
    mqtt_client.loop_start()
    
    time.sleep(1)
    publish_discovery(mqtt_client)
    
    print("\nâœ“ Monitoring for voice clusters...")
    print("Press Ctrl+C to exit\n")
    
    cycle = 0
    
    try:
        while True:
            cycle += 1
            
            try:
                clusters = voice_clustering.generate_clusters(force_refresh=False)
                
                if len(clusters) != last_cluster_count:
                    print(f"\n[Cycle {cycle}] Cluster update:")
                    print(f"  Pending clusters: {len(clusters)}")
                    
                    if clusters:
                        total_samples = sum(c['stats']['count'] for c in clusters)
                        print(f"  Total samples: {total_samples}")
                        
                        for c in clusters:
                            print(f"    Cluster {c['cluster_id']}: {c['stats']['count']} samples, "
                                  f"similarity={c['stats']['avg_similarity']:.3f}")
                    
                    publish_cluster_summary(mqtt_client, clusters)
                    
                    for cluster in clusters:
                        publish_cluster_details(mqtt_client, cluster)
                    
                    last_cluster_count = len(clusters)
                
            except Exception as e:
                print(f"âœ— Error in publish cycle: {e}")
            
            time.sleep(10)
            
    except KeyboardInterrupt:
        print("\n\nShutting down...")
        mqtt_client.loop_stop()
        mqtt_client.disconnect()
        print("âœ“ Cluster publisher stopped")


if __name__ == "__main__":
    main()



################################################################################
# FILE: embed_stt.sh.template
# TYPE: script
################################################################################

#!/usr/bin/env bash
set -euo pipefail

# Voice biometrics embedding script for STT analysis
# Usage: ./embed_stt.sh <input_wav> <output_txt>

INPUT="$1"
OUTPUT="$2"

# DEBUG LOGGING
echo "[embed_stt.sh] START: $(date '+%Y-%m-%d %H:%M:%S.%3N')" >&2
echo "[embed_stt.sh] INPUT: $INPUT" >&2
echo "[embed_stt.sh] OUTPUT: $OUTPUT" >&2

# Use VB conda environment Python
PYTHON="{CONDA_PATH}/envs/vb/bin/python3"
SHERPA_WORKER="{SHERPA_BIN}"
SHERPA_MODEL="{SHERPA_MODEL}"

echo "[embed_stt.sh] PYTHON: $PYTHON" >&2
echo "[embed_stt.sh] WORKER: $SHERPA_WORKER" >&2
echo "[embed_stt.sh] MODEL: $SHERPA_MODEL" >&2

# Check if input file exists
if [ ! -f "$INPUT" ]; then
    echo "[embed_stt.sh] ERROR: Input WAV not found: $INPUT" >&2
    exit 1
fi

echo "[embed_stt.sh] Input file size: $(stat -c%s "$INPUT") bytes" >&2

# Create embedding
echo "[embed_stt.sh] Calling Sherpa..." >&2
START_TIME=$(date +%s%3N)

"$PYTHON" "$SHERPA_WORKER" \
    --model "$SHERPA_MODEL" \
    --wav "$INPUT" \
    --out "$OUTPUT" 2>&1

SHERPA_EXIT=$?
END_TIME=$(date +%s%3N)
ELAPSED=$((END_TIME - START_TIME))

echo "[embed_stt.sh] Sherpa exit code: $SHERPA_EXIT" >&2
echo "[embed_stt.sh] Sherpa execution time: ${ELAPSED}ms" >&2

# Check if output was created
if [ ! -f "$OUTPUT" ]; then
    echo "[embed_stt.sh] ERROR: Output embedding not created: $OUTPUT" >&2
    exit 1
fi

OUTPUT_SIZE=$(stat -c%s "$OUTPUT")
echo "[embed_stt.sh] Output file size: $OUTPUT_SIZE bytes" >&2

if [ "$OUTPUT_SIZE" -eq 0 ]; then
    echo "[embed_stt.sh] ERROR: Output embedding is empty" >&2
    exit 1
fi

echo "[embed_stt.sh] SUCCESS: Embedding created" >&2
echo "[embed_stt.sh] END: $(date '+%Y-%m-%d %H:%M:%S.%3N')" >&2

exit 0



################################################################################
# FILE: enrollment_watcher.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
Enrollment Watcher - Monitors {VOICEBM_BASE}/enroll/ for new person folders
and publishes MQTT device configs.

When a person is enrolled:
1. Create device with presence and voice binary sensors
2. Publish device config to {person_id}/device
3. Initialize state topics
"""

import os
import json
import time
import shutil
import paho.mqtt.client as mqtt
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# MQTT Configuration
# MQTT Configuration (centralized)
import sys
sys.path.insert(0, '{VOICEBM_BASE}')
from voicebm_config import get_mqtt_config

mqtt_config = get_mqtt_config()
BROKER = mqtt_config['broker']
PORT = mqtt_config['port']
USER = mqtt_config['user']
PASS = mqtt_config['password']

# Directories
ENROLL_DIR = Path("{VOICEBM_BASE}/enroll")
TRACKED_FILE = Path("{VOICEBM_BASE}/meta/enrolled_devices.json")
USER_SETTINGS_FILE = Path("{VOICEBM_BASE}/meta/user_settings.json")
DELETE_ENABLED_FILE = Path("{VOICEBM_BASE}/meta/delete_enabled.json")

# Current room this instance monitors
CURRENT_ROOM = "living"

# Track last published gallery sizes to avoid overwriting STT attributes
last_published_gallery_sizes = {}


# ============================================================================
# PERSON ID NORMALIZATION AND VALIDATION
# ============================================================================

def normalize_person_id(name):
    """
    Normalize person name to person_id format.
    Converts to lowercase and replaces spaces/hyphens with underscores.
    
    Transform rules:
    1. Convert to lowercase
    2. Replace hyphens with underscores
    3. Replace multiple spaces with single underscore
    4. Collapse multiple underscores to one
    5. Strip leading/trailing underscores
    
    Examples:
        "David Dryver Sr" â†’ "david_dryver_sr"
        "MARY-JANE Watson" â†’ "mary_jane_watson"
        "Jean   Luc   Picard" â†’ "jean_luc_picard"
        "ada_von-holtz" â†’ "ada_von_holtz"
    
    Returns:
        Normalized person_id (lowercase with underscores)
    """
    import re
    
    # Convert to lowercase
    normalized = name.lower()
    
    # Replace hyphens with underscores
    normalized = normalized.replace('-', '_')
    
    # Replace multiple spaces with single underscore
    normalized = re.sub(r'\s+', '_', normalized)
    
    # Collapse multiple underscores to one
    normalized = re.sub(r'_+', '_', normalized)
    
    # Strip leading/trailing underscores
    normalized = normalized.strip('_')
    
    return normalized


def validate_person_name(name):
    """
    Validate user input for person name.
    
    Rules:
    1. Must begin with a letter
    2. Must end with a letter
    3. Cannot contain digits
    4. Can only contain: letters, spaces, hyphens, underscores
    5. Must have at least one letter
    
    Examples of VALID input:
        "David", "David Dryver Sr", "Mary-Jane Watson"
        "Jean Luc Picard", "ada_von-holtz"
    
    Examples of INVALID input:
        "David_" (ends with non-letter)
        "_David" (starts with non-letter)
        "David2" (contains digits)
        "Ron@Kitchen" (special characters)
    
    Returns:
        (valid: bool, error_message: str or None)
    """
    import re
    
    if not name or len(name.strip()) == 0:
        return False, "Name cannot be empty"
    
    name = name.strip()
    
    # Must begin with a letter
    if not name[0].isalpha():
        return False, "Name must begin with a letter"
    
    # Must end with a letter
    if not name[-1].isalpha():
        return False, "Name must end with a letter"
    
    # Can only contain letters, spaces, hyphens, underscores
    if not re.match(r'^[a-zA-Z\s_-]+$', name):
        return False, "Name can only contain letters, spaces, hyphens, and underscores"
    
    # No digits allowed (already covered by regex, but explicit check)
    if any(char.isdigit() for char in name):
        return False, "Name cannot contain digits"
    
    return True, None


def check_for_duplicate_folders():
    """
    Check for duplicate person folders (e.g., 'David Dryver Sr' vs 'david_dryver_sr').
    
    Returns:
        dict of normalized_id â†’ [actual_folder_names] for folders that normalize to the same ID
    """
    if not ENROLL_DIR.exists():
        return {}
    
    duplicates = {}
    for person_dir in ENROLL_DIR.iterdir():
        if not person_dir.is_dir():
            continue
        
        actual_name = person_dir.name
        normalized = normalize_person_id(actual_name)
        
        if normalized not in duplicates:
            duplicates[normalized] = []
        duplicates[normalized].append(actual_name)
    
    # Return only entries with actual duplicates
    return {k: v for k, v in duplicates.items() if len(v) > 1}


# ============================================================================
# EXISTING HELPER FUNCTIONS
# ============================================================================

def load_tracked_devices():
    """Load set of person_ids we've already published"""
    if not TRACKED_FILE.exists():
        return set()
    try:
        with open(TRACKED_FILE, 'r') as f:
            data = json.load(f)
            return set(data.get('person_ids', []))
    except:
        return set()


def save_tracked_devices(person_ids):
    """Save set of enrolled person_ids"""
    try:
        TRACKED_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(TRACKED_FILE, 'w') as f:
            json.dump({
                'person_ids': list(person_ids),
                'last_updated': time.strftime('%Y-%m-%d %H:%M:%S')
            }, f, indent=2)
    except PermissionError as e:
        print(f"Warning: Cannot save tracked devices (permission denied): {e}")
        print(f"  Try: sudo chown -R ice:ice {VOICEBM_BASE}/meta/")
    except Exception as e:
        print(f"Warning: Cannot save tracked devices: {e}")


def load_user_settings():
    """Load user settings (blocklist state for 'user' device)"""
    if not USER_SETTINGS_FILE.exists():
        return {"blocked": False}
    try:
        with open(USER_SETTINGS_FILE, 'r') as f:
            return json.load(f)
    except:
        return {"blocked": False}


def save_user_settings(settings):
    """Save user settings"""
    try:
        USER_SETTINGS_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(USER_SETTINGS_FILE, 'w') as f:
            json.dump(settings, f, indent=2)
    except Exception as e:
        print(f"Warning: Cannot save user settings: {e}")


def load_delete_enabled():
    """Load which person_ids have delete enabled"""
    if not DELETE_ENABLED_FILE.exists():
        return {}
    try:
        with open(DELETE_ENABLED_FILE, 'r') as f:
            return json.load(f)
    except:
        return {}


def save_delete_enabled(enabled_dict):
    """Save delete enabled states"""
    try:
        DELETE_ENABLED_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(DELETE_ENABLED_FILE, 'w') as f:
            json.dump(enabled_dict, f, indent=2)
    except Exception as e:
        print(f"Warning: Cannot save delete enabled: {e}")



def get_gallery_size(person_id):
    """
    Count number of .txt embedding files for a person (Sherpa format).
    Embeddings are stored in /enroll/{person_id}/embeddings/*.txt
    
    Returns:
        Integer count of gallery samples
    """
    person_dir = Path(ENROLL_DIR) / person_id
    if not person_dir.exists():
        return 0
    
    # Embeddings are in a subdirectory (Sherpa format)
    embeddings_dir = person_dir / 'embeddings'
    if not embeddings_dir.exists():
        return 0
    
    # Count .txt files (Sherpa embeddings)
    txt_files = list(embeddings_dir.glob('*.txt'))
    return len(txt_files)


def publish_gallery_attributes(client, person_id):
    """
    Publish gallery size as attributes for the voice binary sensor.
    Only publishes when gallery_size changes to avoid overwriting
    confidence/source attributes published by STT service.
    """
    global last_published_gallery_sizes
    
    gallery_size = get_gallery_size(person_id)
    
    # Only publish if gallery size changed
    if person_id not in last_published_gallery_sizes or last_published_gallery_sizes[person_id] != gallery_size:
        attributes = {
            "gallery_size": gallery_size,
            "last_updated": time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        client.publish(
            f"{person_id}/voice/attributes",
            json.dumps(attributes),
            qos=1,
            retain=True
        )
        
        last_published_gallery_sizes[person_id] = gallery_size


def publish_person_device(client, person_id, display_name, is_new_device=False):
    """
    Publish person device using Home Assistant MQTT Discovery.
    
    CRITICAL: Discovery config is always published (with retain).
              State is ONLY published for NEW devices.
              Existing devices keep their HA-retained state.
    
    Args:
        client: MQTT client
        person_id: Person identifier
        display_name: Human readable name
        is_new_device: If True, publish initial state. If False, only publish discovery.
    """
    discovery_prefix = "homeassistant"
    
    # Device info
    device = {
        "identifiers": [person_id],
        "name": display_name,
        "manufacturer": "",
        "model": "Person"
    }
    
    # Voice binary sensor config
    voice_config = {
        "name": "Voice",
        "unique_id": f"{person_id}_voice",
        "device_class": "sound",
        "state_topic": f"{person_id}/voice",
        "payload_on": "ON",
        "payload_off": "OFF",
        "json_attributes_topic": f"{person_id}/voice/attributes",
        "device": device
    }
    
    # Publish voice sensor discovery
    client.publish(
        f"{discovery_prefix}/binary_sensor/{person_id}_voice/config",
        json.dumps(voice_config),
        qos=1,
        retain=True
    )
    
    # Blocklist switch config - NOW INCLUDES "user"
    blocklist_config = {
        "name": "Blocklist",
        "unique_id": f"{person_id}_blocklist",
        "command_topic": f"voicebm/blocklist/{person_id}/set",
        "state_topic": f"voicebm/blocklist/{person_id}",
        "payload_on": "ON",
        "payload_off": "OFF",
        "icon": "mdi:account-cancel",
        "device": device
    }
    
    client.publish(
        f"{discovery_prefix}/switch/{person_id}_blocklist/config",
        json.dumps(blocklist_config),
        qos=1,
        retain=True
    )
    
    # Per-Person Threshold Override number entity
    threshold_config = {
        "name": "Threshold Override",
        "unique_id": f"{person_id}_threshold",
        "command_topic": f"{person_id}/threshold_override/set",
        "state_topic": f"{person_id}/threshold_override",
        "min": 0.10,
        "max": 0.90,
        "step": 0.01,
        "mode": "slider",
        "icon": "mdi:gauge",
        "device": device,
        "unit_of_measurement": "",
        "entity_category": "config"
    }
    
    client.publish(
        f"{discovery_prefix}/number/{person_id}_threshold/config",
        json.dumps(threshold_config),
        qos=1,
        retain=True
    )
    
    # Delete controls (only for enrolled persons, not "user")
    if person_id != "user":
        # Enable Delete Controls switch
        enable_delete_config = {
            "name": "Enable Delete Controls",
            "unique_id": f"{person_id}_enable_delete",
            "command_topic": f"voicebm/identity/{person_id}/enable_delete/set",
            "state_topic": f"voicebm/identity/{person_id}/enable_delete",
            "payload_on": "ON",
            "payload_off": "OFF",
            "icon": "mdi:lock-open-alert",
            "entity_category": "config",
            "device": device
        }
        
        client.publish(
            f"{discovery_prefix}/switch/{person_id}_enable_delete/config",
            json.dumps(enable_delete_config),
            qos=1,
            retain=True
        )
        
        # Delete This Identity button
        delete_button_config = {
            "name": "âš ï¸ Delete This Identity",
            "unique_id": f"{person_id}_delete",
            "command_topic": f"voicebm/identity/{person_id}/delete",
            "payload_press": "PRESS",
            "icon": "mdi:delete-forever-outline",
            "entity_category": "config",
            "device": device
        }
        
        client.publish(
            f"{discovery_prefix}/button/{person_id}_delete/config",
            json.dumps(delete_button_config),
            qos=1,
            retain=True
        )
        
        # Thing Engine: Transform text input
        transform_name_config = {
            "name": "New Identity Name",
            "unique_id": f"{person_id}_transform_name",
            "command_topic": f"voicebm/thing/transform/{person_id}/name/set",
            "state_topic": f"voicebm/thing/transform/{person_id}/name",
            "icon": "mdi:account-edit",
            "device": device,
            "entity_category": "config"
        }
        
        client.publish(
            f"{discovery_prefix}/text/{person_id}_transform_name/config",
            json.dumps(transform_name_config),
            qos=1,
            retain=True
        )
        
        # Thing Engine: Transform button
        transform_execute_config = {
            "name": "Rename Identity",
            "unique_id": f"{person_id}_transform_execute",
            "command_topic": f"voicebm/thing/transform/{person_id}/execute",
            "payload_press": "PRESS",
            "icon": "mdi:account-convert",
            "device": device,
            "entity_category": "config"
        }
        
        client.publish(
            f"{discovery_prefix}/button/{person_id}_transform_execute/config",
            json.dumps(transform_execute_config),
            qos=1,
            retain=True
        )
        
        # Thing Engine: Merge tag switch
        merge_tag_config = {
            "name": "Tag for Merge",
            "unique_id": f"{person_id}_merge_tag",
            "command_topic": f"voicebm/thing/merge/tag/{person_id}/set",
            "state_topic": f"voicebm/thing/merge/tag/{person_id}",
            "payload_on": "ON",
            "payload_off": "OFF",
            "icon": "mdi:account-multiple",
            "device": device,
            "entity_category": "config"
        }
        
        client.publish(
            f"{discovery_prefix}/switch/{person_id}_merge_tag/config",
            json.dumps(merge_tag_config),
            qos=1,
            retain=True
        )
    
    # ONLY publish initial state for NEW devices
    # Existing devices keep their HA-retained state
    if is_new_device:
        if person_id == "user":
            # For "user", use separate settings file
            user_settings = load_user_settings()
            blocked = user_settings.get("blocked", False)
        else:
            # For enrolled persons, use metadata.json
            metadata_path = Path(ENROLL_DIR) / person_id / "metadata.json"
            blocked = False
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r') as f:
                        metadata = json.load(f)
                        blocked = metadata.get("blocked", False)
                except:
                    pass
        
        client.publish(
            f"voicebm/blocklist/{person_id}",
            "ON" if blocked else "OFF",
            qos=1,
            retain=True
        )
        
        # Initialize threshold override (default: None = use global threshold)
        # Read from metadata if available, otherwise leave unset
        threshold = None
        if person_id != "user":
            metadata_path = Path(ENROLL_DIR) / person_id / "metadata.json"
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r') as f:
                        metadata = json.load(f)
                        threshold = metadata.get("threshold_override")
                except:
                    pass
        
        # Only publish if threshold is explicitly set
        if threshold is not None:
            client.publish(
                f"{person_id}/threshold_override",
                str(threshold),
                qos=1,
                retain=True
            )
        
        # Initialize enable_delete state (OFF by default for safety)
        if person_id != "user":
            client.publish(
                f"voicebm/identity/{person_id}/enable_delete",
                "OFF",
                qos=1,
                retain=True
            )
        
        print(f"Published device config for {person_id} (NEW, blocked={blocked}, threshold={threshold or 'global'})")
    else:
        print(f"Published device config for {person_id} (discovery only, state preserved)")
    
    return True


def scan_enrollments(client, tracked, force_republish=False):
    """
    Scan enrollment directory for persons.
    
    Args:
        client: MQTT client
        tracked: Set of already tracked person_ids
        force_republish: If True, republish ALL (for startup). If False, only publish new ones.
    """
    if not ENROLL_DIR.exists():
        print(f"Enrollment directory not found: {ENROLL_DIR}")
        return tracked
    
    newly_enrolled = []
    republished = []
    
    for person_dir in ENROLL_DIR.iterdir():
        if not person_dir.is_dir():
            continue
        
        person_id = person_dir.name
        
        # ALWAYS publish gallery attributes (updates gallery size even for existing devices)
        publish_gallery_attributes(client, person_id)
        
        # Skip device discovery if already tracked and not forcing republish
        if person_id in tracked and not force_republish:
            continue
        
        # Load metadata for display name
        metadata_file = person_dir / 'metadata.json'
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    display_name = metadata.get('display_name', person_id.replace('_', ' ').title())
            except:
                display_name = person_id.replace('_', ' ').title()
        else:
            # If no metadata, derive display name from person_id
            display_name = person_id.replace('_', ' ').title()
        
        # Determine if this is a new device or republish
        is_new = person_id not in tracked
        
        # Publish device - only publish state for NEW devices
        success = publish_person_device(client, person_id, display_name, is_new_device=is_new)
        
        if success:
            if person_id in tracked:
                republished.append((person_id, display_name))
            else:
                newly_enrolled.append((person_id, display_name))
                tracked.add(person_id)
    
    if newly_enrolled or republished:
        save_tracked_devices(tracked)
        
        if republished:
            print(f"\nRepublished: {len(republished)} person(s)")
            for pid, name in republished:
                print(f"  - {name} ({pid})")
        
        if newly_enrolled:
            print(f"\nNewly enrolled: {len(newly_enrolled)} person(s)")
            for pid, name in newly_enrolled:
                print(f"  - {name} ({pid})")
    
    return tracked


def delete_person_identity(client, person_id, tracked):
    """
    Delete a person's identity completely.
    
    Two-step safety:
    1. Check if delete is enabled
    2. Delete enrollment folder
    3. Clear MQTT retained topics
    4. Remove from tracked devices
    """
    # Check if delete is enabled for this person
    delete_enabled = load_delete_enabled()
    if not delete_enabled.get(person_id, False):
        print(f"âŒ DELETE BLOCKED: {person_id} - enable_delete switch is OFF")
        return tracked
    
    print(f"\nâš ï¸  DELETING IDENTITY: {person_id}")
    
    # 1. Delete enrollment folder
    person_folder = ENROLL_DIR / person_id
    if person_folder.exists():
        try:
            shutil.rmtree(person_folder)
            print(f"  âœ“ Deleted folder: {person_folder}")
        except Exception as e:
            print(f"  âŒ Failed to delete folder: {e}")
            return tracked
    else:
        print(f"  âš ï¸  Folder not found: {person_folder}")
    
    # 2. Clear MQTT retained topics (None payload = delete retained)
    discovery_prefix = "homeassistant"
    topics_to_clear = [
        # State topics
        f"voicebm/blocklist/{person_id}",
        f"voicebm/identity/{person_id}/enable_delete",
        f"voicebm/thing/transform/{person_id}/name",
        f"voicebm/thing/merge/tag/{person_id}",
        f"{person_id}/voice",
        f"{person_id}/threshold_override",
        # Discovery topics
        f"{discovery_prefix}/switch/{person_id}_blocklist/config",
        f"{discovery_prefix}/switch/{person_id}_enable_delete/config",
        f"{discovery_prefix}/button/{person_id}_delete/config",
        f"{discovery_prefix}/binary_sensor/{person_id}_voice/config",
        f"{discovery_prefix}/number/{person_id}_threshold/config",
        f"{discovery_prefix}/text/{person_id}_transform_name/config",
        f"{discovery_prefix}/button/{person_id}_transform_execute/config",
        f"{discovery_prefix}/switch/{person_id}_merge_tag/config",
    ]
    
    for topic in topics_to_clear:
        client.publish(topic, None, qos=1, retain=True)
    
    print(f"  âœ“ Cleared {len(topics_to_clear)} MQTT retained topics")
    
    # 3. Remove from tracked devices
    if person_id in tracked:
        tracked.discard(person_id)
        save_tracked_devices(tracked)
        print(f"  âœ“ Removed from tracked devices")
    
    # 4. Remove from delete_enabled
    if person_id in delete_enabled:
        del delete_enabled[person_id]
        save_delete_enabled(delete_enabled)
    
    print(f"âœ… DELETED: {person_id}\n")
    
    return tracked


class EnrollmentHandler(FileSystemEventHandler):
    """Watch for new enrollment folders"""
    
    def __init__(self, client, tracked):
        self.client = client
        self.tracked = tracked
    
    def on_created(self, event):
        """Handle new folder creation"""
        if not event.is_directory:
            return
        
        person_dir = Path(event.src_path)
        person_id = person_dir.name
        
        # Skip if already tracked
        if person_id in self.tracked:
            return
        
        # Wait a moment for metadata.json to be written
        time.sleep(0.5)
        
        # Load display name
        metadata_file = person_dir / 'metadata.json'
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    display_name = metadata.get('display_name', person_id.replace('_', ' ').title())
            except:
                display_name = person_id.replace('_', ' ').title()
        else:
            display_name = person_id.replace('_', ' ').title()
        
        # Publish device - this IS a new device
        print(f"\nÃƒÂ¢Ã¢â‚¬Â Ã¢â‚¬â„¢ New enrollment detected: {person_id}")
        success = publish_person_device(self.client, person_id, display_name, is_new_device=True)
        
        if success:
            self.tracked.add(person_id)
            save_tracked_devices(self.tracked)


def on_connect(client, userdata, flags, reason_code, properties):
    if reason_code == 0:
        print(f"ÃƒÂ¢Ã…â€œÃ¢â‚¬Å“ Connected to MQTT broker at {BROKER}:{PORT}")
        # Subscribe to blocklist commands HERE on connect
        client.subscribe("voicebm/blocklist/+/set", qos=1)
        print("Subscribed to voicebm/blocklist/+/set")
        # Subscribe to delete controls
        client.subscribe("voicebm/identity/+/enable_delete/set", qos=1)
        client.subscribe("voicebm/identity/+/delete", qos=1)
        print("Subscribed to delete control topics")
    else:
        print(f"ÃƒÂ¢Ã…â€œÃ¢â‚¬â€ Failed to connect, reason code: {reason_code}")


def on_message(client, userdata, msg):
    """Handle all incoming messages - required for wildcard topic matching."""
    topic = msg.topic
    payload = msg.payload.decode('utf-8')
    
    # Handle blocklist commands
    if topic.startswith("voicebm/blocklist/") and topic.endswith("/set"):
        handle_blocklist_command(client, userdata, msg)
        return
    
    # Handle enable_delete switch
    if "/enable_delete/set" in topic:
        parts = topic.split('/')
        if len(parts) >= 3:
            person_id = parts[2]
            
            delete_enabled = load_delete_enabled()
            delete_enabled[person_id] = (payload == "ON")
            save_delete_enabled(delete_enabled)
            
            # Publish state back
            client.publish(
                f"voicebm/identity/{person_id}/enable_delete",
                payload,
                qos=1,
                retain=True
            )
            
            status = "ENABLED" if payload == "ON" else "DISABLED"
            print(f"ðŸ”“ Delete controls {status}: {person_id}")
        return
    
    # Handle delete button press
    if topic.endswith("/delete") and payload == "PRESS":
        parts = topic.split('/')
        if len(parts) >= 3:
            person_id = parts[2]
            
            # Get tracked set from userdata
            tracked = userdata.get('tracked', set())
            tracked = delete_person_identity(client, person_id, tracked)
            userdata['tracked'] = tracked
        return


def handle_blocklist_command(client, userdata, msg):
    """Handle blocklist toggle commands."""
    try:
        # Extract person_id from topic: voicebm/blocklist/{person_id}/set
        parts = msg.topic.split('/')
        if len(parts) < 4:
            print(f"Invalid blocklist topic: {msg.topic}")
            return
        
        person_id = parts[2]
        command = msg.payload.decode('utf-8')
        
        print(f"\nBlocklist command for {person_id}: {command}")
        
        new_blocked = (command == "ON")
        
        if person_id == "user":
            # Handle "user" blocklist separately
            user_settings = load_user_settings()
            user_settings['blocked'] = new_blocked
            user_settings['last_updated'] = time.strftime('%Y-%m-%d %H:%M:%S')
            save_user_settings(user_settings)
        else:
            # Handle enrolled person blocklist
            metadata_path = Path(ENROLL_DIR) / person_id / "metadata.json"
            
            # Create metadata if it doesn't exist
            if not metadata_path.exists():
                print(f"  Creating metadata.json for {person_id}")
                metadata_path.parent.mkdir(parents=True, exist_ok=True)
                metadata = {
                    'person_id': person_id,
                    'display_name': person_id.replace('_', ' ').title(),
                    'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'blocked': new_blocked
                }
            else:
                try:
                    with open(metadata_path, 'r') as f:
                        metadata = json.load(f)
                except:
                    metadata = {
                        'person_id': person_id,
                        'display_name': person_id.replace('_', ' ').title()
                    }
            
            # Update blocked status
            metadata['blocked'] = new_blocked
            metadata['last_updated'] = time.strftime('%Y-%m-%d %H:%M:%S')
            
            try:
                with open(metadata_path, 'w') as f:
                    json.dump(metadata, f, indent=2)
                print(f"  Metadata saved for {person_id}")
            except Exception as e:
                print(f"  Warning: Failed to save metadata: {e}")
        
        # ALWAYS publish state update back to state topic
        client.publish(
            f"voicebm/blocklist/{person_id}",
            command,
            qos=1,
            retain=True
        )
        
        status = "BLOCKED" if new_blocked else "UNBLOCKED"
        print(f"  {status}: {person_id}")
        
    except Exception as e:
        print(f"  Error handling blocklist command: {e}")
        import traceback
        traceback.print_exc()


def main():
    """
    Main enrollment watcher loop.
    
    Startup behavior:
    1. Scans enrollment directory
    2. REPUBLISHES device config for ALL enrolled persons (even if tracked)
    3. This ensures devices exist in MQTT/HA even if manually deleted
    4. unique_id prevents duplicates
    
    Runtime behavior:
    1. Watches for NEW enrollment folders
    2. Publishes device config only for newly created persons
    """
    print("=" * 60)
    print("VoiceBM Enrollment Watcher")
    print("=" * 60)
    print(f"Monitoring: {ENROLL_DIR}")
    print(f"MQTT Broker: {BROKER}:{PORT}")
    print(f"Current Room: {CURRENT_ROOM}")
    print("=" * 60)
    
    # Check for duplicate person folders (e.g., 'David Dryver Sr' vs 'david_dryver_sr')
    duplicates = check_for_duplicate_folders()
    if duplicates:
        print("\nâš ï¸  WARNING: Duplicate person folders detected!")
        print("These folders normalize to the same person_id:")
        for normalized_id, folder_list in duplicates.items():
            print(f"  {normalized_id}:")
            for folder in folder_list:
                print(f"    - {folder}")
        print("\nRecommendation: Delete duplicate folders and keep only lowercase_with_underscores format")
        print("Example: Keep 'david_dryver_sr', delete 'David Dryver Sr'\n")
    
    # Create enrollment directory if it doesn't exist
    ENROLL_DIR.mkdir(parents=True, exist_ok=True)
    
    # Connect to MQTT
    client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
    client.username_pw_set(USER, PASS)
    client.on_connect = on_connect
    
    try:
        client.connect(BROKER, PORT, 60)
    except Exception as e:
        print(f"ÃƒÂ¢Ã…â€œÃ¢â‚¬â€ MQTT connection failed: {e}")
        return
    
    client.loop_start()
    
    # Load tracked devices
    tracked = load_tracked_devices()
    print(f"\nAlready enrolled: {len(tracked)} person(s)")
    if tracked:
        for pid in sorted(tracked):
            print(f"  - {pid}")
    
    # CRITICAL: Create "user" device for non-enrolled speakers (now with blocklist!)
    # Only publish initial state if "user" is not already tracked
    user_is_new = "user" not in tracked
    print(f"\nCreating 'user' device for non-enrolled speakers (is_new={user_is_new})...")
    publish_person_device(client, "user", "user", is_new_device=user_is_new)
    if user_is_new:
        tracked.add("user")
        save_tracked_devices(tracked)
    
    # STARTUP: Force republish ALL enrolled persons (in case devices were deleted in MQTT/HA)
    print("\nRepublishing all enrolled devices on startup...")
    tracked = scan_enrollments(client, tracked, force_republish=True)
    
    # Set up filesystem watcher
    event_handler = EnrollmentHandler(client, tracked)
    observer = Observer()
    observer.schedule(event_handler, str(ENROLL_DIR), recursive=False)
    
    # Set userdata for on_message handlers (needed for delete functionality)
    client.user_data_set({'tracked': tracked})
    
    # Set on_message callback for wildcard topic handling (blocklist, delete commands)
    client.on_message = on_message
    
    observer.start()
    
    print("\nÃƒÂ¢Ã…â€œÃ¢â‚¬Å“ Watching for new enrollments...")
    print("Press Ctrl+C to exit\n")
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\n\nShutting down...")
        observer.stop()
        observer.join()
        client.loop_stop()
        client.disconnect()
        print("ÃƒÂ¢Ã…â€œÃ¢â‚¬Å“ Enrollment watcher stopped")


if __name__ == "__main__":
    main()



################################################################################
# FILE: handler.py.template
# TYPE: script
################################################################################

"""Event handler for clients of the server with Voice Biometrics integration via MQTT.

ACTIVE PIPELINE SCRIPT - Docker container component
This runs inside the ONNX ASR Docker container (nifty_grothendieck)

CRITICAL FLOW ORDER:
1. Audio comes in
2. Voice biometrics analysis FIRST (identify speaker from gallery)
3. Fire binary sensor (ALWAYS, regardless of blocklist)
4. Update current_speaker text sensor with gallery match
5. If blocked: STOP - No STT, No MQTT publish, just return empty transcript
6. If not blocked: Do STT, apply injection, publish to MQTT

Deploy via:
  sudo docker cp /home/ice/onnx-asr-addon/onnx-asr/handler.py nifty_grothendieck:/app/wyoming_onnx_asr/handler.py
  sudo docker restart nifty_grothendieck
"""

import asyncio
import logging
import os
import tempfile
import wave
import json
import time
import uuid
import shutil
from pathlib import Path

from typing import Optional
import numpy as np
import soundfile as sf
from onnx_asr.adapters import AsrAdapter
from wyoming.asr import Transcribe, Transcript
from wyoming.audio import AudioChunk, AudioStop
from wyoming.event import Event
from wyoming.info import Describe, Info
from wyoming.server import AsyncEventHandler
import paho.mqtt.client as mqtt

_LOGGER = logging.getLogger(__name__)

# Voice biometrics configuration
# MQTT Configuration (from environment variables for Docker)
import os

MQTT_BROKER = os.getenv('MQTT_BROKER', '10.50.60.59')
MQTT_PORT = int(os.getenv('MQTT_PORT', '1883'))
MQTT_USER = os.getenv('MQTT_USER', 'mqtt-user')
MQTT_PASS = os.getenv('MQTT_PASS', 'infinItyD&1')
SHARED_AUDIO_DIR = "/opt/voicebm/stt_requests"
VB_REQUEST_TOPIC = "voicebm/stt/analyze_request"
VB_RESPONSE_TOPIC = "voicebm/stt/analyze_response"
ANALYSIS_TIMEOUT = 20  # seconds to wait for voice biometrics response


class NemoAsrEventHandler(AsyncEventHandler):
    """Event handler for clients."""

    def __init__(
        self,
        wyoming_info: Info,
        models: dict[str, AsrAdapter],
        model_lock: asyncio.Lock,
        *args,
        initial_prompt: Optional[str] = None,
        **kwargs,
    ) -> None:
        super().__init__(*args, **kwargs)

        self.wyoming_info_event = wyoming_info.event()
        self.models = models
        self.model_lock = model_lock
        self.initial_prompt = initial_prompt
        self.request_language: Optional[str] = None
        self._wav_dir = tempfile.TemporaryDirectory()
        self._wav_path = os.path.join(self._wav_dir.name, "speech.wav")
        self._wav_file: Optional[wave.Wave_write] = None
        
        # Create shared directory if it doesn't exist
        Path(SHARED_AUDIO_DIR).mkdir(parents=True, exist_ok=True)
        
        # Track injection state (default: ON)
        # Note: This is a fallback - actual state comes from voicebm_stt_service response
        self.inject_identity_enabled = True
        self._injection_state_initialized = False
        
        # Subscribe to injection toggle via MQTT (for local fallback)
        self._setup_mqtt_subscription()
        
        _LOGGER.info(f"Voice biometrics MQTT integration initialized")
    
    def _setup_mqtt_subscription(self):
        """Subscribe to injection toggle state via MQTT."""
        try:
            def on_connect(client, userdata, flags, reason_code, properties):
                if reason_code == 0:
                    # Only log initial connection, not reconnects
                    if not self._injection_state_initialized:
                        _LOGGER.info(f"Injection state MQTT connected")
                    client.subscribe("voicebm/living/inject_identity", qos=1)
            
            def on_message(client, userdata, msg):
                try:
                    state = msg.payload.decode('utf-8')
                    new_enabled = (state == "ON")
                    
                    # Only log if state actually changed or this is initial setup
                    if not self._injection_state_initialized:
                        self.inject_identity_enabled = new_enabled
                        self._injection_state_initialized = True
                        _LOGGER.info(f"[SETTING] Initial injection state: {state} (enabled={new_enabled})")
                    elif self.inject_identity_enabled != new_enabled:
                        self.inject_identity_enabled = new_enabled
                        _LOGGER.info(f"[SETTING] Injection state changed: {state} (enabled={new_enabled})")
                    # Otherwise, ignore duplicate retained messages
                    
                except Exception as e:
                    _LOGGER.error(f"Failed to parse injection state: {e}")
            
            def on_disconnect(client, userdata, flags, reason_code, properties):
                # Only log unexpected disconnects, and attempt reconnect
                if reason_code != 0:
                    _LOGGER.warning(f"Injection state MQTT disconnected: rc={reason_code}, will auto-reconnect")
            
            # Create persistent MQTT client for state tracking
            self.state_client = mqtt.Client(
                client_id="wyoming_vb_state",
                clean_session=True,
                callback_api_version=mqtt.CallbackAPIVersion.VERSION2
            )
            self.state_client.username_pw_set(MQTT_USER, MQTT_PASS)
            self.state_client.on_connect = on_connect
            self.state_client.on_message = on_message
            self.state_client.on_disconnect = on_disconnect
            
            # Set reconnect delay and keep-alive
            self.state_client.reconnect_delay_set(min_delay=5, max_delay=300)
            
            # Connect with longer keep-alive to prevent timeouts
            self.state_client.connect(MQTT_BROKER, MQTT_PORT, keepalive=300)
            self.state_client.loop_start()
            
            _LOGGER.info("Subscribed to injection state topic")
            
        except Exception as e:
            _LOGGER.error(f"Failed to setup injection state subscription: {e}")
            self.inject_identity_enabled = True  # Default to ON on error

    def request_voice_analysis(self, audio_path):
        """
        Request voice biometrics analysis via MQTT.
        
        Returns tuple of 5 values:
            (speaker_id, display_name, confidence, inject_enabled, is_blocked)
        
        speaker_id and display_name come from speaker identification gallery matching.
        If no match, they will be None (not hardcoded to "user").
        
        IMPORTANT: is_blocked comes from HOST service (voicebm_stt_service.py)
        which has access to metadata files. This container does NOT have
        access to {VOICEBM_BASE}/enroll/ filesystem.
        """
        request_id = str(uuid.uuid4())
        response_data = {
            "received": False,
            "speaker_id": None,
            "display_name": None,
            "confidence": 0.0,
            "inject_enabled": True,  # Default
            "is_blocked": False       # Default - HOST service provides actual value
        }
        
        def on_connect(client, userdata, flags, reason_code, properties):
            _LOGGER.info(f"VB MQTT connected: rc={reason_code}")
            client.subscribe(f"{VB_RESPONSE_TOPIC}/{request_id}", qos=1)
        
        def on_message(client, userdata, msg):
            try:
                payload = json.loads(msg.payload.decode('utf-8'))
                response_data["received"] = True
                response_data["speaker_id"] = payload.get("speaker_id")
                response_data["display_name"] = payload.get("display_name")
                response_data["confidence"] = payload.get("confidence", 0.0)
                response_data["inject_enabled"] = payload.get("inject_enabled", True)
                response_data["is_blocked"] = payload.get("is_blocked", False)
                _LOGGER.info(f"VB response: {payload}")
            except Exception as e:
                _LOGGER.error(f"Failed to parse VB response: {e}")
        
        try:
            client = mqtt.Client(
                client_id=f"wyoming_vb_{request_id[:8]}", 
                clean_session=True, 
                callback_api_version=mqtt.CallbackAPIVersion.VERSION2
            )
            client.username_pw_set(MQTT_USER, MQTT_PASS)
            client.on_connect = on_connect
            client.on_message = on_message
            
            client.connect(MQTT_BROKER, MQTT_PORT, 60)
            client.loop_start()
            
            # Wait for subscription
            time.sleep(0.5)
            
            # Publish analysis request
            request_payload = {
                "request_id": request_id,
                "audio_path": audio_path,
                "timestamp": time.time()
            }
            
            _LOGGER.info(f"Publishing VB request: {request_payload}")
            client.publish(VB_REQUEST_TOPIC, json.dumps(request_payload), qos=1)
            
            # Wait for response
            start_time = time.time()
            while not response_data["received"] and (time.time() - start_time) < ANALYSIS_TIMEOUT:
                time.sleep(0.1)
            
            client.loop_stop()
            client.disconnect()
            
            if response_data["received"]:
                return (
                    response_data["speaker_id"], 
                    response_data["display_name"],
                    response_data["confidence"],
                    response_data["inject_enabled"],
                    response_data["is_blocked"]
                )
            else:
                _LOGGER.warning(f"VB analysis timeout after {ANALYSIS_TIMEOUT}s")
                return None, None, 0.0, True, False
                
        except Exception as e:
            _LOGGER.error(f"VB request failed: {e}", exc_info=True)
            return None, None, 0.0, True, False

    def publish_voice_on(self, person_id):
        """
        Publish ON to person's voice binary sensor via MQTT.
        GROUND TRUTH LAYER - Always fires regardless of blocklist.
        
        person_id comes from speaker identification gallery match (e.g., "david_dryver_sr")
        or "user" if no match above threshold.
        """
        try:
            client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
            client.username_pw_set(MQTT_USER, MQTT_PASS)
            
            client.connect(MQTT_BROKER, MQTT_PORT, 60)
            client.loop_start()
            
            topic = f"{person_id}/voice"
            client.publish(topic, "ON", qos=1, retain=False)
            
            time.sleep(0.3)
            
            client.loop_stop()
            client.disconnect()
            
            _LOGGER.info(f"[OK] Binary sensor ON: {topic}")
            return True
            
        except Exception as e:
            _LOGGER.error(f"Voice sensor MQTT publish failed: {e}")
            return False

    def publish_current_speaker(self, display_name):
        """
        Publish current speaker to global text sensor.
        
        display_name comes from speaker identification gallery match (e.g., "David Dryver Sr")
        or "user" if no match above threshold. This is the IDENTIFIED speaker 
        from the gallery, not a hardcoded value.
        
        Topic: voicebm/living/current_speaker
        """
        try:
            client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
            client.username_pw_set(MQTT_USER, MQTT_PASS)
            
            client.connect(MQTT_BROKER, MQTT_PORT, 60)
            client.loop_start()
            
            topic = "voicebm/living/current_speaker"
            client.publish(topic, display_name or "user", qos=1, retain=True)
            
            time.sleep(0.3)
            
            client.loop_stop()
            client.disconnect()
            
            _LOGGER.info(f"[OK] Current speaker: {display_name or 'user'}")
            return True
            
        except Exception as e:
            _LOGGER.error(f"Current speaker publish failed: {e}")
            return False

    async def handle_event(self, event: Event) -> bool:
        if AudioChunk.is_type(event.type):
            chunk = AudioChunk.from_event(event)

            if self._wav_file is None:
                self._wav_file = wave.open(self._wav_path, "wb")
                self._wav_file.setframerate(chunk.rate)
                self._wav_file.setsampwidth(chunk.width)
                self._wav_file.setnchannels(chunk.channels)

            self._wav_file.writeframes(chunk.audio)
            return True

        if AudioStop.is_type(event.type):
            _LOGGER.debug(
                "Audio stopped. Processing with voice biometrics first.",
            )
            assert self._wav_file is not None

            self._wav_file.close()
            self._wav_file = None

            # ============================================================
            # STEP 1: VOICE BIOMETRICS FIRST (before any STT)
            # ============================================================
            speaker_id = None
            display_name = None
            confidence = 0.0
            inject_enabled = True
            is_blocked = False
            
            try:
                _LOGGER.info("STEP 1: Voice biometrics analysis FIRST...")
                
                # Copy audio to shared location
                shared_audio_filename = f"stt_{int(time.time() * 1000)}.wav"
                shared_audio_path = os.path.join(
                    SHARED_AUDIO_DIR, 
                    shared_audio_filename
                )
                
                shutil.copy2(self._wav_path, shared_audio_path)
                
                # HOST path for voicebm_stt_service.py
                host_audio_path = f"{VOICEBM_BASE}/stt_requests/{shared_audio_filename}"
                
                # Request analysis via MQTT - returns gallery match results
                speaker_id, display_name, confidence, inject_enabled, is_blocked = self.request_voice_analysis(host_audio_path)
                
                # ============================================================
                # speaker_id/display_name come from speaker identification comparison 
                # against enrolled gallery - this is WHO was identified
                # ============================================================
                final_speaker_id = speaker_id or "user"
                final_display_name = display_name or "user"
                
                _LOGGER.info(f"[IDENTIFIED] {final_display_name} (speaker_id={final_speaker_id}, confidence={confidence:.4f}, blocked={is_blocked})")
                
                # ============================================================
                # STEP 2: BINARY SENSOR ALWAYS FIRES (Ground Truth Layer)
                # Fires the sensor for whoever speaker identification identified
                # ============================================================
                self.publish_voice_on(final_speaker_id)
                
                # ============================================================
                # STEP 3: UPDATE CURRENT SPEAKER TEXT SENSOR
                # This shows WHO speaker identification identified from the gallery
                # ============================================================
                self.publish_current_speaker(final_display_name)
                
                # ============================================================
                # STEP 4: IF BLOCKED - STOP EVERYTHING HERE
                # ============================================================
                if is_blocked:
                    _LOGGER.info(f"[BLOCKED] {final_display_name} ({final_speaker_id}) is on blocklist - NO STT, NO MQTT, returning empty")
                    
                    # Cleanup shared audio file
                    try:
                        os.unlink(shared_audio_path)
                    except:
                        pass
                    
                    # Return empty transcript - skip all processing
                    await self.write_event(Transcript(text="").event())
                    self.request_language = None
                    return False
                
                # ============================================================
                # STEP 5: NOT BLOCKED - Do STT transcription
                # ============================================================
                _LOGGER.info("STEP 5: Not blocked - proceeding with STT...")
                
                # Read audio for STT
                waveform, sample_rate = sf.read(self._wav_path, dtype="float32")
                if len(waveform.shape) > 1:
                    waveform = np.mean(waveform, axis=1)

                lang = self.request_language or "en"
                model = None

                if lang == "en" and "en" in self.models:
                    model = self.models["en"]
                elif "multi" in self.models:
                    model = self.models["multi"]
                elif "en" in self.models:
                    model = self.models["en"]

                if model is None:
                    await self.write_event(Transcript(text="ERROR: No model").event())
                    return False

                async with self.model_lock:
                    try:
                        # STT transcription
                        text = model.recognize(
                            waveform, language=lang, sample_rate=sample_rate
                        )
                        _LOGGER.info(f"TRANSCRIPTION: '{text}'")

                        # ============================================================
                        # STEP 6: Apply injection if enabled
                        # Uses display_name from GALLERY MATCH
                        # ============================================================
                        if inject_enabled:
                            if display_name:
                                modified_text = f"{display_name}: {text}"
                            else:
                                modified_text = f"user: {text}"
                            _LOGGER.info(f"[INJECTED] '{modified_text}'")
                        else:
                            modified_text = text
                            _LOGGER.info(f"[CLEAN] '{modified_text}' (injection disabled)")

                        # ============================================================
                        # STEP 7: Publish to MQTT
                        # ============================================================
                        try:
                            msg = {
                                "state": "user_transcript_ready",
                                "full": modified_text.strip() if modified_text else "",
                                "timestamp": __import__('datetime').datetime.now().isoformat()
                            }

                            _LOGGER.info(f"MQTT PUBLISH: topic=andrea/user/full, payload={json.dumps(msg)}")
                            
                            mqtt_client = mqtt.Client(client_id="wyoming_asr", clean_session=True, callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
                            mqtt_client.username_pw_set("mqtt-user", "infinItyD&1")
                            
                            def on_connect(client, userdata, flags, reason_code, properties):
                                _LOGGER.info(f"MQTT CONNECT: rc={reason_code}")
                                
                            def on_publish(client, userdata, mid, reason_code, properties):
                                _LOGGER.info(f"MQTT PUBLISH SUCCESS: mid={mid}")
                                
                            def on_disconnect(client, userdata, flags, reason_code, properties):
                                _LOGGER.info(f"MQTT DISCONNECT: rc={reason_code}")
                            
                            mqtt_client.on_connect = on_connect
                            mqtt_client.on_publish = on_publish
                            mqtt_client.on_disconnect = on_disconnect
                            
                            mqtt_client.connect("{MQTT_BROKER}", {MQTT_PORT}, 60)
                            
                            result = mqtt_client.publish("voicebm/transcript/full", json.dumps(msg), qos=1, retain=True)
                            
                            mqtt_client.loop_start()
                            result.wait_for_publish(timeout=5)
                            mqtt_client.loop_stop()
                            
                            mqtt_client.disconnect()
                            _LOGGER.info(f"MQTT COMPLETE: {modified_text.strip() if modified_text else ''}")
                        except Exception as e:
                            _LOGGER.error(f"MQTT FAILED: {e}", exc_info=True)

                    except Exception as e:
                        _LOGGER.error(f"RECOGNITION FAILED: {e}")
                        await self.write_event(Transcript(text="ERROR: Recognition failed").event())
                        return False

                # Cleanup shared audio file
                try:
                    os.unlink(shared_audio_path)
                except:
                    pass

                # Return transcript
                await self.write_event(Transcript(text=modified_text).event())
                self.request_language = None
                return False

            except Exception as e:
                _LOGGER.error(f"Voice biometrics error: {e}", exc_info=True)
                # On error, fall back to basic STT without identity
                
                waveform, sample_rate = sf.read(self._wav_path, dtype="float32")
                if len(waveform.shape) > 1:
                    waveform = np.mean(waveform, axis=1)

                lang = self.request_language or "en"
                model = self.models.get("en") or self.models.get("multi")
                
                if model:
                    async with self.model_lock:
                        text = model.recognize(waveform, language=lang, sample_rate=sample_rate)
                        # Fallback uses local inject state
                        if self.inject_identity_enabled:
                            await self.write_event(Transcript(text=f"user: {text}").event())
                        else:
                            await self.write_event(Transcript(text=text).event())
                else:
                    await self.write_event(Transcript(text="").event())
                
                self.request_language = None
                return False

        if Transcribe.is_type(event.type):
            transcribe = Transcribe.from_event(event)
            self.request_language = transcribe.language
            return True

        if Describe.is_type(event.type):
            await self.write_event(self.wyoming_info_event)
            return True

        return True



################################################################################
# FILE: manage_nodes.sh.template
# TYPE: script
################################################################################

#!/usr/bin/env bash
# ============================================================================
# VoiceBM Node Management Script
# ============================================================================
# List or remove passive recording nodes
#
# Usage: 
#   ./manage_nodes.sh list              # Show all nodes
#   ./manage_nodes.sh remove <room>     # Remove a node
#   ./manage_nodes.sh status            # Show status of all nodes
#
# ============================================================================

set -euo pipefail

# Configuration
VOICEBM_BASE="{VOICEBM_BASE}"
CONFIG_FILE="${VOICEBM_BASE}/config.json"
BIN_DIR="${VOICEBM_BASE}/bin"
SYSTEMD_DIR="/etc/systemd/system"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# Check if running as root for remove operations
if [[ "$1" == "remove" ]] && [[ $EUID -ne 0 ]]; then
   echo -e "${RED}âœ— Remove operation requires root (use sudo)${NC}"
   exit 1
fi

function list_nodes() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}VoiceBM Passive Nodes${NC}"
    echo -e "${BLUE}========================================${NC}\n"
    
    # Find all recorder services
    local found=0
    
    for service_file in ${SYSTEMD_DIR}/voicebm-recorder-*.service; do
        if [ -f "$service_file" ]; then
            found=1
            local service_name=$(basename "$service_file")
            local room_name=$(echo "$service_name" | sed 's/voicebm-recorder-//g' | sed 's/.service//g')
            
            local embedder_service="voicebm-embedder-${room_name}.service"
            
            # Check if recorder is active
            if systemctl is-active --quiet "$service_name"; then
                local rec_status="${GREEN}ACTIVE${NC}"
            else
                local rec_status="${RED}INACTIVE${NC}"
            fi
            
            # Check if embedder is active
            if systemctl is-active --quiet "$embedder_service"; then
                local emb_status="${GREEN}ACTIVE${NC}"
            else
                local emb_status="${RED}INACTIVE${NC}"
            fi
            
            # Check if enabled
            if systemctl is-enabled --quiet "$service_name" 2>/dev/null; then
                local rec_enabled="${GREEN}enabled${NC}"
            else
                local rec_enabled="${YELLOW}disabled${NC}"
            fi
            
            if systemctl is-enabled --quiet "$embedder_service" 2>/dev/null; then
                local emb_enabled="${GREEN}enabled${NC}"
            else
                local emb_enabled="${YELLOW}disabled${NC}"
            fi
            
            echo -e "  ${BLUE}â—${NC} ${room_name}"
            echo -e "    Recorder: ${rec_status} (${rec_enabled})"
            echo -e "    Embedder: ${emb_status} (${emb_enabled})"
            echo -e "    Scripts: rec_${room_name}.sh, embed_${room_name}.sh"
            
            # Count recordings and embeddings
            local rec_count=0
            local emb_count=0
            if [ -d "${VOICEBM_BASE}/recordings/${room_name}" ]; then
                rec_count=$(find "${VOICEBM_BASE}/recordings/${room_name}" -name "*.wav" 2>/dev/null | wc -l)
            fi
            if [ -d "${VOICEBM_BASE}/embeddings/${room_name}" ]; then
                emb_count=$(find "${VOICEBM_BASE}/embeddings/${room_name}" -name "*.txt" 2>/dev/null | wc -l)
            fi
            echo -e "    Files: ${rec_count} recordings, ${emb_count} embeddings\n"
        fi
    done
    
    if [ $found -eq 0 ]; then
        echo -e "${YELLOW}No passive nodes found.${NC}"
        echo -e "${YELLOW}Create one with: sudo ./replicate_node.sh <room_name>${NC}\n"
    fi
}

function show_status() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}VoiceBM Node Status${NC}"
    echo -e "${BLUE}========================================${NC}\n"
    
    for service_file in ${SYSTEMD_DIR}/voicebm-recorder-*.service; do
        if [ -f "$service_file" ]; then
            local service_name=$(basename "$service_file")
            systemctl status "$service_name" --no-pager -n 5
            echo -e "\n"
        fi
    done
}

function remove_node() {
    local room_name="$1"
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}Remove VoiceBM Node${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "Room: ${RED}${room_name}${NC}\n"
    
    local recorder_service="voicebm-recorder-${room_name}.service"
    local embedder_service="voicebm-embedder-${room_name}.service"
    local recorder_service_file="${SYSTEMD_DIR}/${recorder_service}"
    local embedder_service_file="${SYSTEMD_DIR}/${embedder_service}"
    local recorder_script="${BIN_DIR}/rec_${room_name}.sh"
    local embedder_script="${BIN_DIR}/embed_${room_name}.sh"
    
    # Check if node exists
    if [ ! -f "$recorder_service_file" ]; then
        echo -e "${RED}âœ— Node '${room_name}' does not exist${NC}"
        echo -e "${YELLOW}Use './manage_nodes.sh list' to see available nodes${NC}\n"
        exit 1
    fi
    
    # Confirm deletion
    echo -e "${YELLOW}âš  This will remove:${NC}"
    echo -e "  - Recorder service: ${recorder_service}"
    echo -e "  - Embedder service: ${embedder_service}"
    echo -e "  - Recorder script: ${recorder_script}"
    echo -e "  - Embedder script: ${embedder_script}"
    echo -e "  ${RED}(Recordings and embeddings will be preserved)${NC}\n"
    
    read -p "Continue? (yes/no): " confirm
    if [ "$confirm" != "yes" ]; then
        echo -e "\n${YELLOW}Cancelled${NC}\n"
        exit 0
    fi
    
    echo -e "\n${YELLOW}â†’${NC} Stopping services..."
    systemctl stop "$recorder_service" 2>/dev/null || true
    systemctl stop "$embedder_service" 2>/dev/null || true
    echo -e "${GREEN}âœ“${NC} Services stopped\n"
    
    echo -e "${YELLOW}â†’${NC} Disabling services..."
    systemctl disable "$recorder_service" 2>/dev/null || true
    systemctl disable "$embedder_service" 2>/dev/null || true
    echo -e "${GREEN}âœ“${NC} Services disabled\n"
    
    echo -e "${YELLOW}â†’${NC} Removing service files..."
    rm -f "$recorder_service_file"
    rm -f "$embedder_service_file"
    echo -e "${GREEN}âœ“${NC} Service files removed\n"
    
    echo -e "${YELLOW}â†’${NC} Removing scripts..."
    rm -f "$recorder_script"
    rm -f "$embedder_script"
    echo -e "${GREEN}âœ“${NC} Scripts removed\n"
    
    echo -e "${YELLOW}â†’${NC} Updating voicebm.target..."
    local target_file="${SYSTEMD_DIR}/voicebm.target"
    if [ -f "$target_file" ]; then
        sed -i "/Wants=voicebm-recorder-${room_name}.service/d" "$target_file"
        sed -i "/Wants=voicebm-embedder-${room_name}.service/d" "$target_file"
        echo -e "${GREEN}âœ“${NC} Removed from voicebm.target\n"
    fi
    
    echo -e "${YELLOW}â†’${NC} Reloading systemd..."
    systemctl daemon-reload
    echo -e "${GREEN}âœ“${NC} Systemd reloaded\n"
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}âœ“ Node Removed${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Note: Recordings and embeddings preserved at:${NC}"
    echo -e "  ${VOICEBM_BASE}/recordings/${room_name}/"
    echo -e "  ${VOICEBM_BASE}/embeddings/${room_name}/\n"
}

# Main
case "${1:-}" in
    list)
        list_nodes
        ;;
    status)
        show_status
        ;;
    remove)
        if [ $# -ne 2 ]; then
            echo -e "${RED}Usage: $0 remove <room_name>${NC}"
            exit 1
        fi
        remove_node "$2"
        ;;
    *)
        echo -e "${YELLOW}VoiceBM Node Management${NC}\n"
        echo -e "Usage:"
        echo -e "  $0 list              ${BLUE}# Show all nodes${NC}"
        echo -e "  $0 status            ${BLUE}# Show status of all nodes${NC}"
        echo -e "  $0 remove <room>     ${BLUE}# Remove a node${NC}\n"
        exit 1
        ;;
esac



################################################################################
# FILE: mqtt_commands.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""MQTT Command Listener for Voice Biometrics - Label/Reject Events

UPDATED: Now room-aware (handles all rooms with one service)
"""

import os
import json
import time
import datetime
import paho.mqtt.client as mqtt

# MQTT Configuration (centralized)
import sys
sys.path.insert(0, '{VOICEBM_BASE}')
from voicebm_config import get_mqtt_config

mqtt_config = get_mqtt_config()
BROKER = mqtt_config['broker']
PORT = mqtt_config['port']
USER = mqtt_config['user']
PASS = mqtt_config['password']

# Base directories (room-agnostic)
VOICEBM_BASE = "{VOICEBM_BASE}"
META_LAB = f"{VOICEBM_BASE}/meta/labeled"
ENROLL_DIR = f"{VOICEBM_BASE}/enroll"

# Subscribe to all rooms
LABEL_TOPIC_PATTERN = "voicebm/+/label"
REJECT_TOPIC_PATTERN = "voicebm/+/reject"

def iso_now():
    return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

def label_event(eid, person_id, room):
    """
    Label an event and enroll it to a person.
    
    Args:
        eid: Event ID
        person_id: Person identifier
        room: Room name (for finding files)
    """
    import shutil
    from pathlib import Path
    
    ts_label = int(time.time())
    expire_at = datetime.datetime.utcfromtimestamp(
        ts_label + 3*24*3600
    ).replace(microsecond=0).isoformat() + "Z"

    # Create labeled metadata
    os.makedirs(META_LAB, exist_ok=True)
    sidecar = os.path.join(META_LAB, f"{eid}.json")
    data = {
        "id": eid,
        "room": room,
        "status": "labeled",
        "person_id": person_id,
        "ts_labeled": iso_now(),
        "expire_at": expire_at
    }
    with open(sidecar, "w") as f:
        json.dump(data, f, indent=2)
    print(f"Labeled event {eid} from {room} as person {person_id}")

    # Create enrollment directory structure
    person_dir = Path(ENROLL_DIR) / person_id
    embeddings_dir = person_dir / "embeddings"
    recordings_dir = person_dir / "recordings"
    
    person_dir.mkdir(parents=True, exist_ok=True)
    embeddings_dir.mkdir(exist_ok=True)
    recordings_dir.mkdir(exist_ok=True)
    
    # Load existing metadata if it exists
    metadata_file = person_dir / 'metadata.json'
    if metadata_file.exists():
        with open(metadata_file, 'r') as f:
            metadata = json.load(f)
            existing_samples = metadata.get('samples', [])
    else:
        # Create display name from person_id
        display_name = person_id.replace('_', ' ').title()
        metadata = {
            'person_id': person_id,
            'display_name': display_name,
            'created_at': iso_now()
        }
        existing_samples = []
    
    # Source files (room-specific paths)
    rec_dir = f"{VOICEBM_BASE}/recordings/{room}"
    emb_dir = f"{VOICEBM_BASE}/embeddings/{room}"
    
    emb_src = Path(emb_dir) / f"{eid}.txt"
    rec_src = Path(rec_dir) / f"{eid}.wav"
    
    emb_dst = embeddings_dir / f"{eid}.txt"
    rec_dst = recordings_dir / f"{eid}.wav"
    
    # Calculate 3-day expiration for review period
    ts_enroll = int(time.time())
    expire_at = datetime.datetime.utcfromtimestamp(
        ts_enroll + 3*24*3600
    ).replace(microsecond=0).isoformat() + "Z"
    
    # MOVE embedding (not copy)
    if emb_src.exists() and not emb_dst.exists():
        try:
            shutil.move(str(emb_src), str(emb_dst))
            print(f"  âœ“ Moved embedding: {eid}.txt")
        except Exception as e:
            print(f"  âœ— Failed to move embedding: {e}")
    elif emb_dst.exists():
        print(f"  âš   Embedding already exists: {eid}.txt")
    else:
        print(f"  âœ— Embedding NOT FOUND at: {emb_src}")
    
    # MOVE recording (not copy)
    wav_moved = False
    if rec_src.exists():
        if not rec_dst.exists():
            try:
                shutil.move(str(rec_src), str(rec_dst))
                print(f"  âœ“ Moved recording: {eid}.wav")
                wav_moved = True
            except Exception as e:
                print(f"  âœ— Failed to move recording: {e}")
        else:
            print(f"  âš   Recording already exists: {eid}.wav")
            wav_moved = True
    else:
        print(f"  âœ— Recording NOT FOUND at: {rec_src}")
        print(f"     Looked in: {rec_dir}")
        print(f"     Event ID: {eid}")
    
    # Track sample in metadata
    sample_entry = {
        'event_id': eid,
        'embedding': f"embeddings/{eid}.txt",
        'recording': f"recordings/{eid}.wav" if wav_moved else None,
        'enrolled_at': iso_now(),
        'expire_at': expire_at,
        'retention_days': 3,
        'source_room': room
    }
    
    # Update metadata
    metadata['samples'] = existing_samples + [sample_entry]
    metadata['last_updated'] = iso_now()
    metadata['total_samples'] = len(metadata['samples'])
    
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"Enrolled to {person_id}, total samples: {metadata['total_samples']}")


def reject_event(eid, room):
    """Delete both .wav and .txt files for rejected event"""
    rec_dir = f"{VOICEBM_BASE}/recordings/{room}"
    emb_dir = f"{VOICEBM_BASE}/embeddings/{room}"
    
    deleted = []
    errors = []
    
    # Delete .wav file
    wav_path = os.path.join(rec_dir, f"{eid}.wav")
    if os.path.exists(wav_path):
        try:
            os.remove(wav_path)
            deleted.append(f"WAV: {wav_path}")
            print(f"  âœ“ Deleted: {wav_path}")
        except Exception as e:
            errors.append(f"WAV delete failed: {e}")
            print(f"  âœ— Failed to delete WAV: {e}")
    else:
        print(f"  âš   WAV not found: {wav_path}")
    
    # Delete .txt embedding file
    emb_path = os.path.join(emb_dir, f"{eid}.txt")
    if os.path.exists(emb_path):
        try:
            os.remove(emb_path)
            deleted.append(f"EMB: {emb_path}")
            print(f"  âœ“ Deleted: {emb_path}")
        except Exception as e:
            errors.append(f"EMB delete failed: {e}")
            print(f"  âœ— Failed to delete embedding: {e}")
    else:
        print(f"  âš   Embedding not found: {emb_path}")
    
    # Summary
    if deleted:
        print(f"Rejected event {eid} from {room} - deleted {len(deleted)} file(s)")
    if errors:
        print(f"Errors during rejection: {errors}")
    if not deleted and not errors:
        print(f"Rejected event {eid} from {room} - no files found to delete")

def on_connect(client, userdata, flags, reason_code, properties):
    if reason_code == 0:
        print(f"Connected to MQTT broker at {BROKER}:{PORT}")
        # Subscribe to all rooms
        client.subscribe([(LABEL_TOPIC_PATTERN, 1), (REJECT_TOPIC_PATTERN, 1)])
        print(f"Subscribed to:")
        print(f"  - {LABEL_TOPIC_PATTERN}")
        print(f"  - {REJECT_TOPIC_PATTERN}")
        print(f"Listening for commands from ALL rooms")
    else:
        print(f"Failed to connect, reason code: {reason_code}")

def on_message(client, userdata, msg):
    try:
        payload_str = msg.payload.decode("utf-8")
        
        # Extract room from topic: voicebm/{room}/label or voicebm/{room}/reject
        topic_parts = msg.topic.split('/')
        if len(topic_parts) < 3:
            print(f"  Error: Invalid topic format: {msg.topic}")
            return
        
        room = topic_parts[1]
        action = topic_parts[2]
        
        print(f"\nReceived on {msg.topic} (room={room}, action={action}):")
        print(f"  Payload: {payload_str}")
        
        p = json.loads(payload_str)
        eid = p.get("id")
        if not eid:
            print("  Error: No 'id' field in payload")
            return
            
        if action == "label":
            pid = p.get("person_id")
            if not pid:
                print("  Error: No 'person_id' field in label payload")
                return
            label_event(eid, pid, room)
        elif action == "reject":
            reject_event(eid, room)
        else:
            print(f"  Unknown action: {action}")
            
    except json.JSONDecodeError as e:
        print(f"  Error: Invalid JSON - {e}")
    except Exception as e:
        print(f"  Error processing message: {e}")
        import traceback
        traceback.print_exc()

def main():
    client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
    client.username_pw_set(USER, PASS)
    client.on_connect = on_connect
    client.on_message = on_message
    
    try:
        client.connect(BROKER, PORT, 60)
    except Exception as e:
        print(f"Connection failed: {e}")
        return
    
    print("=" * 60)
    print("VoiceBM MQTT Command Listener (Room-Aware)")
    print("=" * 60)
    print("Handles label/reject commands from ALL rooms")
    print("Press Ctrl+C to exit\n")
    
    try:
        client.loop_forever()
    except KeyboardInterrupt:
        print("\nShutting down...")
        client.disconnect()

if __name__ == "__main__":
    main()



################################################################################
# FILE: retention.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
VoiceBM Retention Service - Clean up expired WAV and embedding files

RULES:
- Unenrolled files past 3-day threshold: DELETE both WAV and embedding
- Rejected files: Already handled by mqtt_commands.py
- Enrolled files: WAV expires after 3 days, embedding stays PERMANENT (in enroll folder)

Files in recordings/living and embeddings/living are TEMPORARY.
Only files MOVED to enroll/{person}/ are permanent.
"""

import os
import json
import time
import datetime
import pathlib

ROOM = "living"
REC_DIR = f"{VOICEBM_BASE}/recordings/{ROOM}"
EMB_DIR = f"{VOICEBM_BASE}/embeddings/{ROOM}"
META_LAB = "{VOICEBM_BASE}/meta/labeled"
ENROLL_DIR = "{VOICEBM_BASE}/enroll"
RETENTION_SECONDS = 3 * 24 * 3600  # 3 days


def now():
    return int(time.time())


def parse_expire(sidecar):
    """Parse expiration timestamp from labeled sidecar JSON."""
    try:
        with open(sidecar, 'r') as f:
            j = json.load(f)
            expire_str = j.get("expire_at")
            if expire_str:
                return int(datetime.datetime.strptime(expire_str, "%Y-%m-%dT%H:%M:%SZ").timestamp())
    except:
        pass
    return None


def is_enrolled(eid):
    """Check if an event ID has been enrolled to any person."""
    enroll_path = pathlib.Path(ENROLL_DIR)
    if not enroll_path.exists():
        return False
    
    # Check each person's embeddings folder
    for person_dir in enroll_path.iterdir():
        if not person_dir.is_dir():
            continue
        
        emb_file = person_dir / "embeddings" / f"{eid}.txt"
        if emb_file.exists():
            return True
    
    return False


def delete_file(path, file_type):
    """Delete a file and log result."""
    try:
        if os.path.exists(path):
            os.remove(path)
            print(f"  âœ“ Deleted {file_type}: {os.path.basename(path)}")
            return True
    except Exception as e:
        print(f"  âœ— Failed to delete {file_type}: {e}")
    return False


def sweep_once():
    """
    Sweep recordings and embeddings directories.
    Delete expired unenrolled files.
    """
    current = now()
    deleted_wav = 0
    deleted_emb = 0
    
    rec_path = pathlib.Path(REC_DIR)
    emb_path = pathlib.Path(EMB_DIR)
    
    if not rec_path.exists():
        return
    
    # Process WAV files
    for wav in rec_path.glob("*.wav"):
        eid = wav.stem
        
        # Skip if enrolled (embedding was moved to person folder)
        if is_enrolled(eid):
            continue
        
        # Check sidecar for explicit expiration
        sidecar = os.path.join(META_LAB, f"{eid}.json")
        should_delete = False
        
        if os.path.exists(sidecar):
            exp = parse_expire(sidecar)
            if exp and current > exp:
                should_delete = True
        else:
            # No sidecar - use file mtime + 3 days
            try:
                mtime = int(wav.stat().st_mtime)
                if current - mtime > RETENTION_SECONDS:
                    should_delete = True
            except:
                pass
        
        if should_delete:
            print(f"Cleaning up: {eid}")
            
            # Delete WAV
            if delete_file(str(wav), "WAV"):
                deleted_wav += 1
            
            # Delete corresponding embedding
            emb_file = emb_path / f"{eid}.txt"
            if delete_file(str(emb_file), "EMB"):
                deleted_emb += 1
            
            # Delete sidecar if exists
            if os.path.exists(sidecar):
                delete_file(sidecar, "sidecar")
    
    # Also clean up orphan embeddings (embeddings without WAV files)
    if emb_path.exists():
        for emb in emb_path.glob("*.txt"):
            eid = emb.stem
            wav_file = rec_path / f"{eid}.wav"
            
            # Skip if enrolled
            if is_enrolled(eid):
                continue
            
            # If no WAV exists and embedding is old, delete it
            if not wav_file.exists():
                try:
                    mtime = int(emb.stat().st_mtime)
                    if current - mtime > RETENTION_SECONDS:
                        print(f"Cleaning orphan embedding: {eid}")
                        if delete_file(str(emb), "orphan EMB"):
                            deleted_emb += 1
                except:
                    pass
    
    if deleted_wav > 0 or deleted_emb > 0:
        print(f"Retention sweep complete: {deleted_wav} WAVs, {deleted_emb} embeddings deleted")


def main():
    print("=" * 60)
    print("VoiceBM Retention Service")
    print("=" * 60)
    print(f"Recordings: {REC_DIR}")
    print(f"Embeddings: {EMB_DIR}")
    print(f"Retention: {RETENTION_SECONDS // 3600} hours")
    print("=" * 60)
    print("Running retention sweep every 60 seconds...")
    print("Press Ctrl+C to exit\n")
    
    while True:
        try:
            sweep_once()
            time.sleep(60)
        except KeyboardInterrupt:
            print("\nShutting down...")
            break
        except Exception as e:
            print(f"Error in sweep: {e}")
            time.sleep(5)


if __name__ == "__main__":
    main()



################################################################################
# FILE: sherpa_embed.py
# TYPE: script
################################################################################

#!/usr/bin/env python3
import sys, wave, numpy as np
import sherpa_onnx

def load_wav_f32(path):
    with wave.open(path, "rb") as w:
        ch = w.getnchannels()
        sr = w.getframerate()
        sw = w.getsampwidth()
        n = w.getnframes()
        raw = w.readframes(n)

    # Supported widths: 16-bit or 32-bit PCM
    if sw == 2:
        pcm = np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0
    elif sw == 4:
        pcm = np.frombuffer(raw, dtype=np.int32).astype(np.float32) / 2147483648.0
    else:
        raise RuntimeError(f"Unsupported sample width: {sw} bytes")

    # Convert stereo â†’ mono
    if ch > 1:
        pcm = pcm.reshape(-1, ch).mean(axis=1)

    return sr, pcm

def main():
    args = sys.argv
    model = args[args.index("--model")+1]
    wav   = args[args.index("--wav")+1]
    out   = args[args.index("--out")+1]

    sr, pcm = load_wav_f32(wav)

    cfg = sherpa_onnx.SpeakerEmbeddingExtractorConfig(
        model=model,
        num_threads=1,
        debug=False
    )
    extractor = sherpa_onnx.SpeakerEmbeddingExtractor(cfg)

    stream = extractor.create_stream()
    stream.accept_waveform(sr, pcm)
    stream.input_finished()

    emb = extractor.compute(stream)

    with open(out, "w") as f:
        f.write(" ".join(str(x) for x in emb))

if __name__ == "__main__":
    main()



################################################################################
# FILE: stt-proxy.service.template
# TYPE: script
################################################################################

# /etc/systemd/system/stt-proxy.service
[Unit]
Description=OpenAI-compatible STT proxy
After=network.target

[Service]
Type=simple
WorkingDirectory=/opt/stt_proxy
Environment=DEFAULT_MODEL=quartznet
ExecStart=/opt/stt_proxy/.venv/bin/uvicorn proxy:app --host 10.50.60.58 --port 7077 --log-level debug
Restart=on-failure

[Install]
WantedBy=multi-user.target




################################################################################
# FILE: thing_engine.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
VoiceBM Thing Engine - Identity Transformation & Merging
Handles permanent identity operations: rename (transform) and merge

LLM Voice Biometrics by David M. Dryver Sr.
"""

import os
import sys
import json
import time
import shutil
import datetime
import subprocess
import zipfile
from pathlib import Path
import paho.mqtt.client as mqtt
import re

# Load configuration
sys.path.insert(0, '{VOICEBM_BASE}')
from voicebm_config import get_mqtt_config

# ============================================================================
# CONFIGURATION
# ============================================================================

VOICEBM_BASE = Path("{VOICEBM_BASE}")
ENROLL_DIR = VOICEBM_BASE / "enroll"
LOGS_DIR = VOICEBM_BASE / "logs"
THING_LOG = LOGS_DIR / "thing_engine.log"

# Load MQTT config dynamically
mqtt_config = get_mqtt_config()
MQTT_BROKER = mqtt_config['broker']
MQTT_PORT = mqtt_config['port']

# MQTT Topics
TOPIC_TRANSFORM = "voicebm/thing/transform"
TOPIC_MERGE_EXECUTE = "voicebm/thing/merge/execute"
TOPIC_MERGE_TAG_PREFIX = "voicebm/thing/merge/tag"
TOPIC_MERGE_TAGGED_COUNT = "voicebm/thing/merge/tagged_count"
TOPIC_MERGE_STATUS = "voicebm/thing/merge/status"

# Discovery prefix
DISCOVERY_PREFIX = "homeassistant"

# First-run detection marker
DISCOVERY_INITIALIZED_FILE = VOICEBM_BASE / "meta" / "discovery_initialized_thing_engine"

# Global state for merge tagging
tagged_identities = set()

# Global state for text inputs
transform_names = {}  # person_id -> new_name
merge_name = ""  # Name for merged identity


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def is_first_run():
    """Check if this is the first time discovery has been published."""
    return not DISCOVERY_INITIALIZED_FILE.exists()


def mark_initialized():
    """Mark that discovery has been initialized."""
    DISCOVERY_INITIALIZED_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(DISCOVERY_INITIALIZED_FILE, 'w') as f:
        f.write(time.strftime('%Y-%m-%d %H:%M:%S'))
    print("  Marked Thing Engine discovery as initialized")

def log_operation(operation: str, details: dict):
    """Log Thing Engine operations to file"""
    LOGS_DIR.mkdir(exist_ok=True)
    
    log_entry = {
        "timestamp": datetime.datetime.now().isoformat(),
        "operation": operation,
        **details
    }
    
    with open(THING_LOG, 'a') as f:
        f.write(json.dumps(log_entry) + "\n")
    
    print(f"[THING ENGINE] {operation}: {details}")


def normalize_person_id(name: str) -> str:
    """
    Normalize person name to person_id format.
    Same logic as enrollment_watcher and dashboard.
    """
    # Convert to lowercase
    normalized = name.lower()
    
    # Replace hyphens with underscores
    normalized = normalized.replace('-', '_')
    
    # Replace multiple spaces with single underscore
    normalized = re.sub(r'\s+', '_', normalized)
    
    # Collapse multiple underscores into single
    normalized = re.sub(r'_+', '_', normalized)
    
    # Strip leading/trailing underscores
    normalized = normalized.strip('_')
    
    return normalized


def validate_person_name(name: str) -> tuple[bool, str]:
    """
    Validate person name meets requirements.
    Returns (is_valid, error_message)
    """
    if not name:
        return False, "Name cannot be empty"
    
    if len(name) > 100:
        return False, "Name too long (max 100 characters)"
    
    # Must start and end with letter
    if not name[0].isalpha():
        return False, "Name must start with a letter"
    if not name[-1].isalpha():
        return False, "Name must end with a letter"
    
    # Check for invalid characters (allow letters, spaces, hyphens, underscores)
    if not re.match(r'^[A-Za-z][A-Za-z0-9\s\-_]*[A-Za-z]$', name):
        return False, "Name can only contain letters, spaces, hyphens, and underscores"
    
    return True, ""


def person_exists(person_id: str) -> bool:
    """Check if person directory exists"""
    return (ENROLL_DIR / person_id).exists()


def get_person_metadata(person_id: str) -> dict:
    """Load person metadata.json"""
    metadata_file = ENROLL_DIR / person_id / "metadata.json"
    if metadata_file.exists():
        with open(metadata_file, 'r') as f:
            return json.load(f)
    return {}


def update_person_metadata(person_id: str, metadata: dict):
    """Update person metadata.json"""
    metadata_file = ENROLL_DIR / person_id / "metadata.json"
    metadata_file.parent.mkdir(parents=True, exist_ok=True)
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f, indent=2)


def restart_enrollment_watcher(client):
    """
    Restart enrollment_watcher service to force complete republish.
    
    enrollment_watcher now publishes ALL entities (Voice, Blocklist, Threshold, Delete, Thing Engine)
    so we just need to restart the service and it handles everything.
    """
    print("[THING ENGINE] Restarting enrollment_watcher service...")
    try:
        result = subprocess.run(
            ['systemctl', 'restart', 'voicebm-enrollment-watcher'],
            capture_output=True,
            text=True,
            timeout=5
        )
        if result.returncode == 0:
            print("[THING ENGINE] âœ“ Successfully restarted enrollment_watcher service")
            time.sleep(3)  # Give it time to republish all devices
        else:
            print(f"[THING ENGINE] âš ï¸  Warning: Failed to restart enrollment_watcher")
            print(f"[THING ENGINE] Error: {result.stderr}")
            print(f"[THING ENGINE] You may need to restart manually")
    except subprocess.TimeoutExpired:
        print(f"[THING ENGINE] âš ï¸  Warning: Restart command timed out")
    except Exception as e:
        print(f"[THING ENGINE] âš ï¸  Warning: Error restarting enrollment_watcher: {e}")


# ============================================================================
# TRANSFORM OPERATION (Rename Identity)
# ============================================================================

def transform_identity(client, old_person_id: str, new_display_name: str) -> tuple[bool, str]:
    """
    Transform (rename) a person's identity permanently.
    
    Steps:
    1. Validate inputs
    2. Normalize new person_id
    3. Rename directory
    4. Update metadata.json
    5. Trigger MQTT discovery republish
    6. Log operation
    
    Returns:
        (success, message)
    """
    print(f"\n[TRANSFORM] Renaming '{old_person_id}' to '{new_display_name}'")
    
    # Validate old person exists
    if not person_exists(old_person_id):
        error = f"Person '{old_person_id}' does not exist"
        log_operation("transform_failed", {
            "old_id": old_person_id,
            "new_name": new_display_name,
            "error": error
        })
        return False, error
    
    # Validate new name
    is_valid, error_msg = validate_person_name(new_display_name)
    if not is_valid:
        log_operation("transform_failed", {
            "old_id": old_person_id,
            "new_name": new_display_name,
            "error": error_msg
        })
        return False, error_msg
    
    # Normalize new person_id
    new_person_id = normalize_person_id(new_display_name)
    
    # Check if new person_id already exists (but allow same as old for display name changes)
    if new_person_id != old_person_id and person_exists(new_person_id):
        error = f"Person '{new_person_id}' already exists"
        log_operation("transform_failed", {
            "old_id": old_person_id,
            "new_id": new_person_id,
            "new_name": new_display_name,
            "error": error
        })
        return False, error
    
    try:
        old_dir = ENROLL_DIR / old_person_id
        
        # If only display name is changing (person_id stays same), just update metadata
        if old_person_id == new_person_id:
            print(f"  Display name only change: {old_person_id} -> {new_display_name}")
            metadata = get_person_metadata(old_person_id)
            metadata['display_name'] = new_display_name
            metadata['last_modified'] = datetime.datetime.now().isoformat()
            metadata['modified_by'] = 'thing_engine'
            update_person_metadata(old_person_id, metadata)
            
            # Restart enrollment_watcher to update HA device name
            restart_enrollment_watcher(client)
        else:
            # Full identity transformation with delete
            print(f"  Full identity transformation: {old_person_id} -> {new_person_id}")
            
            # 1. Update metadata.json IN PLACE (before zipping)
            print(f"  Updating metadata in source directory...")
            metadata = get_person_metadata(old_person_id)
            metadata['person_id'] = new_person_id
            metadata['display_name'] = new_display_name
            metadata['previous_id'] = old_person_id
            metadata['last_modified'] = datetime.datetime.now().isoformat()
            metadata['modified_by'] = 'thing_engine'
            update_person_metadata(old_person_id, metadata)
            
            # 2. Create zip backup with NEW name (metadata already correct inside)
            zip_path = ENROLL_DIR / f"{new_person_id}.zip"
            print(f"  Creating backup: {zip_path.name}")
            
            try:
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for item in old_dir.rglob('*'):
                        if item.is_file():
                            arcname = item.relative_to(old_dir)
                            zipf.write(item, arcname)
                
                # 3. Enable delete for old person_id
                print(f"  Enabling delete for: {old_person_id}")
                client.publish(
                    f"voicebm/identity/{old_person_id}/enable_delete/set",
                    "ON",
                    qos=1,
                    retain=False
                )
                time.sleep(0.5)
                
                # 4. Trigger delete
                print(f"  Deleting old identity: {old_person_id}")
                client.publish(
                    f"voicebm/identity/{old_person_id}/delete",
                    "PRESS",
                    qos=1,
                    retain=False
                )
                
                # 5. Wait and check metadata.json (more reliable than checking directory)
                print(f"  Waiting 3 seconds...")
                time.sleep(3)
                
                metadata_file = old_dir / "metadata.json"
                if metadata_file.exists():
                    print(f"  metadata.json still exists, waiting 5 more seconds...")
                    time.sleep(5)
                    # Trust it's gone after 8 seconds total
                    print(f"  Proceeding (trusting deletion completed)")
                else:
                    print(f"  Deletion confirmed (metadata.json gone)")
                
                # 6. Unzip directly to enroll directory (metadata already correct)
                new_dir = ENROLL_DIR / new_person_id
                print(f"  Extracting backup...")
                with zipfile.ZipFile(zip_path, 'r') as zipf:
                    zipf.extractall(new_dir)
                
            except Exception as e:
                # Backup preserved on failure
                if zip_path.exists():
                    print(f"  ERROR: Backup preserved at {zip_path}")
                raise e
            
            # 7. Restart enrollment_watcher (sees new directory, publishes all entities)
            restart_enrollment_watcher(client)
            
            # 8. Delete backup zip after successful completion
            if zip_path.exists():
                zip_path.unlink()
                print(f"  âœ“ Cleaned up backup zip")
        
        # Log success
        log_operation("transform_success", {
            "old_id": old_person_id,
            "new_id": new_person_id,
            "new_display_name": new_display_name
        })
        
        print(f"  âœ“ Transform complete: {old_person_id} -> {new_person_id}")
        return True, f"Successfully renamed to '{new_display_name}'"
    
    except Exception as e:
        error = f"Transform failed: {str(e)}"
        log_operation("transform_error", {
            "old_id": old_person_id,
            "new_name": new_display_name,
            "error": str(e)
        })
        return False, error


# ============================================================================
# MERGE OPERATION (Combine Identities)
# ============================================================================

def merge_identities(client, source_ids: list, new_display_name: str) -> tuple[bool, str]:
    """
    Merge multiple identities into one new identity.
    
    Steps:
    1. Validate inputs
    2. Create new identity directory
    3. Copy all embeddings from source identities
    4. Copy all audio files from source identities
    5. Delete source identity directories
    6. Trigger MQTT discovery republish
    7. Log operation
    
    Returns:
        (success, message)
    """
    print(f"\n[MERGE] Combining {len(source_ids)} identities into '{new_display_name}'")
    print(f"  Sources: {', '.join(source_ids)}")
    
    # Validate at least 2 sources
    if len(source_ids) < 2:
        error = "Must select at least 2 identities to merge"
        log_operation("merge_failed", {
            "sources": source_ids,
            "new_name": new_display_name,
            "error": error
        })
        return False, error
    
    # Validate all sources exist
    for source_id in source_ids:
        if not person_exists(source_id):
            error = f"Source identity '{source_id}' does not exist"
            log_operation("merge_failed", {
                "sources": source_ids,
                "new_name": new_display_name,
                "error": error
            })
            return False, error
    
    # Validate new name
    is_valid, error_msg = validate_person_name(new_display_name)
    if not is_valid:
        log_operation("merge_failed", {
            "sources": source_ids,
            "new_name": new_display_name,
            "error": error_msg
        })
        return False, error_msg
    
    # Normalize new person_id
    new_person_id = normalize_person_id(new_display_name)
    
    # Check if new person_id already exists
    if person_exists(new_person_id):
        error = f"Person '{new_person_id}' already exists"
        log_operation("merge_failed", {
            "sources": source_ids,
            "new_id": new_person_id,
            "new_name": new_display_name,
            "error": error
        })
        return False, error
    
    try:
        # Create new identity directory structure
        new_dir = ENROLL_DIR / new_person_id
        new_dir.mkdir(parents=True, exist_ok=True)
        embeddings_dir = new_dir / "embeddings"
        embeddings_dir.mkdir(exist_ok=True)
        
        # Create metadata for merged identity
        metadata = {
            "person_id": new_person_id,
            "display_name": new_display_name,
            "created": datetime.datetime.now().isoformat(),
            "source": "thing_engine_merge",
            "merged_from": source_ids,
            "blocked": False
        }
        update_person_metadata(new_person_id, metadata)
        
        # Copy embeddings and audio from all sources
        total_embeddings = 0
        total_audio = 0
        
        for source_id in source_ids:
            source_dir = ENROLL_DIR / source_id
            
            # Copy embeddings
            source_embeddings = source_dir / "embeddings"
            if source_embeddings.exists():
                for emb_file in source_embeddings.glob("*.txt"):
                    # Rename to new person_id
                    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                    new_filename = f"{new_person_id}_{timestamp}_{total_embeddings}.txt"
                    shutil.copy2(emb_file, embeddings_dir / new_filename)
                    total_embeddings += 1
            
            # Copy audio files
            for audio_file in source_dir.glob("*.wav"):
                timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                new_filename = f"{new_person_id}_{timestamp}_{total_audio}.wav"
                shutil.copy2(audio_file, new_dir / new_filename)
                total_audio += 1
        
        print(f"  Copied {total_embeddings} embeddings, {total_audio} audio files")
        
        # Delete source identities via MQTT (two-step safety)
        for source_id in source_ids:
            print(f"  Deleting source: {source_id}")
            
            # Enable delete
            client.publish(
                f"voicebm/identity/{source_id}/enable_delete/set",
                "ON",
                qos=1,
                retain=False
            )
            time.sleep(0.5)
            
            # Trigger delete
            client.publish(
                f"voicebm/identity/{source_id}/delete",
                "PRESS",
                qos=1,
                retain=False
            )
            
            # Wait and check metadata.json (same logic as transform)
            print(f"  Waiting 3 seconds...")
            time.sleep(3)
            
            source_dir = ENROLL_DIR / source_id
            metadata_file = source_dir / "metadata.json"
            if metadata_file.exists():
                print(f"  metadata.json still exists for {source_id}, waiting 5 more seconds...")
                time.sleep(5)
                print(f"  Proceeding (trusting deletion completed)")
            else:
                print(f"  Deletion confirmed for {source_id}")
        
        # Restart enrollment_watcher (sees new merged identity, publishes all entities)
        restart_enrollment_watcher(client)
        
        # Log success
        log_operation("merge_success", {
            "sources": source_ids,
            "new_id": new_person_id,
            "new_display_name": new_display_name,
            "embeddings_count": total_embeddings,
            "audio_count": total_audio
        })
        
        print(f"  âœ“ Merge complete: {new_person_id} created from {len(source_ids)} sources")
        return True, f"Successfully merged into '{new_display_name}' ({total_embeddings} samples)"
    
    except Exception as e:
        error = f"Merge failed: {str(e)}"
        log_operation("merge_error", {
            "sources": source_ids,
            "new_name": new_display_name,
            "error": str(e)
        })
        return False, error


# ============================================================================
# MQTT HANDLERS
# ============================================================================

def handle_transform_name_input(client, userdata, msg):
    """
    Handle transform name text input changes.
    Stores the new name for when button is pressed.
    """
    global transform_names
    
    try:
        # Extract person_id from topic: voicebm/thing/transform/{person_id}/name/set
        parts = msg.topic.split('/')
        person_id = parts[3]
        new_name = msg.payload.decode('utf-8').strip()
        
        transform_names[person_id] = new_name
        
        # Echo back to state topic
        client.publish(f"voicebm/thing/transform/{person_id}/name", new_name, qos=1, retain=True)
        print(f"[TRANSFORM NAME] {person_id} -> {new_name}")
        
    except Exception as e:
        print(f"[TRANSFORM NAME] Error: {e}")


def handle_transform_execute(client, userdata, msg):
    """
    Handle transform execute button press.
    Uses stored name from text input.
    """
    global transform_names
    
    try:
        # Extract person_id from topic: voicebm/thing/transform/{person_id}/execute
        parts = msg.topic.split('/')
        person_id = parts[3]
        
        # Get stored new name
        new_display_name = transform_names.get(person_id, "").strip()
        
        if not new_display_name:
            print(f"[TRANSFORM] No name set for {person_id}")
            status = {
                "operation": "transform",
                "success": False,
                "message": "Please enter a new name first",
                "timestamp": datetime.datetime.now().isoformat()
            }
            client.publish(TOPIC_MERGE_STATUS, json.dumps(status), qos=1, retain=True)
            return
        
        success, message = transform_identity(client, person_id, new_display_name)
        
        # Clear stored name on success
        if success:
            transform_names.pop(person_id, None)
            client.publish(f"voicebm/thing/transform/{person_id}/name", "", qos=1, retain=True)
        
        # Publish status
        status = {
            "operation": "transform",
            "person": person_id,
            "success": success,
            "message": message,
            "timestamp": datetime.datetime.now().isoformat()
        }
        client.publish(TOPIC_MERGE_STATUS, json.dumps(status), qos=1, retain=True)
        
    except Exception as e:
        print(f"[TRANSFORM EXECUTE] Error: {e}")


def handle_merge_tag(client, userdata, msg):
    """
    Handle merge tag switch changes.
    Tracks which identities are tagged for merging.
    """
    global tagged_identities
    
    try:
        # Extract person_id from topic: voicebm/thing/merge/tag/{person_id}/set
        parts = msg.topic.split('/')
        person_id = parts[-2]  # Second to last element
        state = msg.payload.decode('utf-8').upper()
        
        if state == "ON":
            tagged_identities.add(person_id)
            print(f"[MERGE TAG] Added: {person_id} (total: {len(tagged_identities)})")
        elif state == "OFF":
            tagged_identities.discard(person_id)
            print(f"[MERGE TAG] Removed: {person_id} (total: {len(tagged_identities)})")
        
        # Echo back to state topic
        client.publish(f"voicebm/thing/merge/tag/{person_id}", state, qos=1, retain=True)
        
        # Publish updated count
        client.publish(TOPIC_MERGE_TAGGED_COUNT, str(len(tagged_identities)), qos=1, retain=True)
        
    except Exception as e:
        print(f"[MERGE TAG] Error: {e}")


def handle_merge_name_input(client, userdata, msg):
    """
    Handle merge name text input changes.
    Stores the name for when merge button is pressed.
    """
    global merge_name
    
    try:
        merge_name = msg.payload.decode('utf-8').strip()
        
        # Echo back to state topic
        client.publish("voicebm/thing/merge/name", merge_name, qos=1, retain=True)
        print(f"[MERGE NAME] Set to: {merge_name}")
        
    except Exception as e:
        print(f"[MERGE NAME] Error: {e}")


def handle_merge_execute(client, userdata, msg):
    """
    Handle merge execution button press.
    Uses globally tracked tagged_identities and merge_name.
    """
    global tagged_identities, merge_name
    
    try:
        if not merge_name.strip():
            print("[MERGE] No name set for merged identity")
            status = {
                "operation": "merge",
                "success": False,
                "message": "Please enter a name for the merged identity",
                "timestamp": datetime.datetime.now().isoformat()
            }
            client.publish(TOPIC_MERGE_STATUS, json.dumps(status), qos=1, retain=True)
            return
        
        if len(tagged_identities) < 2:
            print("[MERGE] Not enough identities tagged (need at least 2)")
            status = {
                "operation": "merge",
                "success": False,
                "message": f"Need at least 2 identities tagged (currently {len(tagged_identities)})",
                "timestamp": datetime.datetime.now().isoformat()
            }
            client.publish(TOPIC_MERGE_STATUS, json.dumps(status), qos=1, retain=True)
            return
        
        # Convert set to list for merge
        source_ids = list(tagged_identities)
        
        success, message = merge_identities(client, source_ids, merge_name)
        
        # Clear tagged identities and merge name on success
        if success:
            tagged_identities.clear()
            merge_name = ""
            client.publish(TOPIC_MERGE_TAGGED_COUNT, "0", qos=1, retain=True)
            client.publish("voicebm/thing/merge/name", "", qos=1, retain=True)
            
            # Clear all tag switches
            for person_id in source_ids:
                client.publish(f"voicebm/thing/merge/tag/{person_id}", "OFF", qos=1, retain=True)
        
        # Publish status
        status = {
            "operation": "merge",
            "success": success,
            "message": message,
            "sources": source_ids,
            "timestamp": datetime.datetime.now().isoformat()
        }
        client.publish(TOPIC_MERGE_STATUS, json.dumps(status), qos=1, retain=True)
        
    except Exception as e:
        print(f"[MERGE] Error: {e}")


def remove_person_thing_entities(client, person_id: str):
    """
    Remove Thing Engine entities for a person by publishing empty config.
    Called before transform to clean up old person_id's entities.
    """
    # Remove transform text input
    client.publish(
        f"{DISCOVERY_PREFIX}/text/{person_id}_transform_name/config",
        "",
        qos=1,
        retain=True
    )
    
    # Remove transform button
    client.publish(
        f"{DISCOVERY_PREFIX}/button/{person_id}_transform_execute/config",
        "",
        qos=1,
        retain=True
    )
    
    # Remove merge tag switch
    client.publish(
        f"{DISCOVERY_PREFIX}/switch/{person_id}_merge_tag/config",
        "",
        qos=1,
        retain=True
    )
    
    print(f"[THING ENGINE] Removed Thing Engine entities for: {person_id}")


def publish_person_thing_entities(client, person_id: str, display_name: str):
    """
    Publish Thing Engine entities for a specific person.
    Called when enrollment is refreshed.
    """
    device = {
        "identifiers": [person_id],
        "name": display_name,
        "manufacturer": "VoiceBM by David M. Dryver Sr.",
        "model": "Person"
    }
    
    # Transform Name Text Input
    transform_name_config = {
        "name": "New Identity Name",
        "unique_id": f"{person_id}_transform_name",
        "command_topic": f"voicebm/thing/transform/{person_id}/name/set",
        "state_topic": f"voicebm/thing/transform/{person_id}/name",
        "mode": "text",
        "icon": "mdi:rename-box",
        "device": device
    }
    client.publish(
        f"{DISCOVERY_PREFIX}/text/{person_id}_transform_name/config",
        json.dumps(transform_name_config),
        qos=1,
        retain=True
    )
    
    # Transform Execute Button
    transform_button_config = {
        "name": "Rename Identity",
        "unique_id": f"{person_id}_transform_execute",
        "command_topic": f"voicebm/thing/transform/{person_id}/execute",
        "payload_press": "PRESS",
        "icon": "mdi:account-convert",
        "device": device
    }
    client.publish(
        f"{DISCOVERY_PREFIX}/button/{person_id}_transform_execute/config",
        json.dumps(transform_button_config),
        qos=1,
        retain=True
    )
    
    # Merge Tag Switch
    merge_tag_config = {
        "name": "Tag for Merge",
        "unique_id": f"{person_id}_merge_tag",
        "command_topic": f"voicebm/thing/merge/tag/{person_id}/set",
        "state_topic": f"voicebm/thing/merge/tag/{person_id}",
        "payload_on": "ON",
        "payload_off": "OFF",
        "icon": "mdi:tag-multiple",
        "device": device
    }
    client.publish(
        f"{DISCOVERY_PREFIX}/switch/{person_id}_merge_tag/config",
        json.dumps(merge_tag_config),
        qos=1,
        retain=True
    )
    
    # Publish initial states for new entities
    client.publish(f"voicebm/thing/transform/{person_id}/name", "", qos=1, retain=True)
    client.publish(f"voicebm/thing/merge/tag/{person_id}", "OFF", qos=1, retain=True)


def scan_and_publish_person_entities(client):
    """
    Scan enrollment directory and publish Thing Engine entities for all persons.
    Thing Engine adds transform/merge controls to person devices created by enrollment_watcher.
    """
    if not ENROLL_DIR.exists():
        print(f"[THING ENGINE] Enrollment directory not found: {ENROLL_DIR}")
        return
    
    person_count = 0
    
    for person_dir in ENROLL_DIR.iterdir():
        if not person_dir.is_dir():
            continue
        
        person_id = person_dir.name
        
        # Load display name from metadata
        metadata_file = person_dir / "metadata.json"
        display_name = person_id
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    display_name = metadata.get('display_name', person_id)
            except:
                pass
        
        publish_person_thing_entities(client, person_id, display_name)
        person_count += 1
    
    print(f"[THING ENGINE] Published entities for {person_count} persons")


def publish_discovery(client):
    """Publish Home Assistant MQTT Discovery for Thing Engine system entities."""
    device = {
        "identifiers": ["voicebm_thing_engine"],
        "name": "VoiceBM Thing Engine",
        "model": "Identity Transformation & Merge",
        "manufacturer": "VoiceBM by David M. Dryver Sr."
    }
    
    # Merge Tagged Count Sensor
    tagged_count_config = {
        "name": "Merge Tagged Count",
        "unique_id": "voicebm_thing_tagged_count",
        "state_topic": "voicebm/thing/merge/tagged_count",
        "icon": "mdi:counter",
        "device": device
    }
    client.publish(
        f"{DISCOVERY_PREFIX}/sensor/voicebm_thing_tagged_count/config",
        json.dumps(tagged_count_config),
        qos=1,
        retain=True
    )
    
    # Merge Status Sensor
    status_config = {
        "name": "Thing Engine Status",
        "unique_id": "voicebm_thing_status",
        "state_topic": "voicebm/thing/merge/status",
        "value_template": "{{ value_json.message | default('Ready') }}",
        "json_attributes_topic": "voicebm/thing/merge/status",
        "icon": "mdi:state-machine",
        "device": device
    }
    client.publish(
        f"{DISCOVERY_PREFIX}/sensor/voicebm_thing_status/config",
        json.dumps(status_config),
        qos=1,
        retain=True
    )
    
    # Merge Name Text Input
    merge_name_config = {
        "name": "New Merged Identity Name",
        "unique_id": "voicebm_thing_merge_name",
        "command_topic": "voicebm/thing/merge/name/set",
        "state_topic": "voicebm/thing/merge/name",
        "mode": "text",
        "icon": "mdi:form-textbox",
        "device": device
    }
    client.publish(
        f"{DISCOVERY_PREFIX}/text/voicebm_thing_merge_name/config",
        json.dumps(merge_name_config),
        qos=1,
        retain=True
    )
    
    # Merge Execute Button
    merge_button_config = {
        "name": "Execute Merge",
        "unique_id": "voicebm_thing_merge_execute",
        "command_topic": "voicebm/thing/merge/execute/trigger",
        "payload_press": "PRESS",
        "icon": "mdi:merge",
        "device": device
    }
    client.publish(
        f"{DISCOVERY_PREFIX}/button/voicebm_thing_merge_execute/config",
        json.dumps(merge_button_config),
        qos=1,
        retain=True
    )
    
    print("[THING ENGINE] Published system entity discovery configs")


def on_connect(client, userdata, flags, reason_code, properties):
    """MQTT connection callback"""
    if reason_code == 0:
        print("[THING ENGINE] Connected to MQTT broker")
        
        # Publish discovery first
        publish_discovery(client)
        
        # Subscribe to command topics
        client.subscribe("voicebm/thing/transform/+/name/set")  # Per-person name input
        client.subscribe("voicebm/thing/transform/+/execute")  # Per-person transform button
        client.subscribe("voicebm/thing/merge/name/set")  # Merge name input
        client.subscribe("voicebm/thing/merge/execute/trigger")  # Merge button
        client.subscribe(f"{TOPIC_MERGE_TAG_PREFIX}/+/set")  # Tag switches
        
        # Check if this is first run
        first_run = is_first_run()
        
        if first_run:
            print("[THING ENGINE] First run detected - will publish initial states")
        else:
            print("[THING ENGINE] Subsequent run - respecting HA state")
        
        # ONLY publish initial state on first run
        # Subsequent runs preserve HA's retained state
        if first_run:
            client.publish(TOPIC_MERGE_TAGGED_COUNT, "0", qos=1, retain=True)
            client.publish("voicebm/thing/merge/name", "", qos=1, retain=True)
            client.publish(TOPIC_MERGE_STATUS, json.dumps({
                "status": "ready",
                "message": "Ready",
                "timestamp": datetime.datetime.now().isoformat()
            }), qos=1, retain=True)
            print("[THING ENGINE] Published initial states")
            mark_initialized()
        
        # Scan and publish Thing Engine entities for all persons
        # This adds transform/merge controls to devices created by enrollment_watcher
        scan_and_publish_person_entities(client)
        
        print("[THING ENGINE] Subscriptions active")
        print("  - Transform name inputs: voicebm/thing/transform/+/name/set")
        print("  - Transform buttons: voicebm/thing/transform/+/execute")
        print("  - Merge name input: voicebm/thing/merge/name/set")
        print("  - Merge button: voicebm/thing/merge/execute/trigger")
        print("  - Tag switches: voicebm/thing/merge/tag/+/set")
    else:
        print(f"[THING ENGINE] Connection failed with reason code {reason_code}")


def on_message(client, userdata, msg):
    """MQTT message router"""
    try:
        topic = msg.topic
        
        if topic.startswith("voicebm/thing/transform/") and topic.endswith("/name/set"):
            handle_transform_name_input(client, userdata, msg)
        elif topic.startswith("voicebm/thing/transform/") and topic.endswith("/execute"):
            handle_transform_execute(client, userdata, msg)
        elif topic == "voicebm/thing/merge/name/set":
            handle_merge_name_input(client, userdata, msg)
        elif topic == "voicebm/thing/merge/execute/trigger":
            handle_merge_execute(client, userdata, msg)
        elif topic.startswith(TOPIC_MERGE_TAG_PREFIX) and topic.endswith("/set"):
            handle_merge_tag(client, userdata, msg)
    except Exception as e:
        print(f"[THING ENGINE] Message handler error: {e}")


# ============================================================================
# MAIN
# ============================================================================

def main():
    """Main Thing Engine service loop"""
    print("=" * 70)
    print("VoiceBM Thing Engine - Identity Transformation & Merging")
    print("LLM Voice Biometrics by David M. Dryver Sr.")
    print("=" * 70)
    print(f"Enrollment directory: {ENROLL_DIR}")
    print(f"Logs directory: {LOGS_DIR}")
    print(f"MQTT Broker: {MQTT_BROKER}:{MQTT_PORT}")
    print()
    
    # Ensure directories exist
    ENROLL_DIR.mkdir(exist_ok=True)
    LOGS_DIR.mkdir(exist_ok=True)
    
    # Setup MQTT client
    client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
    if mqtt_config.get('user') and mqtt_config.get('password'):
        client.username_pw_set(mqtt_config['user'], mqtt_config['password'])
    client.on_connect = on_connect
    client.on_message = on_message
    
    print(f"Connecting to MQTT broker at {MQTT_BROKER}:{MQTT_PORT}...")
    client.connect(MQTT_BROKER, MQTT_PORT, 60)
    
    print("Thing Engine running. Press Ctrl+C to stop.")
    print()
    
    # Start MQTT loop
    try:
        client.loop_forever()
    except KeyboardInterrupt:
        print("\n[THING ENGINE] Shutting down...")
        client.disconnect()


if __name__ == "__main__":
    main()



################################################################################
# FILE: vad_filter.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""VAD Filter Service - Removes silence/noise files before embedding

FIXED: Now watches ALL room directories under recordings/
- Scans recordings/*/ for all rooms
- Processes any .wav without corresponding .txt in embeddings/
- One global service handles all passive nodes
"""

import os
import sys
import time
import wave
import torch
import logging
from pathlib import Path

# Configuration
RECORDINGS_BASE = Path("{VOICEBM_BASE}/recordings")
EMBEDDINGS_BASE = Path("{VOICEBM_BASE}/embeddings")
LOG_FILE = Path("{VOICEBM_BASE}/meta/vad_filter.log")
STATS_FILE = Path("{VOICEBM_BASE}/meta/vad_stats.json")

# VAD Thresholds (adjust these to tune filtering)
MIN_SPEECH_DURATION = 0.8   # seconds - file must have at least this much speech
SPEECH_THRESHOLD = 0.5       # VAD confidence (0.0-1.0, higher = stricter)
MIN_SPEECH_RATIO = 0.15      # 15% of file must be speech (helps with short files)

# Safety settings
MIN_FILE_AGE_SECONDS = 10    # Don't process files younger than this (ffmpeg still writing)
MIN_FILE_SIZE_BYTES = 1000   # Skip files smaller than this (corrupt/incomplete)

# Setup logging
os.makedirs(LOG_FILE.parent, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler(sys.stdout)
    ]
)

# Load Silero VAD model
logging.info("Loading Silero VAD model...")
# DISABLED: # torch.set_num_threads(1)  # Not available in all torch builds
model = None
get_speech_timestamps = None
read_audio = None

try:
    model, utils = torch.hub.load(
        repo_or_dir='snakers4/silero-vad',
        model='silero_vad',
        force_reload=False,
        onnx=False  # Use PyTorch version
    )
    (get_speech_timestamps, _, read_audio, _, _) = utils
    logging.info("Silero VAD model loaded successfully")
except Exception as e:
    logging.error(f"Failed to load Silero VAD: {e}")
    sys.exit(1)


def get_file_age_seconds(wav_path):
    """Get age of file in seconds"""
    try:
        mtime = wav_path.stat().st_mtime
        return time.time() - mtime
    except:
        return 0


def is_valid_wav(wav_path):
    """
    Check if WAV file can be opened and has valid audio data.
    Returns: (valid: bool, duration: float, error_msg: str or None)
    """
    try:
        with wave.open(str(wav_path), 'rb') as wf:
            frames = wf.getnframes()
            rate = wf.getframerate()
            channels = wf.getnchannels()
            
            if rate <= 0 or frames <= 0 or channels <= 0:
                return False, 0.0, "invalid WAV header"
            
            duration = frames / float(rate)
            
            if duration < 0.1:  # Less than 100ms is useless
                return False, duration, "too short"
            
            return True, duration, None
    except wave.Error as e:
        return False, 0.0, f"WAV error: {e}"
    except Exception as e:
        return False, 0.0, f"read error: {e}"


def has_sufficient_speech(wav_path):
    """
    Check if audio file contains sufficient speech.
    Returns: (keep_file: bool, speech_duration: float, total_duration: float)
    """
    try:
        # Read audio (Silero expects 16kHz)
        wav = read_audio(str(wav_path), sampling_rate=16000)
        total_duration = len(wav) / 16000.0
        
        # Get speech timestamps
        speech_timestamps = get_speech_timestamps(
            wav,
            model,
            threshold=SPEECH_THRESHOLD,
            sampling_rate=16000,
            return_seconds=True
        )
        
        if not speech_timestamps:
            return False, 0.0, total_duration
        
        # Calculate total speech duration
        speech_duration = sum(
            segment['end'] - segment['start']
            for segment in speech_timestamps
        )
        
        # Apply thresholds
        speech_ratio = speech_duration / total_duration if total_duration > 0 else 0
        
        keep = (speech_duration >= MIN_SPEECH_DURATION and 
                speech_ratio >= MIN_SPEECH_RATIO)
        
        return keep, speech_duration, total_duration
        
    except Exception as e:
        # VAD failed to process - file is likely corrupt
        # Return False to DELETE it, not keep it
        logging.warning(f"VAD processing failed on {wav_path.name}: {e} - marking for deletion")
        return False, 0.0, 0.0


def get_all_rooms():
    """Get list of all room directories under recordings/"""
    if not RECORDINGS_BASE.exists():
        return []
    
    rooms = []
    for item in RECORDINGS_BASE.iterdir():
        if item.is_dir():
            rooms.append(item.name)
    
    return sorted(rooms)


def process_room_recordings(room):
    """Process all unprocessed recordings for a specific room"""
    rec_dir = RECORDINGS_BASE / room
    emb_dir = EMBEDDINGS_BASE / room
    
    if not rec_dir.exists():
        return {"kept": 0, "deleted": 0, "errors": 0, "skipped": 0}
    
    # Ensure embeddings directory exists
    emb_dir.mkdir(parents=True, exist_ok=True)
    
    stats = {"kept": 0, "deleted": 0, "errors": 0, "skipped": 0}
    
    # Get all WAV files without TXT companions
    for wav_file in sorted(rec_dir.glob("*.wav")):
        basename = wav_file.stem
        txt_file = emb_dir / f"{basename}.txt"
        
        # Skip if already embedded
        if txt_file.exists():
            continue
        
        # Skip files that are too young (still being written by ffmpeg)
        file_age = get_file_age_seconds(wav_file)
        if file_age < MIN_FILE_AGE_SECONDS:
            stats["skipped"] += 1
            continue
        
        # Check file size
        try:
            file_size = wav_file.stat().st_size
        except:
            file_size = 0
        
        # Delete files that are too small (corrupt/incomplete)
        if file_size < MIN_FILE_SIZE_BYTES:
            try:
                wav_file.unlink()
                logging.info(f"Ã¢Å“â€” DELETE [{room}] {wav_file.name} [corrupt: {file_size} bytes]")
                stats["deleted"] += 1
            except Exception as e:
                logging.error(f"Failed to delete corrupt {wav_file.name}: {e}")
                stats["errors"] += 1
            continue
        
        # Validate WAV file structure before VAD
        valid, duration, error_msg = is_valid_wav(wav_file)
        if not valid:
            try:
                wav_file.unlink()
                logging.info(f"Ã¢Å“â€” DELETE [{room}] {wav_file.name} [invalid: {error_msg}]")
                stats["deleted"] += 1
            except Exception as e:
                logging.error(f"Failed to delete invalid {wav_file.name}: {e}")
                stats["errors"] += 1
            continue
        
        # Run VAD check
        keep, speech_dur, total_dur = has_sufficient_speech(wav_file)
        speech_pct = (speech_dur / total_dur * 100) if total_dur > 0 else 0
        
        if keep:
            logging.info(
                f"Ã¢Å“â€œ KEEP   [{room}] {wav_file.name} "
                f"[speech: {speech_dur:.2f}s / {total_dur:.1f}s = {speech_pct:.0f}%]"
            )
            stats["kept"] += 1
        else:
            try:
                wav_file.unlink()
                if total_dur > 0:
                    logging.info(
                        f"Ã¢Å“â€” DELETE [{room}] {wav_file.name} "
                        f"[speech: {speech_dur:.2f}s / {total_dur:.1f}s = {speech_pct:.0f}%]"
                    )
                else:
                    logging.info(f"Ã¢Å“â€” DELETE [{room}] {wav_file.name} [unreadable/corrupt]")
                stats["deleted"] += 1
            except Exception as e:
                logging.error(f"Failed to delete {wav_file.name}: {e}")
                stats["errors"] += 1
    
    return stats


def save_stats(all_stats):
    """Save cumulative statistics"""
    import json
    try:
        if STATS_FILE.exists():
            with open(STATS_FILE, 'r') as f:
                cumulative = json.load(f)
        else:
            cumulative = {"kept": 0, "deleted": 0, "errors": 0, "skipped": 0, "started": None}
        
        if cumulative["started"] is None:
            cumulative["started"] = time.strftime('%Y-%m-%d %H:%M:%S')
        
        cumulative["kept"] += all_stats["kept"]
        cumulative["deleted"] += all_stats["deleted"]
        cumulative["errors"] += all_stats["errors"]
        cumulative["skipped"] = cumulative.get("skipped", 0) + all_stats.get("skipped", 0)
        cumulative["last_run"] = time.strftime('%Y-%m-%d %H:%M:%S')
        
        with open(STATS_FILE, 'w') as f:
            json.dump(cumulative, f, indent=2)
    except Exception as e:
        logging.error(f"Failed to save stats: {e}")


def main():
    """Main loop - watches ALL rooms"""
    logging.info("=" * 60)
    logging.info("VAD Filter Service Started (MULTI-ROOM)")
    logging.info(f"Monitoring: {RECORDINGS_BASE}")
    logging.info(f"VAD Thresholds: min_speech={MIN_SPEECH_DURATION}s, "
                 f"threshold={SPEECH_THRESHOLD}, "
                 f"min_ratio={MIN_SPEECH_RATIO}")
    logging.info(f"Safety: min_age={MIN_FILE_AGE_SECONDS}s, min_size={MIN_FILE_SIZE_BYTES} bytes")
    logging.info("=" * 60)
    
    cycle = 0
    
    while True:
        try:
            cycle += 1
            
            # Get all rooms
            rooms = get_all_rooms()
            
            if not rooms:
                logging.info("No room directories found, waiting...")
                time.sleep(5)
                continue
            
            # Process each room
            all_stats = {"kept": 0, "deleted": 0, "errors": 0, "skipped": 0}
            
            for room in rooms:
                room_stats = process_room_recordings(room)
                
                # Aggregate stats
                for key in all_stats:
                    all_stats[key] += room_stats[key]
            
            if all_stats["kept"] > 0 or all_stats["deleted"] > 0:
                logging.info(
                    f"Cycle {cycle}: kept={all_stats['kept']}, "
                    f"deleted={all_stats['deleted']}, skipped={all_stats['skipped']}, "
                    f"errors={all_stats['errors']} (across {len(rooms)} rooms)"
                )
                save_stats(all_stats)
            
            time.sleep(2)  # Poll every 2 seconds
            
        except KeyboardInterrupt:
            logging.info("VAD Filter Service stopped by user")
            break
        except Exception as e:
            logging.error(f"Main loop error: {e}", exc_info=True)
            time.sleep(5)


if __name__ == "__main__":
    main()



################################################################################
# FILE: voice_clustering.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""Voice Clustering - Groups similar unprocessed voice embeddings for batch enrollment"""

import os
import json
import numpy as np
from pathlib import Path
from collections import defaultdict
from typing import List, Dict, Tuple

# Configuration
LOGS_FILE = Path("{VOICEBM_BASE}/meta/logs.jsonl")
EMB_DIR = Path("{VOICEBM_BASE}/embeddings/living")
META_LAB = Path("{VOICEBM_BASE}/meta/labeled")
PROCESSED_FILE = Path("{VOICEBM_BASE}/meta/processed.txt")
CLUSTER_CACHE = Path("{VOICEBM_BASE}/meta/clusters.json")

# Clustering parameters
SIMILARITY_THRESHOLD = 0.70  # Voices above this similarity are clustered together
MIN_CLUSTER_SIZE = 3         # Minimum samples to form a cluster
MAX_CLUSTER_SIZE = 50        # Maximum samples in one cluster (prevents overwhelming UI)


def get_processed_ids():
    """Get set of already processed event IDs"""
    processed = set()
    
    # Check labeled folder
    if META_LAB.exists():
        for f in META_LAB.glob("*.json"):
            processed.add(f.stem)
    
    # Check processed tracking file
    if PROCESSED_FILE.exists():
        with open(PROCESSED_FILE, 'r') as f:
            processed.update(line.strip() for line in f if line.strip())
    
    return processed


def load_embedding(emb_path: Path) -> np.ndarray:
    """Load embedding vector from file"""
    try:
        return np.loadtxt(emb_path)
    except Exception as e:
        print(f"Error loading {emb_path}: {e}")
        return None


def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """Compute cosine similarity between two vectors"""
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return float(np.dot(a, b) / (norm_a * norm_b))


def get_enrolled_persons() -> Dict[str, Dict]:
    """
    Load enrolled persons and their embeddings.
    Returns dict of person_id -> {display_name, embeddings}
    """
    enroll_dir = Path("{VOICEBM_BASE}/enroll")
    persons = {}
    
    if not enroll_dir.exists():
        return persons
    
    for person_dir in enroll_dir.iterdir():
        if not person_dir.is_dir():
            continue
        
        person_id = person_dir.name
        
        # Load metadata for display name
        metadata_file = person_dir / 'metadata.json'
        display_name = person_id
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    display_name = metadata.get('display_name', person_id)
            except:
                pass
        
        # Load embeddings (Sherpa format: .txt files in embeddings/ subdirectory)
        embeddings_dir = person_dir / 'embeddings'
        if not embeddings_dir.exists():
            continue
        
        embeddings = []
        for emb_file in embeddings_dir.glob('*.txt'):
            emb = load_embedding(emb_file)
            if emb is not None:
                embeddings.append(emb)
        
        if embeddings:
            persons[person_id] = {
                'display_name': display_name,
                'embeddings': embeddings
            }
    
    return persons


def find_likely_person_match(cluster_centroid: np.ndarray, enrolled_persons: Dict) -> Tuple[str, str, float]:
    """
    Compare cluster centroid against enrolled persons.
    
    Returns:
        (person_id, display_name, confidence) or (None, None, 0.0) if no good match
    """
    if not enrolled_persons:
        return None, None, 0.0
    
    best_match = None
    best_confidence = 0.0
    best_name = None
    
    for person_id, person_data in enrolled_persons.items():
        # Compute centroid of person's embeddings
        person_centroid = np.mean(person_data['embeddings'], axis=0)
        
        # Compare with cluster centroid
        similarity = cosine_similarity(cluster_centroid, person_centroid)
        
        if similarity > best_confidence:
            best_confidence = similarity
            best_match = person_id
            best_name = person_data['display_name']
    
    # Only return match if confidence is reasonable (>0.50)
    if best_confidence > 0.50:
        return best_match, best_name, best_confidence
    
    return None, None, 0.0


def get_unprocessed_samples() -> List[Dict]:
    """Get all unprocessed audio samples with their embeddings"""
    if not LOGS_FILE.exists():
        return []
    
    processed = get_processed_ids()
    samples = []
    
    with open(LOGS_FILE, 'r') as f:
        for line in f:
            if not line.strip():
                continue
            
            try:
                event = json.loads(line)
            except json.JSONDecodeError:
                continue
            
            wav_path = event.get('wav', '')
            emb_path = event.get('emb', '')
            
            if not wav_path or not emb_path:
                continue
            
            eid = Path(wav_path).stem
            
            # Skip if already processed
            if eid in processed:
                continue
            
            # Skip if files don't exist
            if not Path(wav_path).exists() or not Path(emb_path).exists():
                continue
            
            # Load embedding
            emb = load_embedding(Path(emb_path))
            if emb is None:
                continue
            
            samples.append({
                'id': eid,
                'wav': wav_path,
                'emb_path': emb_path,
                'embedding': emb,
                'timestamp': event.get('ts_iso', '')
            })
    
    return samples


def cluster_voices(samples: List[Dict]) -> List[List[Dict]]:
    """
    Cluster voice samples by similarity using simple threshold-based clustering.
    Similar to how Frigate groups similar faces.
    """
    if not samples:
        return []
    
    clusters = []
    remaining = samples.copy()
    
    while remaining:
        # Start new cluster with first remaining sample
        seed = remaining.pop(0)
        cluster = [seed]
        
        # Find all samples similar to this cluster
        to_remove = []
        for i, sample in enumerate(remaining):
            # Compare against cluster centroid
            cluster_embeddings = [s['embedding'] for s in cluster]
            centroid = np.mean(cluster_embeddings, axis=0)
            
            similarity = cosine_similarity(sample['embedding'], centroid)
            
            if similarity >= SIMILARITY_THRESHOLD:
                cluster.append(sample)
                to_remove.append(i)
                
                # Stop if cluster is getting too large
                if len(cluster) >= MAX_CLUSTER_SIZE:
                    break
        
        # Remove clustered samples from remaining
        for i in reversed(to_remove):
            remaining.pop(i)
        
        # Only keep clusters that meet minimum size
        if len(cluster) >= MIN_CLUSTER_SIZE:
            clusters.append(cluster)
    
    return clusters


def compute_cluster_stats(cluster: List[Dict]) -> Dict:
    """Compute statistics for a cluster"""
    embeddings = [s['embedding'] for s in cluster]
    centroid = np.mean(embeddings, axis=0)
    
    # Compute average similarity within cluster
    similarities = []
    for i, emb1 in enumerate(embeddings):
        for emb2 in embeddings[i+1:]:
            similarities.append(cosine_similarity(emb1, emb2))
    
    avg_similarity = np.mean(similarities) if similarities else 0.0
    
    # Get time range
    timestamps = [s['timestamp'] for s in cluster if s['timestamp']]
    time_range = {
        'start': min(timestamps) if timestamps else None,
        'end': max(timestamps) if timestamps else None
    }
    
    return {
        'count': len(cluster),
        'avg_similarity': float(avg_similarity),
        'time_range': time_range
    }


def generate_clusters(force_refresh: bool = False) -> List[Dict]:
    """
    Generate voice clusters for batch enrollment.
    Returns list of clusters with metadata.
    """
    # Check cache if not forcing refresh
    if not force_refresh and CLUSTER_CACHE.exists():
        try:
            cache_age = (Path.cwd().stat().st_mtime - CLUSTER_CACHE.stat().st_mtime)
            if cache_age < 300:  # Cache valid for 5 minutes
                with open(CLUSTER_CACHE, 'r') as f:
                    return json.load(f)
        except:
            pass
    
    print("Loading unprocessed samples...")
    samples = get_unprocessed_samples()
    print(f"Found {len(samples)} unprocessed samples")
    
    if not samples:
        return []
    
    print("Clustering voices by similarity...")
    clusters = cluster_voices(samples)
    print(f"Generated {len(clusters)} clusters")
    
    # Load enrolled persons for matching
    print("Loading enrolled persons for matching...")
    enrolled_persons = get_enrolled_persons()
    print(f"Found {len(enrolled_persons)} enrolled persons")
    
    # Convert clusters to serializable format
    cluster_data = []
    for i, cluster in enumerate(clusters):
        # Compute cluster centroid for person matching
        cluster_embeddings = [s['embedding'] for s in cluster]
        centroid = np.mean(cluster_embeddings, axis=0)
        
        # Find likely person match
        person_id, display_name, confidence = find_likely_person_match(centroid, enrolled_persons)
        
        # Remove embeddings from sample data (too large for JSON)
        # BUT keep emb_path for enrollment
        samples_data = [
            {
                'id': s['id'],
                'wav': s['wav'],
                'emb_path': s['emb_path'],  # CRITICAL: Needed for enrollment
                'timestamp': s['timestamp']
            }
            for s in cluster
        ]
        
        stats = compute_cluster_stats(cluster)
        
        cluster_data.append({
            'cluster_id': i,
            'samples': samples_data,
            'stats': stats,
            'likely_match': {
                'person_id': person_id,
                'display_name': display_name,
                'confidence': float(confidence) if confidence else 0.0
            } if person_id else None
        })
    
    # Cache results
    CLUSTER_CACHE.parent.mkdir(exist_ok=True)
    with open(CLUSTER_CACHE, 'w') as f:
        json.dump(cluster_data, f, indent=2)
    
    return cluster_data


def get_cluster_by_id(cluster_id: int) -> Dict:
    """Get specific cluster by ID"""
    clusters = generate_clusters()
    for cluster in clusters:
        if cluster['cluster_id'] == cluster_id:
            return cluster
    return None


if __name__ == "__main__":
    # Test clustering
    print("Generating voice clusters...")
    clusters = generate_clusters(force_refresh=True)
    
    print(f"\nFound {len(clusters)} clusters:")
    for c in clusters:
        print(f"  Cluster {c['cluster_id']}: "
              f"{c['stats']['count']} samples, "
              f"avg similarity: {c['stats']['avg_similarity']:.3f}")



################################################################################
# FILE: voicebm-audio-server.service.template
# TYPE: script
################################################################################

[Unit]
Description=Voice Biometrics Audio HTTP Server
After=network.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
ExecStart=/usr/bin/python3 {VOICEBM_BASE}/bin/audio_server.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target



################################################################################
# FILE: voicebm-cleanup.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Recording Cleanup - Delete expired WAV files
After=network.target

[Service]
Type=oneshot
User=ice
Group=ice
WorkingDirectory={VOICEBM_BASE}
ExecStart=/usr/bin/python3 {VOICEBM_BASE}/bin/cleanup_recordings.py
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target



################################################################################
# FILE: voicebm-cleanup.timer.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Recording Cleanup Timer - Run daily at 2 AM
Requires=voicebm-cleanup.service

[Timer]
OnCalendar=daily
OnCalendar=02:00
Persistent=true

[Install]
WantedBy=timers.target



################################################################################
# FILE: voicebm-cluster-publisher.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Cluster Publisher
After=voicebm-embedder.service network-online.target
Wants=voicebm-embedder.service network-online.target
PartOf=voicebm.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
Environment=PYTHONUNBUFFERED=1
ExecStart=/bin/bash -c 'source {CONDA_PATH}/etc/profile.d/conda.sh && conda activate vb && python3 {VOICEBM_BASE}/bin/cluster_publisher.py'
Restart=always
RestartSec=2

[Install]
WantedBy=multi-user.target



################################################################################
# FILE: voicebm-commands.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM MQTT Commands (label/reject)
After=network-online.target
Wants=network-online.target
PartOf=voicebm.target


[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
Environment=PYTHONUNBUFFERED=1
ExecStart=/bin/bash -c 'source {CONDA_PATH}/etc/profile.d/conda.sh && conda activate vb && python3 {VOICEBM_BASE}/bin/mqtt_commands.py'
Restart=always
RestartSec=2

[Install]
WantedBy=multi-user.target



################################################################################
# FILE: voicebm-dashboard.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Dashboard (Flask Web UI)
After=network.target voicebm-stt.service
Wants=voicebm-stt.service
PartOf=voicebm.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
ExecStart=/bin/bash -c 'source {CONDA_PATH}/etc/profile.d/conda.sh && conda activate vb && python3 {VOICEBM_BASE}/bin/voicebm_dashboard.py'
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target voicebm.target



################################################################################
# FILE: voicebm-enrollment-watcher.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Enrollment Watcher
After=network-online.target
Wants=network-online.target
PartOf=voicebm.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
Environment=PYTHONUNBUFFERED=1
ExecStart=/usr/bin/python3 {VOICEBM_BASE}/bin/enrollment_watcher.py
Restart=always
RestartSec=2

[Install]
WantedBy=multi-user.target



################################################################################
# FILE: voicebm-global-publisher.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Global Publisher (ID Injection + Latest Result)
After=network.target mosquitto.service
PartOf=voicebm.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
Environment=PYTHONUNBUFFERED=1
ExecStart=/usr/bin/python3 {VOICEBM_BASE}/bin/voicebm_global_publisher.py
Restart=always
RestartSec=10

[Install]
WantedBy=voicebm.target



################################################################################
# FILE: voicebm-retention.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Retention
After=voicebm-recorder.service
Wants=voicebm-recorder.service
PartOf=voicebm.target


[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
Environment=PYTHONUNBUFFERED=1
ExecStart=/usr/bin/python3 {VOICEBM_BASE}/bin/retention.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target



################################################################################
# FILE: voicebm-stt.service.template
# TYPE: script
################################################################################

[Unit]
Description=Voice Biometrics STT Analysis Service
After=network.target mosquitto.service
PartOf=voicebm.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
Environment=PYTHONUNBUFFERED=1
ExecStart=/bin/bash -c 'source {CONDA_PATH}/etc/profile.d/conda.sh && conda activate vb && python3 {VOICEBM_BASE}/bin/voicebm_stt_service.py'
Restart=always
RestartSec=10

[Install]
WantedBy=voicebm.target


################################################################################
# FILE: voicebm-thing-engine.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM Thing Engine - Identity Transformation & Merging
After=network.target
PartOf=voicebm.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
Environment=PYTHONUNBUFFERED=1
ExecStart=/bin/bash -c 'source {CONDA_PATH}/etc/profile.d/conda.sh && conda activate vb_wesp && python3 {VOICEBM_BASE}/bin/thing_engine.py'
Restart=always
RestartSec=10

[Install]
WantedBy=voicebm.target



################################################################################
# FILE: voicebm-vad.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM VAD Filter (living)
After=voicebm-recorder.service
Wants=voicebm-recorder.service
PartOf=voicebm.target

[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}
ExecStart=/bin/bash -c 'source {CONDA_PATH}/etc/profile.d/conda.sh && conda activate vb && python3 {VOICEBM_BASE}/bin/vad_filter.py'
Restart=always
RestartSec=5

[Install]
WantedBy=voicebm.target



################################################################################
# FILE: voicebm-wav-http.service.template
# TYPE: script
################################################################################

[Unit]
Description=VoiceBM WAV HTTP (8000)
After=network-online.target
Wants=network-online.target
PartOf=voicebm.target


[Service]
Type=simple
User=ice
WorkingDirectory={VOICEBM_BASE}/recordings
ExecStart=/usr/bin/python3 -m http.server 8000 --bind 0.0.0.0 --directory {VOICEBM_BASE}/recordings
Restart=always
RestartSec=2

[Install]
WantedBy=multi-user.target



################################################################################
# FILE: voicebm_config.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
VoiceBM Configuration Module
Centralized configuration loading from config.json
"""

import json
import os
from pathlib import Path


def get_mqtt_config():
    """
    Load MQTT configuration from config.json
    
    Returns:
        dict: MQTT configuration with keys: broker, port, user, password
    """
    config_file = Path("{VOICEBM_BASE}/config.json")
    
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
            return config['mqtt']
    except FileNotFoundError:
        print(f"Warning: Config file not found at {config_file}")
        return {
            'broker': 'localhost',
            'port': 1883,
            'user': 'mqtt-user',
            'password': ''
        }
    except Exception as e:
        print(f"Warning: Failed to load MQTT config: {e}")
        return {
            'broker': 'localhost',
            'port': 1883,
            'user': 'mqtt-user',
            'password': ''
        }


def get_audio_server_config():
    """
    Load audio server configuration from config.json
    
    Returns:
        dict: Audio server configuration with keys: host, port, base_url
    """
    config_file = Path("{VOICEBM_BASE}/config.json")
    
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
            return config['audio_server']
    except:
        return {
            'host': 'localhost',
            'port': 9090,
            'base_url': 'http://localhost:9090'
        }


def get_hosts_config():
    """
    Load host addresses from config.json
    
    Returns:
        dict: Host configuration with keys like home_assistant, orin_agx
    """
    config_file = Path("{VOICEBM_BASE}/config.json")
    
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
            return config.get('hosts', {})
    except:
        return {}


def get_paths_config():
    """
    Load path configuration from config.json
    
    Returns:
        dict: Path configuration
    """
    config_file = Path("{VOICEBM_BASE}/config.json")
    
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
            return config.get('paths', {})
    except:
        return {
            'voicebm_base': '{VOICEBM_BASE}',
            'enroll_dir': '{VOICEBM_BASE}/enroll',
            'recordings_dir': '{VOICEBM_BASE}/recordings',
            'embeddings_dir': '{VOICEBM_BASE}/embeddings',
            'meta_dir': '{VOICEBM_BASE}/meta',
            'out_dir': '{VOICEBM_BASE}/out',
            'pending_active_dir': '{VOICEBM_BASE}/pending_active',
            'sherpa_bin': '{SHERPA_BIN}',
            'sherpa_model': '/home/ice/sherpa_models/nemo_en_titanet_small.onnx'
        }


def get_thresholds_config():
    """
    Load threshold configuration from config.json
    
    Returns:
        dict: Threshold configuration with keys: passive, active
    """
    config_file = Path("{VOICEBM_BASE}/config.json")
    
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
            return config.get('thresholds', {'passive': 0.22, 'active': 0.50})
    except:
        return {'passive': 0.22, 'active': 0.50}


def get_room_config(room_name):
    """
    Load configuration for a specific room
    
    Args:
        room_name: Name of the room (e.g., 'living', 'bedroom')
    
    Returns:
        dict: Room configuration with keys: rtsp_url, recorder_enabled
    """
    config_file = Path("{VOICEBM_BASE}/config.json")
    
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
            rooms = config.get('rooms', {})
            return rooms.get(room_name, {})
    except:
        return {}


if __name__ == "__main__":
    # Test configuration loading
    print("Testing VoiceBM configuration loading...")
    print(f"MQTT Config: {get_mqtt_config()}")
    print(f"Audio Server Config: {get_audio_server_config()}")
    print(f"Thresholds: {get_thresholds_config()}")



################################################################################
# FILE: voicebm_dashboard.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
VoiceBM Web Dashboard - Professional UI with branding
LLM Voice Biometrics by David M. Dryver Sr.

Provides web interface for VoiceBM control, enrollment, clustering, and blocklist management.
File-based shared state for multi-platform support (Home Assistant, Open WebUI, local LLM).
"""

from flask import Flask, render_template_string, jsonify, request, send_file
from flask_cors import CORS
from pathlib import Path
import json
import os
from typing import Dict, List, Optional
import datetime
import sys
import paho.mqtt.client as mqtt

app = Flask(__name__)
CORS(app)

# Load MQTT configuration
sys.path.insert(0, '{VOICEBM_BASE}')
from voicebm_config import get_mqtt_config

mqtt_config = get_mqtt_config()
MQTT_BROKER = mqtt_config['broker']
MQTT_PORT = mqtt_config['port']
MQTT_USER = mqtt_config['user']
MQTT_PASS = mqtt_config['password']

# Configuration
VOICEBM_BASE = "{VOICEBM_BASE}"
META_DIR = f"{VOICEBM_BASE}/meta"
ENROLL_DIR = f"{VOICEBM_BASE}/enroll"
PENDING_RECORDINGS = f"{VOICEBM_BASE}/pending_active/recordings"
AUDIO_SERVER_BASE = "http://10.50.60.58:9090"

# State files
SETTINGS_FILE = f"{META_DIR}/settings.json"
ACTIVE_STATE_FILE = f"{META_DIR}/active_state.json"
PENDING_FILE = f"{VOICEBM_BASE}/pending_active/pending.json"
CLUSTERS_FILE = f"{META_DIR}/clusters.json"
USER_SETTINGS_FILE = f"{META_DIR}/user_settings.json"

# ============================================================================
# MQTT CLIENT FOR DASHBOARD CONTROL (Sync Dashboard â†’ HA)
# ============================================================================

# Global MQTT client for publishing control commands
mqtt_client = None

def init_mqtt_client():
    """Initialize MQTT client for dashboard control commands"""
    global mqtt_client
    try:
        mqtt_client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
        mqtt_client.username_pw_set(MQTT_USER, MQTT_PASS)
        mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
        mqtt_client.loop_start()
        print(f"Dashboard MQTT client connected to {MQTT_BROKER}:{MQTT_PORT}")
        return True
    except Exception as e:
        print(f"Warning: Could not connect MQTT client: {e}")
        print("Dashboard will work in read-only mode")
        return False

def publish_to_mqtt(topic, payload, qos=1, retain=True):
    """Publish message to MQTT broker"""
    if mqtt_client:
        try:
            mqtt_client.publish(topic, payload, qos=qos, retain=retain)
            return True
        except Exception as e:
            print(f"MQTT publish failed: {e}")
            return False
    return False

# HTML Template with Bootstrap tables and branding
HTML_TEMPLATE = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VoiceBM Control Dashboard</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.0/font/bootstrap-icons.css">
    <style>
        body {
            background-color: #1a1a1a;
            color: #e0e0e0;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            padding: 20px;
        }
        .main-container {
            max-width: 1400px;
            margin: 0 auto;
        }
        .brand-header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }
        .brand-title {
            font-size: 2.5rem;
            font-weight: bold;
            margin: 0;
            color: white;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .brand-author {
            font-size: 1.1rem;
            margin: 5px 0;
            color: rgba(255,255,255,0.9);
        }
        .brand-version {
            font-size: 0.9rem;
            color: rgba(255,255,255,0.7);
            font-style: italic;
        }
        .section-card {
            background-color: #2d2d2d;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }
        .section-title {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 15px;
            color: #4ade80;
            border-bottom: 2px solid #4ade80;
            padding-bottom: 8px;
        }
        .table-dark {
            background-color: #242424;
            color: #e0e0e0;
        }
        .table-dark thead {
            background-color: #1a1a1a;
        }
        .table-dark tbody tr:hover {
            background-color: #333;
        }
        .badge-virtual {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        }
        .badge-active {
            background-color: #4ade80;
        }
        .badge-blocked {
            background-color: #ef4444;
        }
        .btn-play { background-color: #3b82f6; border: none; }
        .btn-play:hover { background-color: #2563eb; }
        .btn-enroll { background-color: #10b981; border: none; }
        .btn-enroll:hover { background-color: #059669; }
        .btn-reject { background-color: #ef4444; border: none; }
        .btn-reject:hover { background-color: #dc2626; }
        .form-switch .form-check-input {
            width: 3em;
            height: 1.5em;
            cursor: pointer;
        }
        .form-switch .form-check-input:checked {
            background-color: #4ade80;
            border-color: #4ade80;
        }
        .cluster-card {
            background-color: #242424;
            border-radius: 6px;
            padding: 15px;
            margin-bottom: 10px;
            border-left: 4px solid #f59e0b;
        }
        .similarity-badge {
            background-color: #f59e0b;
            color: #000;
            font-weight: bold;
        }
        .no-activity {
            color: #60a5fa;
            font-style: italic;
        }
        .threshold-slider {
            width: 100%;
        }
        .badge-count {
            background-color: #6366f1;
            font-size: 0.9rem;
        }
    </style>
</head>
<body>
    <div class="main-container">
        <!-- Branded Header -->
        <div class="brand-header">
            <div class="brand-title">
                <i class="bi bi-mic-fill"></i> LLM Voice Biometrics
            </div>
            <div class="brand-author">by David M. Dryver Sr.</div>
            <div class="brand-version">Firmware: 1.0</div>
        </div>

        <!-- Active Pipeline Section -->
        <div class="section-card">
            <h2 class="section-title"><i class="bi bi-broadcast"></i> Active Pipeline</h2>
            <div id="active-status" class="no-activity">No recent activity</div>
            <div class="row mt-3">
                <div class="col-md-4">
                    <div class="form-check form-switch">
                        <input class="form-check-input" type="checkbox" id="injectionToggle">
                        <label class="form-check-label" for="injectionToggle">
                            ID Injection: <span id="injectionStatus">OFF</span>
                        </label>
                    </div>
                </div>
                <div class="col-md-8">
                    <label for="thresholdSlider" class="form-label">
                        Active Threshold: <span id="thresholdValue">0.50</span>
                    </label>
                    <input type="range" class="form-range threshold-slider" id="thresholdSlider" 
                           min="0.01" max="1.00" step="0.01" value="0.50">
                </div>
            </div>
        </div>

        <!-- Blocklist Control Section -->
        <div class="section-card">
            <h2 class="section-title"><i class="bi bi-shield-lock"></i> Blocklist Control</h2>
            <table class="table table-dark table-hover">
                <thead>
                    <tr>
                        <th>Identity</th>
                        <th>Status</th>
                        <th>Samples</th>
                        <th>Control</th>
                    </tr>
                </thead>
                <tbody id="blocklistTable">
                    <tr><td colspan="4" class="text-center">Loading...</td></tr>
                </tbody>
            </table>
        </div>

        <!-- Pending Voices Section -->
        <div class="section-card">
            <h2 class="section-title">
                <i class="bi bi-hourglass-split"></i> Pending Voices
                <span class="badge badge-count" id="pendingCount">0</span>
            </h2>
            <table class="table table-dark table-hover">
                <thead>
                    <tr>
                        <th>ID</th>
                        <th>Timestamp</th>
                        <th>Actions</th>
                    </tr>
                </thead>
                <tbody id="pendingTable">
                    <tr><td colspan="3" class="text-center">No pending voices</td></tr>
                </tbody>
            </table>
        </div>

        <!-- Enrolled Identities Section -->
        <div class="section-card">
            <h2 class="section-title">
                <i class="bi bi-people-fill"></i> Enrolled Identities
                <span class="badge badge-count" id="enrolledCount">0</span>
            </h2>
            <table class="table table-dark table-hover">
                <thead>
                    <tr>
                        <th>Name</th>
                        <th>Samples</th>
                        <th>Type</th>
                        <th>Status</th>
                    </tr>
                </thead>
                <tbody id="enrolledTable">
                    <tr><td colspan="4" class="text-center">Loading...</td></tr>
                </tbody>
            </table>
        </div>

        <!-- Voice Clusters Section -->
        <div class="section-card">
            <h2 class="section-title">
                <i class="bi bi-diagram-3"></i> Voice Clusters
                <span class="badge badge-count" id="clusterCount">0</span>
            </h2>
            <div id="clustersList">
                <p class="text-center">No clusters available</p>
            </div>
        </div>
    </div>

    <!-- Cluster Sample Viewer Modal -->
    <div id="sampleModal" style="display: none; position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.8); z-index: 1000; overflow-y: auto;">
        <div style="max-width: 900px; margin: 50px auto; background: #2d2d2d; border-radius: 10px; padding: 30px;">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
                <h3 style="color: #4ade80; margin: 0;">
                    <i class="bi bi-music-note-list"></i> Cluster <span id="modalClusterId">0</span> Samples
                </h3>
                <button onclick="closeSampleModal()" style="background: none; border: none; color: #ef4444; font-size: 24px; cursor: pointer;">&times;</button>
            </div>
            
            <div style="margin-bottom: 20px;">
                <strong>Total Samples:</strong> <span id="modalSampleCount">0</span> &nbsp;&nbsp;
                <strong>Avg Similarity:</strong> <span id="modalSimilarity">0%</span>
                <br>
                <button class="btn btn-sm btn-play mt-2" onclick="playAllFromModal()">
                    <i class="bi bi-play-fill"></i> Play All Samples
                </button>
            </div>
            
            <div id="sampleList" style="max-height: 500px; overflow-y: auto;">
                <!-- Sample list will be populated here -->
            </div>
            
            <!-- Global audio player -->
            <div id="audioPlayerContainer" style="margin-top: 20px; padding: 15px; background: #1a1a1a; border-radius: 8px; display: none;">
                <div style="margin-bottom: 10px;">
                    <strong>Now Playing:</strong> <span id="nowPlayingInfo">Sample #1</span>
                </div>
                <audio id="audioPlayer" controls style="width: 100%;">
                    Your browser does not support audio playback.
                </audio>
            </div>
        </div>
    </div>

    <script>
        // State
        let currentSettings = {};
        let currentActiveState = {};

        // Load initial state
        async function loadState() {
            try {
                const [settings, activeState, pending, clusters, enrolled] = await Promise.all([
                    fetch('/api/state/settings').then(r => r.json()),
                    fetch('/api/state/active').then(r => r.json()),
                    fetch('/api/state/pending').then(r => r.json()),
                    fetch('/api/state/clusters').then(r => r.json()),
                    fetch('/api/enrolled').then(r => r.json())
                ]);

                updateSettings(settings);
                updateActiveState(activeState);
                updatePending(pending);
                updateClusters(clusters);
                updateBlocklist(enrolled);
                updateEnrolled(enrolled);
            } catch (error) {
                console.error('Error loading state:', error);
            }
        }

        function updateSettings(settings) {
            currentSettings = settings;
            const injectionToggle = document.getElementById('injectionToggle');
            const injectionStatus = document.getElementById('injectionStatus');
            const thresholdSlider = document.getElementById('thresholdSlider');
            const thresholdValue = document.getElementById('thresholdValue');

            injectionToggle.checked = settings.inject_identity || false;
            injectionStatus.textContent = settings.inject_identity ? 'ON' : 'OFF';
            injectionStatus.style.color = settings.inject_identity ? '#4ade80' : '#ef4444';

            const threshold = settings.active_threshold || 0.50;
            thresholdSlider.value = threshold;
            thresholdValue.textContent = threshold.toFixed(2);
        }

        function updateActiveState(state) {
            currentActiveState = state;
            const statusDiv = document.getElementById('active-status');
            
            if (state.speaker_id) {
                const enrollButtons = state.speaker_id !== 'user' ? `
                    <div class="mt-3">
                        <button class="btn btn-sm btn-success" onclick="addCurrentToGallery('${state.speaker_id}')" title="Add this sample to ${state.display_name}'s gallery">
                            <i class="bi bi-plus-circle"></i> Add to Gallery
                        </button>
                        <button class="btn btn-sm" style="background: #4ade80; color: #000;" onclick="trainCurrentAsPerson()" title="Train as new person">
                            <i class="bi bi-person-plus"></i> Train as New
                        </button>
                    </div>
                ` : `
                    <div class="mt-3">
                        <button class="btn btn-sm" style="background: #4ade80; color: #000;" onclick="trainCurrentAsPerson()" title="Enroll unknown speaker">
                            <i class="bi bi-person-plus"></i> Enroll Unknown
                        </button>
                    </div>
                `;
                
                statusDiv.innerHTML = `
                    <strong>Current Speaker:</strong> ${state.display_name || 'Unknown'} 
                    (${state.speaker_id})<br>
                    <strong>Confidence:</strong> ${(state.confidence * 100).toFixed(1)}%<br>
                    <strong>Decision:</strong> <span class="badge ${state.decision === 'accepted' ? 'badge-active' : 'bg-warning'}">${state.decision}</span>
                    ${enrollButtons}
                `;
                statusDiv.classList.remove('no-activity');
            } else {
                statusDiv.innerHTML = 'No recent activity';
                statusDiv.classList.add('no-activity');
            }
        }

        function updatePending(pending) {
            const table = document.getElementById('pendingTable');
            const count = document.getElementById('pendingCount');
            
            count.textContent = pending.entries?.length || 0;

            if (!pending.entries || pending.entries.length === 0) {
                table.innerHTML = '<tr><td colspan="3" class="text-center">No pending voices</td></tr>';
                return;
            }

            table.innerHTML = pending.entries.map(entry => `
                <tr>
                    <td><code>${entry.id}</code></td>
                    <td>${new Date(entry.timestamp * 1000).toLocaleString()}</td>
                    <td>
                        <button class="btn btn-sm btn-play" onclick="playAudio('${entry.audio_url}')">
                            <i class="bi bi-play-fill"></i> Play
                        </button>
                        <button class="btn btn-sm btn-enroll" onclick="enrollPending('${entry.id}')">
                            <i class="bi bi-check-circle"></i> Enroll
                        </button>
                        <button class="btn btn-sm btn-reject" onclick="rejectPending('${entry.id}')">
                            <i class="bi bi-x-circle"></i> Reject
                        </button>
                    </td>
                </tr>
            `).join('');
        }

        function updateBlocklist(enrolled) {
            const table = document.getElementById('blocklistTable');
            
            if (!enrolled || enrolled.length === 0) {
                table.innerHTML = '<tr><td colspan="4" class="text-center">No enrolled identities</td></tr>';
                return;
            }

            table.innerHTML = enrolled.map(person => {
                const statusBadge = person.blocked 
                    ? '<span class="badge badge-blocked">BLOCKED</span>'
                    : '<span class="badge badge-active">ACTIVE</span>';
                
                const typeBadge = person.is_virtual 
                    ? '<span class="badge badge-virtual">Virtual</span>'
                    : '<span class="badge bg-secondary">Enrolled</span>';

                return `
                    <tr ${person.is_virtual ? 'style="border-left: 4px solid #764ba2;"' : ''}>
                        <td><strong>${person.display_name}</strong></td>
                        <td>${statusBadge}</td>
                        <td>${person.sample_count}</td>
                        <td>
                            <div class="form-check form-switch">
                                <input class="form-check-input" type="checkbox" 
                                       id="block_${person.person_id}" 
                                       ${person.blocked ? '' : 'checked'}
                                       onchange="toggleBlocklist('${person.person_id}')">
                                <label class="form-check-label" for="block_${person.person_id}">
                                    ${person.blocked ? 'Blocked' : 'Active'}
                                </label>
                            </div>
                        </td>
                    </tr>
                `;
            }).join('');
        }

        function updateEnrolled(enrolled) {
            const table = document.getElementById('enrolledTable');
            const count = document.getElementById('enrolledCount');
            
            // Filter out virtual user for this table
            const realEnrolled = enrolled.filter(p => !p.is_virtual);
            count.textContent = realEnrolled.length;

            if (realEnrolled.length === 0) {
                table.innerHTML = '<tr><td colspan="4" class="text-center">No enrolled identities</td></tr>';
                return;
            }

            table.innerHTML = realEnrolled.map(person => {
                const statusBadge = person.blocked 
                    ? '<span class="badge badge-blocked">BLOCKED</span>'
                    : '<span class="badge badge-active">ACTIVE</span>';

                return `
                    <tr>
                        <td><strong>${person.display_name}</strong></td>
                        <td>${person.sample_count}</td>
                        <td><span class="badge bg-secondary">Enrolled</span></td>
                        <td>${statusBadge}</td>
                    </tr>
                `;
            }).join('');
        }

        function updateClusters(clusters) {
            const container = document.getElementById('clustersList');
            const count = document.getElementById('clusterCount');
            
            count.textContent = clusters.length || 0;

            if (!clusters || clusters.length === 0) {
                container.innerHTML = '<p class="text-center">No clusters available</p>';
                return;
            }

            // Reverse order - show highest cluster numbers first (newest samples)
            const reversedClusters = [...clusters].reverse();

            container.innerHTML = reversedClusters.map(cluster => `
                <div class="cluster-card">
                    <div class="row align-items-center">
                        <div class="col-md-7">
                            <strong>Cluster ${cluster.cluster_id}</strong> - 
                            ${cluster.stats.count} samples
                            <span class="badge similarity-badge ms-2">
                                Similarity: ${(cluster.stats.avg_similarity * 100).toFixed(1)}%
                            </span>
                            ${cluster.likely_match ? `
                                <div class="mt-1">
                                    <span class="badge" style="background: #667eea; font-size: 0.85rem;">
                                        Likely: ${cluster.likely_match.display_name} (${(cluster.likely_match.confidence * 100).toFixed(1)}%)
                                    </span>
                                </div>
                            ` : `
                                <div class="text-muted small mt-1">No enrolled person match</div>
                            `}
                            ${cluster.stats.time_range.start ? `
                                <div class="text-muted small mt-1">
                                    ${cluster.stats.time_range.start.split('T')[0]}
                                </div>
                            ` : ''}
                        </div>
                        <div class="col-md-5 text-end">
                            <div class="d-flex justify-content-end gap-1 flex-wrap">
                                <button class="btn btn-sm btn-primary" onclick="viewClusterSamples(${cluster.cluster_id})" title="View samples">
                                    <i class="bi bi-list-ul"></i>
                                </button>
                                <button class="btn btn-sm btn-play" onclick="playCluster(${cluster.cluster_id})" title="Play all">
                                    <i class="bi bi-play-fill"></i>
                                </button>
                                ${cluster.likely_match ? `
                                    <button class="btn btn-sm btn-success" onclick="enrollClusterAsPerson(${cluster.cluster_id}, '${cluster.likely_match.person_id}')" title="Add to ${cluster.likely_match.display_name}">
                                        <i class="bi bi-person-plus-fill"></i> Add
                                    </button>
                                ` : ''}
                                <button class="btn btn-sm" style="background: #4ade80; color: #000;" onclick="enrollClusterAsNew(${cluster.cluster_id})" title="Enroll as new person">
                                    <i class="bi bi-person-add"></i> New
                                </button>
                                <button class="btn btn-sm btn-danger" onclick="rejectCluster(${cluster.cluster_id})" title="Reject cluster">
                                    <i class="bi bi-x-circle"></i>
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            `).join('');
        }

        // Event handlers
        document.getElementById('injectionToggle').addEventListener('change', async (e) => {
            try {
                await fetch('/api/settings/injection', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ enabled: e.target.checked })
                });
            } catch (error) {
                console.error('Error updating injection:', error);
            }
        });

        document.getElementById('thresholdSlider').addEventListener('input', (e) => {
            document.getElementById('thresholdValue').textContent = parseFloat(e.target.value).toFixed(2);
        });

        document.getElementById('thresholdSlider').addEventListener('change', async (e) => {
            try {
                await fetch('/api/settings/threshold', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ threshold: parseFloat(e.target.value) })
                });
            } catch (error) {
                console.error('Error updating threshold:', error);
            }
        });

        async function toggleBlocklist(personId) {
            try {
                await fetch('/api/blocklist/toggle', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ person_id: personId })
                });
                loadState(); // Refresh
            } catch (error) {
                console.error('Error toggling blocklist:', error);
            }
        }

        function playAudio(url) {
            const audio = new Audio(url);
            audio.play();
        }

        async function enrollPending(pendingId) {
            const name = prompt('Enter person name (will be converted to person_id):');
            if (!name) return;

            try {
                const response = await fetch('/api/pending/enroll', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        pending_id: pendingId,
                        display_name: name
                    })
                });
                
                if (response.ok) {
                    alert('Enrolled successfully!');
                    loadState();
                }
            } catch (error) {
                console.error('Error enrolling:', error);
                alert('Enrollment failed');
            }
        }

        async function rejectPending(pendingId) {
            if (!confirm('Reject this voice sample?')) return;

            try {
                await fetch('/api/pending/reject', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ pending_id: pendingId })
                });
                loadState();
            } catch (error) {
                console.error('Error rejecting:', error);
            }
        }

        async function viewClusterSamples(clusterId) {
            try {
                const response = await fetch(`/api/cluster/${clusterId}`);
                const cluster = await response.json();
                
                if (cluster.error) {
                    alert(`Error: ${cluster.error}`);
                    return;
                }
                
                // Update modal info
                document.getElementById('modalClusterId').textContent = cluster.cluster_id;
                document.getElementById('modalSampleCount').textContent = cluster.stats.count;
                document.getElementById('modalSimilarity').textContent = (cluster.stats.avg_similarity * 100).toFixed(1) + '%';
                
                // Build sample list
                const sampleList = document.getElementById('sampleList');
                sampleList.innerHTML = cluster.samples.map((sample, index) => `
                    <div style="padding: 12px; margin-bottom: 10px; background: #1a1a1a; border-radius: 6px; display: flex; justify-content: space-between; align-items: center;">
                        <div>
                            <strong>Sample #${index + 1}</strong>
                            <div class="text-muted small">${sample.timestamp || 'No timestamp'}</div>
                            <div class="text-muted small">ID: ${sample.id}</div>
                        </div>
                        <button class="btn btn-sm btn-primary" onclick='playSample(${JSON.stringify(sample.audio_url)}, ${index + 1})'>
                            <i class="bi bi-play-fill"></i> Play
                        </button>
                    </div>
                `).join('');
                
                // Store samples globally for batch playback
                window.currentClusterSamples = cluster.samples;
                
                // Show modal
                document.getElementById('sampleModal').style.display = 'block';
            } catch (error) {
                console.error('Error loading cluster:', error);
                alert('Failed to load cluster samples');
            }
        }

        function closeSampleModal() {
            document.getElementById('sampleModal').style.display = 'none';
            // Stop any playing audio
            const player = document.getElementById('audioPlayer');
            player.pause();
            player.src = '';
            document.getElementById('audioPlayerContainer').style.display = 'none';
        }

        function playSample(audioUrl, sampleNumber) {
            const player = document.getElementById('audioPlayer');
            const playerContainer = document.getElementById('audioPlayerContainer');
            const nowPlayingInfo = document.getElementById('nowPlayingInfo');
            
            // Update player
            player.src = audioUrl;
            nowPlayingInfo.textContent = `Sample #${sampleNumber}`;
            playerContainer.style.display = 'block';
            
            // Play
            player.play();
        }

        async function playAllFromModal() {
            if (!window.currentClusterSamples || window.currentClusterSamples.length === 0) {
                alert('No samples to play');
                return;
            }
            
            const player = document.getElementById('audioPlayer');
            const playerContainer = document.getElementById('audioPlayerContainer');
            const nowPlayingInfo = document.getElementById('nowPlayingInfo');
            
            playerContainer.style.display = 'block';
            
            let currentIndex = 0;
            
            function playNext() {
                if (currentIndex >= window.currentClusterSamples.length) {
                    nowPlayingInfo.textContent = 'Playback complete';
                    return;
                }
                
                const sample = window.currentClusterSamples[currentIndex];
                player.src = sample.audio_url;
                nowPlayingInfo.textContent = `Sample #${currentIndex + 1} of ${window.currentClusterSamples.length}`;
                player.play();
                
                currentIndex++;
            }
            
            // Play next sample when current ends
            player.onended = playNext;
            
            // Start playback
            playNext();
        }

        async function playCluster(clusterId) {
            try {
                const response = await fetch(`/api/cluster/${clusterId}`);
                const cluster = await response.json();
                
                if (cluster.error) {
                    alert(`Error: ${cluster.error}`);
                    return;
                }
                
                // Store samples and open modal
                window.currentClusterSamples = cluster.samples;
                await viewClusterSamples(clusterId);
                
                // Auto-start playback
                setTimeout(() => playAllFromModal(), 500);
            } catch (error) {
                console.error('Error playing cluster:', error);
                alert('Failed to play cluster');
            }
        }

        async function enrollClusterAsPerson(clusterId, personId) {
            if (!confirm(`Add all samples from Cluster ${clusterId} to this person's gallery?`)) {
                return;
            }
            
            try {
                const response = await fetch('/api/cluster/enroll', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        cluster_id: clusterId,
                        person_id: personId,
                        action: 'add_to_existing'
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    alert(`âœ“ Added ${result.samples_added} samples to gallery`);
                    loadState(); // Refresh clusters
                } else {
                    alert(`Error: ${result.error}`);
                }
            } catch (error) {
                console.error('Error enrolling cluster:', error);
                alert('Failed to enroll cluster');
            }
        }

        async function enrollClusterAsNew(clusterId) {
            const personName = prompt('Enter person name for this cluster:');
            if (!personName || !personName.trim()) {
                return;
            }
            
            try {
                const response = await fetch('/api/cluster/enroll', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        cluster_id: clusterId,
                        person_name: personName.trim(),
                        action: 'create_new'
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    alert(`âœ“ Created new person with ${result.samples_added} samples`);
                    loadState(); // Refresh clusters
                } else {
                    alert(`Error: ${result.error}`);
                }
            } catch (error) {
                console.error('Error enrolling cluster:', error);
                alert('Failed to enroll cluster');
            }
        }

        async function rejectCluster(clusterId) {
            if (!confirm(`Reject Cluster ${clusterId}? Samples will be marked as processed.`)) {
                return;
            }
            
            try {
                const response = await fetch('/api/cluster/reject', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        cluster_id: clusterId
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    alert(`âœ“ Rejected cluster (${result.samples_rejected} samples marked as processed)`);
                    loadState(); // Refresh clusters
                } else {
                    alert(`Error: ${result.error}`);
                }
            } catch (error) {
                console.error('Error rejecting cluster:', error);
                alert('Failed to reject cluster');
            }
        }

        async function addCurrentToGallery(personId) {
            if (!currentActiveState || !currentActiveState.speaker_id) {
                alert('No active speaker detected');
                return;
            }
            
            if (!confirm(`Add current sample to this person's gallery for training?`)) {
                return;
            }
            
            try {
                const response = await fetch('/api/active/add_to_gallery', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        person_id: personId
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    alert(`âœ“ Added sample to gallery`);
                } else {
                    alert(`Error: ${result.error}`);
                }
            } catch (error) {
                console.error('Error adding to gallery:', error);
                alert('Failed to add sample to gallery');
            }
        }

        async function trainCurrentAsPerson() {
            if (!currentActiveState) {
                alert('No active speaker detected');
                return;
            }
            
            const personName = prompt('Enter person name:');
            if (!personName || !personName.trim()) {
                return;
            }
            
            try {
                const response = await fetch('/api/active/train_as_person', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        person_name: personName.trim()
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    alert(`âœ“ Enrolled as ${personName}`);
                } else {
                    alert(`Error: ${result.error}`);
                }
            } catch (error) {
                console.error('Error training as person:', error);
                alert('Failed to train as person');
            }
        }

        // Auto-refresh
        setInterval(loadState, 2000);
        loadState();
    </script>
</body>
</html>
'''


# === State File Helpers ===

def load_json(filepath: str, default: dict) -> dict:
    """Load JSON file with fallback to default"""
    try:
        if os.path.exists(filepath):
            with open(filepath, 'r') as f:
                return json.load(f)
    except Exception as e:
        print(f"Error loading {filepath}: {e}")
    return default


def save_json(filepath: str, data: dict):
    """Save JSON file atomically"""
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    tmp_path = f"{filepath}.tmp"
    with open(tmp_path, 'w') as f:
        json.dump(data, f, indent=2)
    os.replace(tmp_path, filepath)


# ============================================================================
# PERSON NAME VALIDATION & NORMALIZATION
# ============================================================================

def validate_person_name(name: str) -> tuple[bool, str]:
    """
    Validate person name meets requirements.
    Returns (is_valid, error_message)
    """
    if not name:
        return False, "Name cannot be empty"
    
    if len(name) > 100:
        return False, "Name too long (max 100 characters)"
    
    # Must start and end with letter
    if not name[0].isalpha():
        return False, "Name must start with a letter"
    if not name[-1].isalpha():
        return False, "Name must end with a letter"
    
    # Check for invalid characters (allow letters, spaces, hyphens, underscores)
    import re
    if not re.match(r'^[A-Za-z][A-Za-z0-9\s\-_]*[A-Za-z]$', name):
        return False, "Name can only contain letters, spaces, hyphens, and underscores"
    
    return True, ""


def normalize_person_id(name: str) -> str:
    """
    Normalize person name to person_id format.
    Same logic as enrollment_watcher to ensure consistency.
    """
    import re
    
    # Convert to lowercase
    normalized = name.lower()
    
    # Replace hyphens with underscores
    normalized = normalized.replace('-', '_')
    
    # Replace multiple spaces with single underscore
    normalized = re.sub(r'\s+', '_', normalized)
    
    # Collapse multiple underscores into single
    normalized = re.sub(r'_+', '_', normalized)
    
    # Strip leading/trailing underscores
    normalized = normalized.strip('_')
    
    return normalized


def get_settings() -> dict:
    """Load settings.json"""
    return load_json(SETTINGS_FILE, {
        'inject_identity': True,
        'active_threshold': 0.50
    })


def get_active_state() -> dict:
    """Load active_state.json"""
    return load_json(ACTIVE_STATE_FILE, {})


def get_pending() -> dict:
    """Load pending.json"""
    return load_json(PENDING_FILE, {'entries': []})


def get_clusters() -> list:
    """Load clusters.json"""
    data = load_json(CLUSTERS_FILE, [])
    return data if isinstance(data, list) else []


def get_enrolled_people() -> list:
    """Get all enrolled people including virtual 'user'"""
    people = []
    
    # Add virtual "user" first
    user_settings = load_json(USER_SETTINGS_FILE, {'blocked': False})
    people.append({
        'person_id': 'user',
        'display_name': 'user',
        'sample_count': 0,
        'blocked': user_settings.get('blocked', False),
        'is_virtual': True
    })
    
    # Add enrolled people
    if not os.path.exists(ENROLL_DIR):
        return people
    
    for person_dir in Path(ENROLL_DIR).iterdir():
        if not person_dir.is_dir():
            continue
        
        person_id = person_dir.name
        metadata_file = person_dir / 'metadata.json'
        
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    display_name = metadata.get('display_name', person_id.replace('_', ' ').title())
                    sample_count = len(metadata.get('samples', []))
                    blocked = metadata.get('blocked', False)
            except:
                display_name = person_id.replace('_', ' ').title()
                sample_count = 0
                blocked = False
        else:
            display_name = person_id.replace('_', ' ').title()
            sample_count = 0
            blocked = False
        
        people.append({
            'person_id': person_id,
            'display_name': display_name,
            'sample_count': sample_count,
            'blocked': blocked,
            'is_virtual': False
        })
    
    # Sort: virtual user first, then by sample count descending
    return sorted(people, key=lambda x: (not x['is_virtual'], -x['sample_count']))


# === API Routes ===

@app.route('/')
def index():
    """Main dashboard page"""
    return render_template_string(HTML_TEMPLATE)


@app.route('/api/state/settings')
def api_settings():
    """Get current settings"""
    return jsonify(get_settings())


@app.route('/api/state/active')
def api_active_state():
    """Get current active state"""
    return jsonify(get_active_state())


@app.route('/api/state/pending')
def api_pending():
    """Get pending voices"""
    return jsonify(get_pending())


@app.route('/api/state/clusters')
def api_clusters():
    """Get voice clusters"""
    return jsonify(get_clusters())


@app.route('/api/enrolled')
def api_enrolled():
    """Get enrolled people"""
    return jsonify(get_enrolled_people())


# ============================================================================
# CLUSTER AUDIO PLAYBACK ENDPOINTS
# ============================================================================

@app.route('/api/audio/<path:filename>')
def serve_audio(filename):
    """Serve audio file for playback"""
    try:
        # Audio files are typically in {VOICEBM_BASE}/recordings/living/
        audio_path = Path(f"{VOICEBM_BASE}/recordings/living/{filename}")
        
        if not audio_path.exists():
            return jsonify({'error': 'Audio file not found'}), 404
        
        return send_file(audio_path, mimetype='audio/wav')
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/cluster/<int:cluster_id>')
def get_cluster_detail(cluster_id):
    """Get detailed information about a specific cluster"""
    try:
        # Import clustering module
        import sys
        sys.path.insert(0, '{VOICEBM_BASE}')
        from voice_clustering import get_cluster_by_id
        
        cluster = get_cluster_by_id(cluster_id)
        
        if not cluster:
            return jsonify({'error': 'Cluster not found'}), 404
        
        # Add audio URLs to each sample
        for sample in cluster['samples']:
            audio_filename = Path(sample['wav']).name
            sample['audio_url'] = f"/api/audio/{audio_filename}"
        
        return jsonify(cluster)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/cluster/enroll', methods=['POST'])
def enroll_cluster():
    """Enroll cluster samples as new person or add to existing person"""
    try:
        import sys
        import shutil
        sys.path.insert(0, '{VOICEBM_BASE}')
        from voice_clustering import get_cluster_by_id
        
        data = request.get_json()
        cluster_id = data.get('cluster_id')
        action = data.get('action')  # 'create_new' or 'add_to_existing'
        
        if cluster_id is None:
            return jsonify({'error': 'Missing cluster_id'}), 400
        
        # Get cluster
        cluster = get_cluster_by_id(cluster_id)
        if not cluster:
            return jsonify({'error': 'Cluster not found'}), 404
        
        # Determine person_id
        if action == 'create_new':
            person_name = data.get('person_name', '').strip()
            if not person_name:
                return jsonify({'error': 'Missing person_name'}), 400
            
            # Validate person name
            is_valid, error_msg = validate_person_name(person_name)
            if not is_valid:
                return jsonify({'error': error_msg}), 400
            
            # Normalize person name (consistent with enrollment_watcher)
            person_id = normalize_person_id(person_name)
            display_name = person_name
            
            # Check if person already exists
            person_dir = Path(ENROLL_DIR) / person_id
            if person_dir.exists():
                return jsonify({'error': f'Person "{person_name}" already exists (normalized as "{person_id}")'}), 400
            
            # Create person directory structure
            person_dir.mkdir(parents=True, exist_ok=True)
            embeddings_dir = person_dir / 'embeddings'
            embeddings_dir.mkdir(exist_ok=True)
            
            # Create metadata
            metadata = {
                'display_name': display_name,
                'person_id': person_id,
                'created': datetime.datetime.now().isoformat(),
                'source': 'cluster_enrollment',
                'blocked': False
            }
            
            with open(person_dir / 'metadata.json', 'w') as f:
                json.dump(metadata, f, indent=2)
        
        elif action == 'add_to_existing':
            person_id = data.get('person_id')
            if not person_id:
                return jsonify({'error': 'Missing person_id'}), 400
            
            person_dir = Path(ENROLL_DIR) / person_id
            if not person_dir.exists():
                return jsonify({'error': f'Person "{person_id}" not found'}), 404
            
            embeddings_dir = person_dir / 'embeddings'
            embeddings_dir.mkdir(exist_ok=True)
        
        else:
            return jsonify({'error': 'Invalid action'}), 400
        
        # Copy samples to person directory
        samples_added = 0
        for sample in cluster['samples']:
            try:
                wav_path = Path(sample['wav'])
                # Use actual emb_path from cluster data (now included in samples)
                emb_path = Path(sample['emb_path']) if 'emb_path' in sample else None
                
                if not wav_path.exists():
                    print(f"Warning: WAV file not found: {wav_path}")
                    continue
                
                if not emb_path or not emb_path.exists():
                    print(f"Warning: Embedding file not found: {emb_path}")
                    continue
                
                # Generate unique filename
                timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                new_wav = person_dir / f"{person_id}_{timestamp}.wav"
                new_emb = embeddings_dir / f"{person_id}_{timestamp}.txt"
                
                # Copy files
                shutil.copy2(wav_path, new_wav)
                shutil.copy2(emb_path, new_emb)
                
                samples_added += 1
            except Exception as e:
                print(f"Error copying sample {sample['id']}: {e}")
                continue
        
        # Mark samples as processed
        processed_file = Path("{VOICEBM_BASE}/meta/processed.txt")
        processed_file.parent.mkdir(exist_ok=True)
        with open(processed_file, 'a') as f:
            for sample in cluster['samples']:
                f.write(f"{sample['id']}\n")
        
        return jsonify({
            'success': True,
            'samples_added': samples_added,
            'person_id': person_id
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/cluster/reject', methods=['POST'])
def reject_cluster():
    """Reject cluster - mark all samples as processed without enrolling"""
    try:
        import sys
        sys.path.insert(0, '{VOICEBM_BASE}')
        from voice_clustering import get_cluster_by_id
        
        data = request.get_json()
        cluster_id = data.get('cluster_id')
        
        if cluster_id is None:
            return jsonify({'error': 'Missing cluster_id'}), 400
        
        # Get cluster
        cluster = get_cluster_by_id(cluster_id)
        if not cluster:
            return jsonify({'error': 'Cluster not found'}), 404
        
        # Mark all samples as processed
        processed_file = Path("{VOICEBM_BASE}/meta/processed.txt")
        processed_file.parent.mkdir(exist_ok=True)
        
        with open(processed_file, 'a') as f:
            for sample in cluster['samples']:
                f.write(f"{sample['id']}\n")
        
        return jsonify({
            'success': True,
            'samples_rejected': len(cluster['samples'])
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ============================================================================
# ACTIVE SPEAKER ENROLLMENT ENDPOINTS
# ============================================================================

@app.route('/api/active/add_to_gallery', methods=['POST'])
def add_active_to_gallery():
    """Add current active speaker sample to person's gallery for training"""
    try:
        import shutil
        data = request.get_json()
        person_id = data.get('person_id')
        
        if not person_id:
            return jsonify({'error': 'Missing person_id'}), 400
        
        # Verify person exists
        person_dir = Path(ENROLL_DIR) / person_id
        if not person_dir.exists():
            return jsonify({'error': f'Person "{person_id}" not found'}), 404
        
        embeddings_dir = person_dir / 'embeddings'
        embeddings_dir.mkdir(exist_ok=True)
        
        # Get most recent sample from pending buffer
        pending_json = Path("{VOICEBM_BASE}/pending_active/pending.json")
        if not pending_json.exists():
            return jsonify({'error': 'No recent samples available'}), 404
        
        with open(pending_json, 'r') as f:
            pending_data = json.load(f)
        
        if not pending_data.get('entries'):
            return jsonify({'error': 'No recent samples available'}), 404
        
        # Get most recent entry
        most_recent = pending_data['entries'][-1]
        audio_path = Path(most_recent['audio_path'])
        emb_path = Path(most_recent['emb_path'])
        
        if not audio_path.exists() or not emb_path.exists():
            return jsonify({'error': 'Sample files not found'}), 404
        
        # Generate unique filename
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        new_wav = person_dir / f"{person_id}_{timestamp}.wav"
        new_emb = embeddings_dir / f"{person_id}_{timestamp}.txt"
        
        # Copy files
        shutil.copy2(audio_path, new_wav)
        shutil.copy2(emb_path, new_emb)
        
        return jsonify({
            'success': True,
            'person_id': person_id
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/active/train_as_person', methods=['POST'])
def train_active_as_person():
    """Train current active speaker as new person"""
    try:
        import shutil
        data = request.get_json()
        person_name = data.get('person_name', '').strip()
        
        if not person_name:
            return jsonify({'error': 'Missing person_name'}), 400
        
        # Validate person name
        is_valid, error_msg = validate_person_name(person_name)
        if not is_valid:
            return jsonify({'error': error_msg}), 400
        
        # Normalize person name (consistent with enrollment_watcher)
        person_id = normalize_person_id(person_name)
        display_name = person_name
        
        # Check if person already exists
        person_dir = Path(ENROLL_DIR) / person_id
        if person_dir.exists():
            return jsonify({'error': f'Person "{person_name}" already exists (normalized as "{person_id}")'}), 400
        
        # Create person directory structure
        person_dir.mkdir(parents=True, exist_ok=True)
        embeddings_dir = person_dir / 'embeddings'
        embeddings_dir.mkdir(exist_ok=True)
        
        # Create metadata
        metadata = {
            'display_name': display_name,
            'person_id': person_id,
            'created': datetime.datetime.now().isoformat(),
            'source': 'active_enrollment',
            'blocked': False
        }
        
        with open(person_dir / 'metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # Get most recent sample from pending buffer
        pending_json = Path("{VOICEBM_BASE}/pending_active/pending.json")
        if pending_json.exists():
            with open(pending_json, 'r') as f:
                pending_data = json.load(f)
            
            if pending_data.get('entries'):
                # Get most recent entry
                most_recent = pending_data['entries'][-1]
                audio_path = Path(most_recent['audio_path'])
                emb_path = Path(most_recent['emb_path'])
                
                if audio_path.exists() and emb_path.exists():
                    # Generate unique filename
                    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                    new_wav = person_dir / f"{person_id}_{timestamp}.wav"
                    new_emb = embeddings_dir / f"{person_id}_{timestamp}.txt"
                    
                    # Copy files
                    shutil.copy2(audio_path, new_wav)
                    shutil.copy2(emb_path, new_emb)
        
        return jsonify({
            'success': True,
            'person_id': person_id
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/settings/injection', methods=['POST'])
def update_injection():
    """Update ID injection setting"""
    data = request.get_json()
    settings = get_settings()
    enabled = data.get('enabled', False)
    settings['inject_identity'] = enabled
    settings['last_updated'] = datetime.datetime.now().isoformat()
    save_json(SETTINGS_FILE, settings)
    
    # Publish to MQTT for HA sync
    state = "ON" if enabled else "OFF"
    publish_to_mqtt("voicebm/inject_identity", state)
    
    return jsonify({'success': True})


@app.route('/api/settings/threshold', methods=['POST'])
def update_threshold():
    """Update active threshold setting"""
    data = request.get_json()
    settings = get_settings()
    threshold = float(data.get('threshold', 0.50))
    settings['active_threshold'] = threshold
    settings['last_updated'] = datetime.datetime.now().isoformat()
    save_json(SETTINGS_FILE, settings)
    
    # Publish to MQTT for HA sync
    publish_to_mqtt("voicebm/active/threshold/set", str(threshold))
    
    return jsonify({'success': True})


@app.route('/api/blocklist/toggle', methods=['POST'])
def toggle_blocklist():
    """Toggle blocklist for a person or virtual user"""
    data = request.get_json()
    person_id = data.get('person_id')
    
    if not person_id:
        return jsonify({'error': 'Missing person_id'}), 400
    
    # Special handling for virtual "user"
    if person_id == 'user':
        user_settings = load_json(USER_SETTINGS_FILE, {'blocked': False})
        user_settings['blocked'] = not user_settings.get('blocked', False)
        user_settings['last_updated'] = datetime.datetime.now().isoformat()
        save_json(USER_SETTINGS_FILE, user_settings)
        
        # Publish to MQTT for HA sync
        state = "ON" if user_settings['blocked'] else "OFF"
        publish_to_mqtt(f"voicebm/blocklist/{person_id}", state)
        
        return jsonify({'success': True, 'blocked': user_settings['blocked']})
    
    # Handle enrolled person
    metadata_file = Path(ENROLL_DIR) / person_id / 'metadata.json'
    
    if not metadata_file.exists():
        return jsonify({'error': 'Person not found'}), 404
    
    metadata = load_json(str(metadata_file), {})
    metadata['blocked'] = not metadata.get('blocked', False)
    metadata['last_updated'] = datetime.datetime.now().isoformat()
    save_json(str(metadata_file), metadata)
    
    # Publish to MQTT for HA sync
    state = "ON" if metadata['blocked'] else "OFF"
    publish_to_mqtt(f"voicebm/blocklist/{person_id}", state)
    
    return jsonify({'success': True, 'blocked': metadata['blocked']})


@app.route('/api/pending/enroll', methods=['POST'])
def enroll_pending():
    """Enroll a pending voice"""
    data = request.get_json()
    pending_id = data.get('pending_id')
    display_name = data.get('display_name', '').strip()
    
    if not pending_id or not display_name:
        return jsonify({'error': 'Missing required fields'}), 400
    
    person_id = display_name.lower().replace(' ', '_')
    
    # TODO: Implement enrollment logic
    # This would move files from pending_active/ to enroll/{person_id}/
    
    return jsonify({'success': True, 'person_id': person_id})


@app.route('/api/pending/reject', methods=['POST'])
def reject_pending():
    """Reject a pending voice"""
    data = request.get_json()
    pending_id = data.get('pending_id')
    
    if not pending_id:
        return jsonify({'error': 'Missing pending_id'}), 400
    
    # TODO: Implement rejection logic
    # This would delete files from pending_active/
    
    return jsonify({'success': True})


if __name__ == '__main__':
    print("=" * 60)
    print("VoiceBM Dashboard - LLM Voice Biometrics")
    print("by David M. Dryver Sr.")
    print("=" * 60)
    print(f"Dashboard URL: http://10.50.60.58:5000")
    print(f"Settings file: {SETTINGS_FILE}")
    print(f"Active state: {ACTIVE_STATE_FILE}")
    print(f"Pending: {PENDING_FILE}")
    print("=" * 60)
    
    # Initialize MQTT client for dashboard control
    print("Connecting MQTT client for dashboard control...")
    if init_mqtt_client():
        print("âœ“ MQTT connected - Dashboard has full control")
    else:
        print("âœ— MQTT failed - Dashboard in read-only mode")
    print("=" * 60)
    
    app.run(host='0.0.0.0', port=5000, debug=True)



################################################################################
# FILE: voicebm_global_publisher.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
VoiceBM Global Publisher - Publishes global system entities

Entities published:
- ID Injection switch (voicebm/inject_identity)
- Latest Voice Result sensor (from enroll_suggest output)

This is a GLOBAL service - runs once for the entire system, not per-room.
"""

import os
import json
import time
import paho.mqtt.client as mqtt

# MQTT Configuration (centralized)
import sys
sys.path.insert(0, '{VOICEBM_BASE}')
from voicebm_config import get_mqtt_config

mqtt_config = get_mqtt_config()
BROKER = mqtt_config['broker']
PORT = mqtt_config['port']
USER = mqtt_config['user']
PASS = mqtt_config['password']

# Global topics
INJECT_STATE_TOPIC = "voicebm/inject_identity"
RESULT_TOPIC = "voicebm/result"

# Latest result file (monitoring living room as primary)
LATEST_JSON = "{VOICEBM_BASE}/out/living.latest.json"
THRESH_JSON = "{VOICEBM_BASE}/out/thresholds.json"

# First-run detection marker
DISCOVERY_INITIALIZED_FILE = "{VOICEBM_BASE}/meta/discovery_initialized_global"


def load_json(path, default=None):
    try:
        with open(path, "r") as f:
            return json.load(f)
    except:
        return default


def is_first_run():
    """Check if this is the first time discovery has been published."""
    return not os.path.exists(DISCOVERY_INITIALIZED_FILE)


def mark_initialized():
    """Mark that discovery has been initialized."""
    os.makedirs(os.path.dirname(DISCOVERY_INITIALIZED_FILE), exist_ok=True)
    with open(DISCOVERY_INITIALIZED_FILE, 'w') as f:
        f.write(time.strftime('%Y-%m-%d %H:%M:%S'))
    print("  Marked global discovery as initialized")


def publish_discovery(client):
    """Publish Home Assistant MQTT Discovery for global entities."""
    discovery_prefix = "homeassistant"
    
    device = {
        "identifiers": ["voicebm"],
        "name": "Voice Biometrics",
        "manufacturer": "David M. Dryver Sr.",
        "model": "VoiceBM Voice ID System"
    }
    
    # ID Injection Switch
    injection_switch_config = {
        "name": "ID Injection",
        "unique_id": "voicebm_inject_identity",
        "command_topic": f"{INJECT_STATE_TOPIC}/set",
        "state_topic": INJECT_STATE_TOPIC,
        "payload_on": "ON",
        "payload_off": "OFF",
        "icon": "mdi:account-arrow-right",
        "device": device
    }
    
    client.publish(
        f"{discovery_prefix}/switch/voicebm_inject_identity/config",
        json.dumps(injection_switch_config),
        qos=1,
        retain=True
    )
    
    # Latest Voice Result sensor
    result_config = {
        "name": "Latest Voice Result",
        "unique_id": "voicebm_latest_result",
        "state_topic": RESULT_TOPIC,
        "value_template": "{{ value_json.file }}",
        "json_attributes_topic": RESULT_TOPIC,
        "icon": "mdi:microphone",
        "device": device
    }
    
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_latest_result/config",
        json.dumps(result_config),
        qos=1,
        retain=True
    )
    
    # Current Speaker sensor (from STT pipeline)
    current_speaker_config = {
        "name": "Current Speaker",
        "unique_id": "voicebm_current_speaker",
        "state_topic": "voicebm/current_speaker",
        "icon": "mdi:account-voice",
        "device": device
    }
    
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_current_speaker/config",
        json.dumps(current_speaker_config),
        qos=1,
        retain=True
    )
    
    print("Published global entity discovery configs")


def on_connect(client, userdata, flags, reason_code, properties):
    if reason_code == 0:
        print(f"Connected to MQTT broker at {BROKER}:{PORT}")
        
        # Subscribe to injection toggle commands
        client.subscribe(f"{INJECT_STATE_TOPIC}/set", qos=1)
        print(f"Subscribed to {INJECT_STATE_TOPIC}/set")
        
        # Check if this is first run
        first_run = is_first_run()
        
        if first_run:
            print("First run detected - will publish initial states")
        else:
            print("Subsequent run - respecting HA state (discovery only)")
        
        # Publish discovery
        publish_discovery(client)
        
        # ONLY publish initial state on first run
        # Subsequent runs preserve HA's retained state
        if first_run:
            client.publish(INJECT_STATE_TOPIC, "ON", qos=1, retain=True)
            print("  Initial state: inject_identity = ON")
            mark_initialized()
        
    else:
        print(f"Failed to connect, reason code: {reason_code}")


def on_message(client, userdata, msg):
    """Handle injection toggle commands."""
    if msg.topic == f"{INJECT_STATE_TOPIC}/set":
        try:
            command = msg.payload.decode('utf-8')
            print(f"ID Injection toggle: {command}")
            
            # Update settings file
            settings_path = "{VOICEBM_BASE}/meta/settings.json"
            os.makedirs(os.path.dirname(settings_path), exist_ok=True)
            
            try:
                with open(settings_path, 'r') as f:
                    settings = json.load(f)
            except:
                settings = {}
            
            settings['inject_identity'] = (command == "ON")
            settings['last_updated'] = time.strftime('%Y-%m-%d %H:%M:%S')
            
            with open(settings_path, 'w') as f:
                json.dump(settings, f, indent=2)
            
            # Publish state update
            client.publish(INJECT_STATE_TOPIC, command, qos=1, retain=True)
            
            status = "ENABLED" if command == "ON" else "DISABLED"
            print(f"  ID Injection: {status}")
            
        except Exception as e:
            print(f"  Error handling injection toggle: {e}")


def monitor_latest_result(client):
    """Monitor latest result file and publish to MQTT."""
    last_mtime = 0
    
    while True:
        try:
            if os.path.exists(LATEST_JSON):
                mtime = os.path.getmtime(LATEST_JSON)
                
                if mtime != last_mtime:
                    last_mtime = mtime
                    
                    data = load_json(LATEST_JSON, {})
                    thresh = load_json(THRESH_JSON, {"MATCH_T": 0.22})
                    
                    score = float(data.get("score", 0.0))
                    match_t = float(thresh.get("MATCH_T", 0.22))
                    
                    result = {
                        "file": data.get("file", ""),
                        "best_match": data.get("best_match"),
                        "score": round(score, 4),
                        "accepted": score >= match_t
                    }
                    
                    client.publish(RESULT_TOPIC, json.dumps(result), qos=1, retain=True)
                    print(f"Published latest result: {result['file']}, score={result['score']}")
            
            time.sleep(1)
            
        except KeyboardInterrupt:
            print("\nShutting down...")
            break
        except Exception as e:
            print(f"Error in monitor loop: {e}")
            time.sleep(1)


def main():
    print("=" * 60)
    print("VoiceBM Global Publisher")
    print("=" * 60)
    print(f"MQTT Broker: {BROKER}:{PORT}")
    print("Publishing global entities:")
    print("  - ID Injection switch")
    print("  - Latest Voice Result sensor")
    print("=" * 60)
    
    client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
    client.username_pw_set(USER, PASS)
    client.on_connect = on_connect
    client.on_message = on_message
    
    try:
        client.connect(BROKER, PORT, 60)
    except Exception as e:
        print(f"MQTT connection failed: {e}")
        return
    
    client.loop_start()
    
    print("\nMonitoring for latest results...")
    print("Press Ctrl+C to exit\n")
    
    try:
        monitor_latest_result(client)
    except KeyboardInterrupt:
        print("\n\nShutting down...")
    finally:
        client.loop_stop()
        client.disconnect()
        print("Global publisher stopped")


if __name__ == "__main__":
    main()



################################################################################
# FILE: voicebm_stt_service.py.template
# TYPE: script
################################################################################

#!/usr/bin/env python3
"""
Voice Biometrics MQTT Service - Processes STT analysis requests from Wyoming container
Runs on HOST (Orin AGX) with access to Sherpa-ONNX conda environment

ACTIVE PIPELINE SCRIPT - Uses slider-controlled threshold (MATCH_T_ACTIVE)
The passive pipeline (publish_identity_living.py) uses MATCH_T_PASSIVE = 0.22.
This script responds to the HA slider for adjustable STT injection threshold.

Features:
- Responds to voice analysis requests from Docker handler.py
- Tracks injection toggle state and includes in response
- Maintains pending buffer (5) for unidentified voices
- Handles enrollment/rejection of pending voices

CRITICAL FIX APPLIED:
- Unknown speakers (speaker_id=None) now map to virtual "user" identity
- "user" blocklist switch now actually blocks unknowns (removed skeleton key)
"""

import os
import json
import time
import shutil
import subprocess
import tempfile
import datetime
from pathlib import Path
import numpy as np
import paho.mqtt.client as mqtt

# Configuration
# MQTT Configuration (centralized)
import sys
sys.path.insert(0, '{VOICEBM_BASE}')
from voicebm_config import get_mqtt_config

mqtt_config = get_mqtt_config()
BROKER = mqtt_config['broker']
PORT = mqtt_config['port']
USER = mqtt_config['user']
PASS = mqtt_config['password']

# UPDATED PATH FOR WRAPPER SCRIPT (under {VOICEBM_BASE}/bin/)
SHERPA_SCRIPT = "{VOICEBM_BASE}/bin/embed_stt.sh"
SHERPA_MODEL = "{SHERPA_MODEL}"
ENROLL_DIR = "{VOICEBM_BASE}/enroll"
THRESHOLD_FILE = "{VOICEBM_BASE}/out/thresholds.json"

# THRESHOLD SPLIT:
# - This script uses MATCH_T_ACTIVE (slider-controlled, default 0.50)
# - Passive pipeline uses MATCH_T_PASSIVE = 0.22 (fixed)
DEFAULT_THRESHOLD_ACTIVE = 0.50

REQUEST_TOPIC = "voicebm/stt/analyze_request"
RESPONSE_TOPIC = "voicebm/stt/analyze_response"

# Pending enrollment configuration
PENDING_DIR = Path("{VOICEBM_BASE}/pending_active")
PENDING_RECORDINGS = PENDING_DIR / "recordings"
PENDING_EMBEDDINGS = PENDING_DIR / "embeddings"
PENDING_JSON = PENDING_DIR / "pending.json"
PENDING_BUFFER_SIZE = 5
PENDING_EXPIRE_HOURS = 1

# MQTT Topics
PENDING_TOPIC = "voicebm/pending_active"
PENDING_ENROLL_TOPIC = "voicebm/pending_active/enroll"
PENDING_REJECT_TOPIC = "voicebm/pending_active/reject"
PENDING_CLEAR_TOPIC = "voicebm/pending_active/clear"
INJECT_STATE_TOPIC = "voicebm/inject_identity"

# Dashboard state files (for Flask/OpenWebUI multi-platform sync)
META_DIR = Path("{VOICEBM_BASE}/meta")
SETTINGS_FILE = META_DIR / "settings.json"
ACTIVE_STATE_FILE = META_DIR / "active_state.json"

# Global state
inject_identity_enabled = True
blocked_speakers = set()  # In-memory set of blocked person_ids, populated from MQTT

# Global state for pending enrollment name
pending_person_name = ""

# Track last published person for state clearing (prevents stuck sensors in HA)
last_published_person = None


def is_speaker_blocked(speaker_id):
    """
    Check if a speaker is on the blocklist.
    
    Uses in-memory set populated from MQTT subscriptions.
    NO file reads - fast and simple.
    
    Args:
        speaker_id: The person_id to check
    
    Returns:
        bool: True if blocked, False otherwise
    """
    if not speaker_id:
        return False
    
    is_blocked = speaker_id in blocked_speakers
    print(f"  [BLOCKLIST] {speaker_id} blocked={is_blocked} (in-memory check)")
    return is_blocked


def handle_blocklist_state(client, userdata, msg):
    """
    Handle blocklist state updates from MQTT.
    Topic pattern: voicebm/blocklist/{person_id}
    Payload: 'ON' or 'OFF'
    """
    global blocked_speakers
    
    try:
        parts = msg.topic.split('/')
        if len(parts) >= 3:
            person_id = parts[2]
            state = msg.payload.decode('utf-8')
            
            if state == "ON":
                blocked_speakers.add(person_id)
                print(f"[BLOCKLIST] Added to blocklist: {person_id}")
            else:
                blocked_speakers.discard(person_id)
                print(f"[BLOCKLIST] Removed from blocklist: {person_id}")
            
            print(f"[BLOCKLIST] Current blocked speakers: {blocked_speakers}")
    except Exception as e:
        print(f"[BLOCKLIST] Error handling state update: {e}")


# ============================================================================
# DASHBOARD STATE FILE WRITERS (Multi-platform sync via filesystem)
# ============================================================================

def write_settings_file():
    """
    Write settings.json for dashboard.
    Syncs injection state and threshold to filesystem for Flask/OpenWebUI access.
    """
    try:
        META_DIR.mkdir(parents=True, exist_ok=True)
        
        # Read current threshold from thresholds.json
        threshold = DEFAULT_THRESHOLD_ACTIVE
        try:
            if os.path.exists(THRESHOLD_FILE):
                with open(THRESHOLD_FILE, 'r') as f:
                    thr = json.load(f)
                    threshold = float(thr.get("MATCH_T_ACTIVE", DEFAULT_THRESHOLD_ACTIVE))
        except:
            pass
        
        settings = {
            "inject_identity": inject_identity_enabled,
            "active_threshold": threshold,
            "last_updated": time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        with open(SETTINGS_FILE, 'w') as f:
            json.dump(settings, f, indent=2)
            
    except Exception as e:
        print(f"Warning: Could not write settings.json: {e}")


def write_active_state_file(speaker_id, display_name, confidence, decision):
    """
    Write active_state.json for dashboard.
    Syncs current speaker identity to filesystem for Flask/OpenWebUI access.
    """
    try:
        META_DIR.mkdir(parents=True, exist_ok=True)
        
        active_state = {
            "speaker_id": speaker_id,
            "display_name": display_name or "Unknown",
            "confidence": round(confidence, 4),
            "decision": decision,
            "timestamp": time.time(),
            "ts_iso": datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"
        }
        
        with open(ACTIVE_STATE_FILE, 'w') as f:
            json.dump(active_state, f, indent=2)
            
    except Exception as e:
        print(f"Warning: Could not write active_state.json: {e}")


def setup_pending_dirs():
    """Create pending enrollment directories."""
    PENDING_DIR.mkdir(parents=True, exist_ok=True)
    PENDING_RECORDINGS.mkdir(exist_ok=True)
    PENDING_EMBEDDINGS.mkdir(exist_ok=True)
    
    if not PENDING_JSON.exists():
        save_pending_buffer([])


def load_pending_buffer():
    """Load pending enrollment buffer from JSON."""
    try:
        if PENDING_JSON.exists():
            with open(PENDING_JSON, 'r') as f:
                return json.load(f)
    except Exception as e:
        print(f"Failed to load pending buffer: {e}")
    return []


def save_pending_buffer(buffer):
    """Save pending enrollment buffer to JSON."""
    try:
        with open(PENDING_JSON, 'w') as f:
            json.dump(buffer, f, indent=2)
    except Exception as e:
        print(f"Failed to save pending buffer: {e}")


def cleanup_expired_pending():
    """Remove expired entries from pending buffer."""
    buffer = load_pending_buffer()
    if not buffer:
        return buffer
    
    now_ts = time.time()
    expire_seconds = PENDING_EXPIRE_HOURS * 3600
    
    valid = []
    for entry in buffer:
        entry_ts = entry.get('timestamp', 0)
        if now_ts - entry_ts < expire_seconds:
            valid.append(entry)
        else:
            try:
                wav_path = PENDING_RECORDINGS / f"{entry['id']}.wav"
                emb_path = PENDING_EMBEDDINGS / f"{entry['id']}.txt"
                if wav_path.exists():
                    wav_path.unlink()
                if emb_path.exists():
                    emb_path.unlink()
                print(f"Expired pending entry removed: {entry['id']}")
            except Exception as e:
                print(f"Failed to cleanup expired {entry['id']}: {e}")
    
    if len(valid) != len(buffer):
        save_pending_buffer(valid)
    
    return valid


def add_to_pending_buffer(audio_path, embedding, request_id):
    """Add unidentified voice to pending enrollment buffer."""
    buffer = cleanup_expired_pending()
    
    pending_id = f"active_{int(time.time() * 1000)}"
    
    try:
        wav_dst = PENDING_RECORDINGS / f"{pending_id}.wav"
        emb_dst = PENDING_EMBEDDINGS / f"{pending_id}.txt"
        
        if os.path.exists(audio_path):
            shutil.copy2(audio_path, wav_dst)
        else:
            print(f"Source audio not found: {audio_path}")
            return None
        
        np.savetxt(emb_dst, embedding)
        
        entry = {
            "id": pending_id,
            "request_id": request_id,
            "timestamp": time.time(),
            "ts_iso": datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z",
            "audio_url": f"http://10.50.60.58:9090/pending/{pending_id}.wav",
            "source": "active_node",
        }
        
        buffer.append(entry)
        
        while len(buffer) > PENDING_BUFFER_SIZE:
            removed = buffer.pop(0)
            try:
                old_wav = PENDING_RECORDINGS / f"{removed['id']}.wav"
                old_emb = PENDING_EMBEDDINGS / f"{removed['id']}.txt"
                if old_wav.exists():
                    old_wav.unlink()
                if old_emb.exists():
                    old_emb.unlink()
                print(f"Buffer overflow, removed oldest: {removed['id']}")
            except Exception as e:
                print(f"Failed to remove overflow {removed['id']}: {e}")
        
        save_pending_buffer(buffer)
        print(f"Added to pending buffer: {pending_id} (buffer size: {len(buffer)})")
        
        return entry
        
    except Exception as e:
        print(f"Failed to add to pending buffer: {e}")
        return None


def publish_pending_status(client):
    """
    Publish current pending buffer status to MQTT.

    IMPORTANT CHANGE vs Claude's original:
    - 'current' entry is now the *newest* pending entry (buffer[-1]),
      not the oldest (buffer[0]).
    """
    buffer = load_pending_buffer()
    
    payload = {
        "count": len(buffer),
        "max_size": PENDING_BUFFER_SIZE,
        "expire_hours": PENDING_EXPIRE_HOURS,
        "entries": buffer,
    }
    
    client.publish(PENDING_TOPIC, json.dumps(payload), qos=1, retain=True)
    
    # Surface the NEWEST pending entry as "current"
    if buffer:
        current = buffer[-1]
        client.publish(
            "voicebm/pending_active/current_id",
            current.get("id", ""),
            qos=1,
            retain=True,
        )
        client.publish(
            "voicebm/pending_active/audio_url",
            current.get("audio_url", ""),
            qos=1,
            retain=True,
        )
    else:
        client.publish("voicebm/pending_active/current_id", "none", qos=1, retain=True)
        client.publish("voicebm/pending_active/audio_url", "", qos=1, retain=True)
    
    print(f"Published pending status: {len(buffer)} entries")


def load_gallery():
    """Load enrolled speakers and compute centroids."""
    people = {}
    enroll_path = Path(ENROLL_DIR)
    
    if not enroll_path.exists():
        print(f"Warning: Enrollment directory not found at {ENROLL_DIR}")
        return {}
    
    try:
        for person_dir in enroll_path.iterdir():
            if not person_dir.is_dir():
                continue
            
            person_id = person_dir.name
            embeddings_dir = person_dir / "embeddings"
            metadata_file = person_dir / "metadata.json"
            
            if metadata_file.exists():
                try:
                    with open(metadata_file, "r") as f:
                        metadata = json.load(f)
                        display_name = metadata.get(
                            "display_name", person_id.replace("_", " ").title()
                        )
                except:
                    display_name = person_id.replace("_", " ").title()
            else:
                display_name = person_id.replace("_", " ").title()
            
            if not embeddings_dir.exists():
                continue
            
            vectors = []
            for emb_file in embeddings_dir.glob("*.txt"):
                try:
                    v = np.loadtxt(emb_file)
                    if v is not None and len(v) > 0:
                        vectors.append(v)
                except Exception as e:
                    print(f"  Failed to load {emb_file.name}: {e}")
            
            if vectors:
                people[(person_id, display_name)] = vectors
    
    except Exception as e:
        print(f"Error loading gallery: {e}")
        return {}
    
    cents = {}
    for (sid, name), vecs in people.items():
        cents[(sid, name)] = np.mean(vecs, axis=0)
    
    print(f"Loaded {len(cents)} enrolled speakers")
    return cents


def create_embedding(wav_path):
    """Create embedding using Sherpa-ONNX via bash wrapper."""
    try:
        with tempfile.NamedTemporaryFile(suffix=".txt", delete=False) as tmp:
            embedding_path = tmp.name
        
        result = subprocess.run(
            [SHERPA_SCRIPT, wav_path, embedding_path],
            capture_output=True,
            text=True,
            timeout=30,
        )
        
        if result.returncode != 0:
            print(f"Sherpa embedding failed: {result.stderr}")
            return None
        
        embedding = np.loadtxt(embedding_path)
        os.unlink(embedding_path)
        
        return embedding
        
    except Exception as e:
        print(f"Embedding creation failed: {e}")
        return None


def cosine_similarity(a, b):
    """Calculate cosine similarity."""
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return float(np.dot(a, b) / (norm_a * norm_b))


# ============================================================================
# PER-PERSON THRESHOLD OVERRIDE SUPPORT
# ============================================================================

# Cache for per-person thresholds (updated via MQTT subscription)
person_thresholds = {}


def get_person_threshold(person_id, global_threshold):
    """
    Get threshold for a specific person.
    
    Returns per-person threshold if set, otherwise returns global threshold.
    
    Args:
        person_id: Person identifier
        global_threshold: Fallback global threshold
    
    Returns:
        Threshold value to use for this person
    """
    if person_id in person_thresholds:
        custom = person_thresholds[person_id]
        print(f"  Using custom threshold for {person_id}: {custom:.2f}")
        return custom
    return global_threshold


def verify_person_threshold(speaker_id, confidence, global_threshold):
    """
    Verify that identified speaker meets their custom threshold (if set).
    
    If person has custom threshold and confidence doesn't meet it,
    returns None (treat as unknown).
    
    Args:
        speaker_id: Identified speaker ID
        confidence: Confidence score from identification
        global_threshold: Global threshold used for initial identification
    
    Returns:
        speaker_id if threshold met, None if custom threshold not met
    """
    if speaker_id is None:
        return None
    
    # Check if person has custom threshold
    if speaker_id in person_thresholds:
        custom_threshold = person_thresholds[speaker_id]
        if confidence < custom_threshold:
            print(f"  Custom threshold check FAILED: {confidence:.4f} < {custom_threshold:.2f} for {speaker_id}")
            return None  # Reject match - doesn't meet person's custom threshold
    
    return speaker_id


def identify_speaker(embedding, gallery, threshold):
    """Identify speaker by comparing embedding against gallery."""
    if embedding is None or not gallery:
        return None, None, 0.0
    
    best_sid = None
    best_name = None
    best_sim = -1.0
    
    all_matches = []
    
    for (person_id, display_name), centroid in gallery.items():
        sim = cosine_similarity(embedding, centroid)
        all_matches.append((person_id, display_name, sim))
        if sim > best_sim:
            best_sim = sim
            best_sid = person_id
            best_name = display_name
    
    all_matches.sort(key=lambda x: x[2], reverse=True)
    
    print("  Match candidates:")
    for pid, pname, sim in all_matches[:5]:
        marker = "[BEST]" if pid == best_sid else "      "
        above_threshold = "PASS" if sim >= threshold else "FAIL"
        print(f"    {marker} {above_threshold} {pname:20s} ({pid:15s}) = {sim:.4f}")
    
    if best_sim >= threshold:
        print(f"  [MATCH] Identified: {best_name} ({best_sid}) confidence={best_sim:.4f}")
        return best_sid, best_name, best_sim
    else:
        print(f"  No match (best={best_sim:.4f} < threshold={threshold})")
        return None, None, best_sim


def publish_discovery(client):
    """Publish MQTT Discovery for pending enrollment controls under VoiceBM device."""
    discovery_prefix = "homeassistant"
    
    device = {
        "identifiers": ["voicebm"],
        "name": "Voice Biometrics",
        "manufacturer": "David M. Dryver Sr.",
        "model": "Home Assistant Voice Biometrics",
        "sw_version": "1.0"
    }
    
    # Pending Active Voices count sensor
    pending_count_config = {
        "name": "Pending Active Voices",
        "unique_id": "voicebm_pending_active_count",
        "state_topic": PENDING_TOPIC,
        "value_template": "{{ value_json.count }}",
        "json_attributes_topic": PENDING_TOPIC,
        "icon": "mdi:account-question",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_pending_active_count/config",
        json.dumps(pending_count_config),
        qos=1,
        retain=True,
    )
    
    # Pending Active Audio URL sensor
    pending_audio_config = {
        "name": "Pending Active Audio URL",
        "unique_id": "voicebm_pending_active_audio_url",
        "state_topic": "voicebm/pending_active/audio_url",
        "icon": "mdi:volume-high",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_pending_active_audio_url/config",
        json.dumps(pending_audio_config),
        qos=1,
        retain=True,
    )
    
    # Pending Active ID sensor
    pending_id_config = {
        "name": "Pending Active ID",
        "unique_id": "voicebm_pending_active_id",
        "state_topic": "voicebm/pending_active/current_id",
        "icon": "mdi:identifier",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_pending_active_id/config",
        json.dumps(pending_id_config),
        qos=1,
        retain=True,
    )
    
    # Text input for person name to enroll pending voice as
    pending_name_config = {
        "name": "Pending Person Name",
        "unique_id": "voicebm_pending_person_name",
        "command_topic": "voicebm/pending_active/person_name/set",
        "state_topic": "voicebm/pending_active/person_name",
        "icon": "mdi:account-edit",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/text/voicebm_pending_person_name/config",
        json.dumps(pending_name_config),
        qos=1,
        retain=True,
    )
    
    # Initialize pending person name
    client.publish("voicebm/pending_active/person_name", "", qos=1, retain=True)
    
    # Enroll Pending button
    enroll_btn_config = {
        "name": "Enroll Pending Voice",
        "unique_id": "voicebm_pending_enroll_btn",
        "command_topic": "voicebm/pending_active/enroll_btn",
        "payload_press": "PRESS",
        "icon": "mdi:account-plus",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/button/voicebm_pending_enroll_btn/config",
        json.dumps(enroll_btn_config),
        qos=1,
        retain=True,
    )
    
    # Reject Pending button
    reject_btn_config = {
        "name": "Reject Pending Voice",
        "unique_id": "voicebm_pending_reject_btn",
        "command_topic": "voicebm/pending_active/reject_btn",
        "payload_press": "PRESS",
        "icon": "mdi:account-remove",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/button/voicebm_pending_reject_btn/config",
        json.dumps(reject_btn_config),
        qos=1,
        retain=True,
    )
    
    # Play Pending Audio button
    play_btn_config = {
        "name": "Play Pending Audio",
        "unique_id": "voicebm_pending_play_btn",
        "command_topic": "voicebm/pending_active/play_btn",
        "payload_press": "PRESS",
        "icon": "mdi:play-circle",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/button/voicebm_pending_play_btn/config",
        json.dumps(play_btn_config),
        qos=1,
        retain=True,
    )
    
    # Clear All Pending button
    clear_btn_config = {
        "name": "Clear All Pending",
        "unique_id": "voicebm_pending_clear_btn",
        "command_topic": "voicebm/pending_active/clear",
        "payload_press": "PRESS",
        "icon": "mdi:delete-sweep",
        "device": device,
    }
    
    client.publish(
        f"{discovery_prefix}/button/voicebm_pending_clear_btn/config",
        json.dumps(clear_btn_config),
        qos=1,
        retain=True,
    )
    
    # Active Identity Entities (8) - Show STT analysis results
    # These mirror what passive nodes publish but for the active STT pipeline
    
    # 1. Active Speaker (display name)
    active_speaker_config = {
        "name": "Active Speaker",
        "unique_id": "voicebm_active_speaker",
        "state_topic": "voicebm/active/identity",
        "value_template": "{{ value_json.display_name if value_json.display_name else 'Unknown' }}",
        "json_attributes_topic": "voicebm/active/identity",
        "icon": "mdi:account-voice",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_speaker/config",
        json.dumps(active_speaker_config),
        qos=1,
        retain=True,
    )
    
    # 2. Active Speaker ID
    active_speaker_id_config = {
        "name": "Active Speaker ID",
        "unique_id": "voicebm_active_speaker_id",
        "state_topic": "voicebm/active/identity",
        "value_template": "{{ value_json.speaker_id if value_json.speaker_id else 'none' }}",
        "icon": "mdi:identifier",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_speaker_id/config",
        json.dumps(active_speaker_id_config),
        qos=1,
        retain=True,
    )
    
    # 3. Active Confidence
    active_confidence_config = {
        "name": "Active Voice Confidence",
        "unique_id": "voicebm_active_confidence",
        "state_topic": "voicebm/active/identity",
        "value_template": "{{ (value_json.confidence * 100) | round(1) }}",
        "unit_of_measurement": "%",
        "icon": "mdi:percent",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_confidence/config",
        json.dumps(active_confidence_config),
        qos=1,
        retain=True,
    )
    
    # 4. Active Decision
    active_decision_config = {
        "name": "Active Voice Decision",
        "unique_id": "voicebm_active_decision",
        "state_topic": "voicebm/active/identity",
        "value_template": "{{ value_json.decision }}",
        "icon": "mdi:check-decagram",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_decision/config",
        json.dumps(active_decision_config),
        qos=1,
        retain=True,
    )
    
    # 5. Active Score
    active_score_config = {
        "name": "Active Voice Score",
        "unique_id": "voicebm_active_score",
        "state_topic": "voicebm/active/identity",
        "value_template": "{{ value_json.score | round(2) if value_json.score else 0.0 }}",
        "unit_of_measurement": "score",
        "icon": "mdi:chart-line",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_score/config",
        json.dumps(active_score_config),
        qos=1,
        retain=True,
    )
    
    # 6. Active Voice Accepted (binary sensor - Detected/Unknown)
    active_accepted_config = {
        "name": "Active Voice Accepted",
        "unique_id": "voicebm_active_accepted",
        "state_topic": "voicebm/active/identity",
        "value_template": "{{ 'Detected' if value_json.decision == 'accepted' else 'Unknown' }}",
        "icon": "mdi:check-circle",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_accepted/config",
        json.dumps(active_accepted_config),
        qos=1,
        retain=True,
    )
    
    # 7. Active Unprocessed Samples (placeholder - set to 0 for now)
    active_unprocessed_config = {
        "name": "Active Unprocessed Samples",
        "unique_id": "voicebm_active_unprocessed",
        "state_topic": "voicebm/active/unprocessed_samples",
        "icon": "mdi:file-question",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_unprocessed/config",
        json.dumps(active_unprocessed_config),
        qos=1,
        retain=True,
    )
    # Initialize to 0
    client.publish("voicebm/active/unprocessed_samples", "0", qos=1, retain=True)
    
    # 8. Active Current Event ID
    active_event_id_config = {
        "name": "Active Current Event ID",
        "unique_id": "voicebm_active_event_id",
        "state_topic": "voicebm/active/current_event_id",
        "icon": "mdi:file-document",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/sensor/voicebm_active_event_id/config",
        json.dumps(active_event_id_config),
        qos=1,
        retain=True,
    )
    
    # Active Match Threshold Number Input (adjustable STT security threshold)
    active_threshold_config = {
        "name": "Active Match Threshold",
        "unique_id": "voicebm_active_threshold",
        "command_topic": "voicebm/active/threshold/set",
        "state_topic": "voicebm/active/threshold",
        "min": 0.01,
        "max": 1.00,
        "step": 0.01,
        "mode": "slider",
        "icon": "mdi:tune-vertical",
        "device": device,
    }
    client.publish(
        f"{discovery_prefix}/number/voicebm_active_threshold/config",
        json.dumps(active_threshold_config),
        qos=1,
        retain=True,
    )
    
    # Initialize active threshold from thresholds.json
    try:
        with open(THRESHOLD_FILE, 'r') as f:
            thr = json.load(f)
            active_threshold_value = float(thr.get("MATCH_T_ACTIVE", DEFAULT_THRESHOLD_ACTIVE))
    except:
        active_threshold_value = DEFAULT_THRESHOLD_ACTIVE
    
    client.publish("voicebm/active/threshold", str(active_threshold_value), qos=1, retain=True)
    print(f"  Initialized active threshold: {active_threshold_value}")
    
    print("Published MQTT Discovery for pending enrollment controls + Active Identity entities + Active Threshold")


def handle_pending_enroll(client, userdata, msg):
    """Handle enrollment command for pending active voice."""
    try:
        data = json.loads(msg.payload.decode("utf-8"))
        pending_id = data.get("id")
        person_id = data.get("person_id", "").strip().lower().replace(" ", "_")
        display_name = data.get("display_name", "").strip()
        
        if not pending_id or not person_id or not display_name:
            print("Enroll command missing required fields")
            return
        
        print(f"Enrolling pending {pending_id} as {display_name} ({person_id})")
        
        buffer = load_pending_buffer()
        entry = None
        for e in buffer:
            if e["id"] == pending_id:
                entry = e
                break
        
        if not entry:
            print(f"Pending entry not found: {pending_id}")
            return
        
        wav_src = PENDING_RECORDINGS / f"{pending_id}.wav"
        emb_src = PENDING_EMBEDDINGS / f"{pending_id}.txt"
        
        if not wav_src.exists() or not emb_src.exists():
            print(f"Pending files not found for {pending_id}")
            return
        
        person_dir = Path(ENROLL_DIR) / person_id
        embeddings_dir = person_dir / "embeddings"
        recordings_dir = person_dir / "recordings"
        
        person_dir.mkdir(parents=True, exist_ok=True)
        embeddings_dir.mkdir(exist_ok=True)
        recordings_dir.mkdir(exist_ok=True)
        
        metadata_file = person_dir / "metadata.json"
        if metadata_file.exists():
            with open(metadata_file, "r") as f:
                metadata = json.load(f)
                existing_samples = metadata.get("samples", [])
        else:
            metadata = {
                "person_id": person_id,
                "display_name": display_name,
                "created_at": datetime.datetime.utcnow()
                .replace(microsecond=0)
                .isoformat()
                + "Z",
            }
            existing_samples = []
        
        event_id = pending_id
        emb_dst = embeddings_dir / f"{event_id}.txt"
        rec_dst = recordings_dir / f"{event_id}.wav"
        
        expire_at = (
            datetime.datetime.utcfromtimestamp(time.time() + 3 * 24 * 3600)
            .replace(microsecond=0)
            .isoformat()
            + "Z"
        )
        
        try:
            shutil.move(str(emb_src), str(emb_dst))
            shutil.move(str(wav_src), str(rec_dst))
            print(f"Moved files to enrollment: {event_id}")
        except Exception as e:
            print(f"Failed to move files: {e}")
            return
        
        sample_entry = {
            "event_id": event_id,
            "embedding": f"embeddings/{event_id}.txt",
            "recording": f"recordings/{event_id}.wav",
            "enrolled_at": datetime.datetime.utcnow()
            .replace(microsecond=0)
            .isoformat()
            + "Z",
            "expire_at": expire_at,
            "retention_days": 3,
            "source": "active_node",
        }
        
        metadata["samples"] = existing_samples + [sample_entry]
        metadata["last_updated"] = (
            datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"
        )
        metadata["total_samples"] = len(metadata["samples"])
        
        with open(metadata_file, "w") as f:
            json.dump(metadata, f, indent=2)
        
        buffer = [e for e in buffer if e["id"] != pending_id]
        save_pending_buffer(buffer)
        
        # Refresh gallery so new enrollment is immediately used
        userdata["gallery"] = load_gallery()
        
        publish_pending_status(client)
        
        response = {
            "success": True,
            "pending_id": pending_id,
            "person_id": person_id,
            "display_name": display_name,
            "total_samples": metadata["total_samples"],
        }
        client.publish(f"{PENDING_ENROLL_TOPIC}/response", json.dumps(response), qos=1)
        
        print(f"Successfully enrolled {pending_id} as {display_name}")
        
    except Exception as e:
        print(f"Error handling enroll command: {e}")
        import traceback

        traceback.print_exc()


def handle_pending_reject(client, userdata, msg):
    """Handle rejection command for pending active voice."""
    try:
        data = json.loads(msg.payload.decode("utf-8"))
        pending_id = data.get("id")
        
        if not pending_id:
            print("Reject command missing id")
            return
        
        print(f"Rejecting pending: {pending_id}")
        
        try:
            wav_path = PENDING_RECORDINGS / f"{pending_id}.wav"
            emb_path = PENDING_EMBEDDINGS / f"{pending_id}.txt"
            if wav_path.exists():
                wav_path.unlink()
            if emb_path.exists():
                emb_path.unlink()
        except Exception as e:
            print(f"Failed to delete files for {pending_id}: {e}")
        
        buffer = load_pending_buffer()
        buffer = [e for e in buffer if e["id"] != pending_id]
        save_pending_buffer(buffer)
        
        publish_pending_status(client)
        
        response = {"success": True, "rejected_id": pending_id}
        client.publish(f"{PENDING_REJECT_TOPIC}/response", json.dumps(response), qos=1)
        
        print(f"Successfully rejected {pending_id}")
        
    except Exception as e:
        print(f"Error handling reject command: {e}")


def handle_pending_clear(client, userdata, msg):
    """Clear all pending entries."""
    try:
        print("Clearing all pending entries")
        
        buffer = load_pending_buffer()
        
        for entry in buffer:
            try:
                wav_path = PENDING_RECORDINGS / f"{entry['id']}.wav"
                emb_path = PENDING_EMBEDDINGS / f"{entry['id']}.txt"
                if wav_path.exists():
                    wav_path.unlink()
                if emb_path.exists():
                    emb_path.unlink()
            except Exception as e:
                print(f"Failed to delete {entry['id']}: {e}")
        
        save_pending_buffer([])
        publish_pending_status(client)
        
        print(f"Cleared {len(buffer)} pending entries")
        
    except Exception as e:
        print(f"Error handling clear command: {e}")


def handle_person_name_set(client, userdata, msg):
    """Handle person name text input for pending enrollment."""
    global pending_person_name
    
    try:
        pending_person_name = msg.payload.decode("utf-8").strip()
        
        client.publish(
            "voicebm/pending_active/person_name",
            pending_person_name,
            qos=1,
            retain=True,
        )
        
        print(f"Pending person name set to: '{pending_person_name}'")
        
    except Exception as e:
        print(f"Error handling person name set: {e}")


def handle_enroll_button(client, userdata, msg):
    """
    Handle enroll button press.

    CHANGE: uses the NEWEST pending entry (buffer[-1]) to match
    what we surface as 'current' in publish_pending_status().
    """
    global pending_person_name
    
    try:
        buffer = load_pending_buffer()
        
        if not buffer:
            print("Enroll button pressed but no pending entries")
            return
        
        if not pending_person_name:
            print("Enroll button pressed but no person name set")
            return
        
        # Use newest pending entry
        current = buffer[-1]
        pending_id = current["id"]
        
        person_id = pending_person_name.lower().replace(" ", "_")
        display_name = pending_person_name.title()
        
        print(f"Enrolling pending {pending_id} as {display_name} ({person_id})")
        
        enroll_data = {
            "id": pending_id,
            "person_id": person_id,
            "display_name": display_name,
        }
        
        class MockMsg:
            def __init__(self, payload):
                self.payload = payload
        
        mock_msg = MockMsg(json.dumps(enroll_data).encode("utf-8"))
        handle_pending_enroll(client, userdata, mock_msg)
        
        pending_person_name = ""
        client.publish(
            "voicebm/pending_active/person_name", "", qos=1, retain=True
        )
        
    except Exception as e:
        print(f"Error handling enroll button: {e}")
        import traceback

        traceback.print_exc()


def handle_reject_button(client, userdata, msg):
    """
    Handle reject button press.

    CHANGE: rejects the NEWEST pending entry (buffer[-1]),
    to stay consistent with what HA is showing as 'current'.
    """
    try:
        buffer = load_pending_buffer()
        
        if not buffer:
            print("Reject button pressed but no pending entries")
            return
        
        current = buffer[-1]
        pending_id = current["id"]
        
        print(f"Rejecting pending {pending_id}")
        
        reject_data = {"id": pending_id}
        
        class MockMsg:
            def __init__(self, payload):
                self.payload = payload
        
        mock_msg = MockMsg(json.dumps(reject_data).encode("utf-8"))
        handle_pending_reject(client, userdata, mock_msg)
        
    except Exception as e:
        print(f"Error handling reject button: {e}")


def handle_play_button(client, userdata, msg):
    """
    Handle play button press.

    CHANGE: plays the NEWEST pending entry (buffer[-1]),
    again matching the surfaced 'current'.
    """
    try:
        buffer = load_pending_buffer()
        
        if not buffer:
            print("Play button pressed but no pending entries")
            return
        
        current = buffer[-1]
        audio_url = current.get("audio_url", "")
        
        if audio_url:
            client.publish(
                "voicebm/pending_active/play_trigger", audio_url, qos=1
            )
            print(f"Play triggered: {audio_url}")
        else:
            print("No audio URL for pending entry")
        
    except Exception as e:
        print(f"Error handling play button: {e}")


def handle_analysis_request(client, userdata, msg):
    """Process voice biometrics analysis request."""
    global inject_identity_enabled, last_published_person
    
    # Clear previous person's binary sensor BEFORE identifying new speaker
    # This ensures OFFâ†’ON state change even if same person speaks twice
    # Prevents stuck sensors in Home Assistant automations
    if last_published_person:
        print(f"  Clearing previous sensor: {last_published_person}/voice")
        client.publish(f"{last_published_person}/voice", "OFF", qos=1, retain=True)
        time.sleep(0.05)  # 50ms for HA to register OFF state
    
    # Also clear Active Identity sensors (Active Speaker, Active Speaker ID, Current Speaker)
    # These show last detected person and need clearing for each new utterance
    clear_identity_data = {
        "speaker_id": "user",
        "display_name": "Unknown",
        "confidence": 0.0,
        "decision": "unknown",
        "score": 0.0
    }
    client.publish("voicebm/active/identity", json.dumps(clear_identity_data), qos=1, retain=True)
    time.sleep(0.05)  # 50ms for HA to register cleared state
    print("  Cleared Active Identity sensors")
    
    try:
        request = json.loads(msg.payload.decode("utf-8"))
        request_id = request.get("request_id")
        audio_path = request.get("audio_path")
        
        print(f"\nAnalysis request: {request_id}")
        print(f"  Audio: {audio_path}")
        
        if not audio_path or not os.path.exists(audio_path):
            print("  Audio file not found")
            return
        
        # Load ACTIVE threshold (slider-controlled)
        try:
            with open(THRESHOLD_FILE, "r") as f:
                thr = json.load(f)
                threshold = float(thr.get("MATCH_T_ACTIVE", DEFAULT_THRESHOLD_ACTIVE))
                print(
                    f"  Using STT threshold: {threshold:.2f} "
                    f"(from thresholds.json MATCH_T_ACTIVE)"
                )
        except Exception as e:
            threshold = DEFAULT_THRESHOLD_ACTIVE
            print(
                f"  Using STT threshold: {threshold:.2f} "
                f"(default, file read failed: {e})"
            )
        
        embedding = create_embedding(audio_path)
        
        if embedding is None:
            print("  Failed to create embedding")
            return
        
        gallery = userdata["gallery"]
        speaker_id, display_name, confidence = identify_speaker(
            embedding, gallery, threshold
        )
        
        # Verify speaker meets their custom threshold (if set)
        # If custom threshold is higher and not met, treat as unknown
        speaker_id = verify_person_threshold(speaker_id, confidence, threshold)
        
        # If speaker_id was cleared by custom threshold check, reset display_name
        if speaker_id is None and display_name is not None:
            print(f"  Match rejected: {display_name} did not meet custom threshold")
            display_name = None
        
        # ALWAYS add to pending buffer (unknowns AND known persons)
        # This enables continuous training and gallery strengthening
        # Unknowns â†’ can enroll as new person
        # Known persons â†’ can add training samples to existing gallery
        print(f"  Adding to pending buffer: {display_name or 'Unknown'} (available for enrollment/training)")
        entry = add_to_pending_buffer(audio_path, embedding, request_id)
        if entry:
            publish_pending_status(client)
        
        # =================================================================
        # CRITICAL FIX: Map unknowns to virtual "user" identity for blocklist check
        # =================================================================
        # For unknowns: speaker_id = None
        # Map to "user" so the blocklist check can actually block them
        effective_id = speaker_id if speaker_id else "user"
        is_blocked = is_speaker_blocked(effective_id)
        
        response = {
            "request_id": request_id,
            "speaker_id": speaker_id,
            "display_name": display_name,
            "confidence": confidence,
            "inject_enabled": inject_identity_enabled,
            "is_blocked": is_blocked,
            "timestamp": time.time(),
        }
        
        if is_blocked:
            print(
                f"  [BLOCKED] Speaker {display_name or 'user'} ({speaker_id or 'user'}) "
                f"is on blocklist - STT will silent fail"
            )
        
        response_topic = f"{RESPONSE_TOPIC}/{request_id}"
        client.publish(response_topic, json.dumps(response), qos=1)
        print(f"  Published response to {response_topic}")
        
        # Publish Active Identity data for HA sensors (8 entities)
        decision = "accepted" if speaker_id else "unknown"
        active_identity_data = {
            "speaker_id": speaker_id,
            "display_name": display_name or "Unknown",
            "confidence": confidence,
            "decision": decision,
            "score": confidence  # Score = confidence for active pipeline
        }
        client.publish("voicebm/active/identity", json.dumps(active_identity_data), qos=1, retain=True)
        client.publish("voicebm/active/current_event_id", request_id, qos=1, retain=True)
        
        # Publish binary sensor state for detected person
        # This creates OFFâ†’ON transition even for consecutive utterances from same person
        if speaker_id:
            client.publish(f"{speaker_id}/voice", "ON", qos=1, retain=True)
            last_published_person = speaker_id  # Store for next clearing cycle
            print(f"  Published binary sensor: {speaker_id}/voice = ON")
        
        # Write active state to filesystem for dashboard (Flask/OpenWebUI multi-platform sync)
        write_active_state_file(speaker_id, display_name, confidence, decision)
        
        # Publish confidence + source + gallery_size as attributes for per-person binary sensor
        # IMPORTANT: Include gallery_size to keep it synced with enrollment_watcher
        if speaker_id:  # Only for identified users, not unknowns
            # Count embeddings in enrollment gallery
            from pathlib import Path
            enroll_dir = Path("{VOICEBM_BASE}/enroll") / speaker_id / "embeddings"
            gallery_size = len(list(enroll_dir.glob('*.txt'))) if enroll_dir.exists() else 0
            
            # Merge all attributes together
            attributes = {
                "confidence": round(confidence, 4),
                "source": "active",
                "gallery_size": gallery_size,
                "last_updated": time.strftime('%Y-%m-%d %H:%M:%S')
            }
            client.publish(f"{speaker_id}/voice/attributes", json.dumps(attributes), qos=1, retain=True)
        
        print(f"  Published Active Identity: {display_name} ({decision}, {confidence:.2%})")
        
    except Exception as e:
        print(f"  Error processing request: {e}")
        import traceback

        traceback.print_exc()


def handle_active_threshold_set(client, userdata, msg):
    """Handle active threshold slider changes and update thresholds.json."""
    try:
        new_threshold = float(msg.payload.decode("utf-8"))
        
        # Validate range
        if not (0.01 <= new_threshold <= 1.00):
            print(f"Invalid active threshold value: {new_threshold}")
            return
        
        print(f"Active threshold changed to: {new_threshold:.2f}")
        
        # Update thresholds.json MATCH_T_ACTIVE
        try:
            if os.path.exists(THRESHOLD_FILE):
                with open(THRESHOLD_FILE, 'r') as f:
                    thresholds = json.load(f)
            else:
                thresholds = {}
            
            thresholds['MATCH_T_ACTIVE'] = new_threshold
            
            os.makedirs(os.path.dirname(THRESHOLD_FILE), exist_ok=True)
            with open(THRESHOLD_FILE, 'w') as f:
                json.dump(thresholds, f, indent=2)
            
            print(f"  Updated thresholds.json: MATCH_T_ACTIVE = {new_threshold:.2f}")
            
            # Echo back to state topic
            client.publish("voicebm/active/threshold", str(new_threshold), qos=1, retain=True)
            
            # Write settings to filesystem for dashboard
            write_settings_file()
            
        except Exception as e:
            print(f"Failed to update thresholds.json: {e}")
    
    except Exception as e:
        print(f"Error handling active threshold change: {e}")


def handle_person_threshold_set(client, userdata, msg):
    """Handle per-person threshold override changes."""
    global person_thresholds
    
    try:
        # Extract person_id from topic: {person_id}/threshold_override/set
        topic_parts = msg.topic.split('/')
        if len(topic_parts) < 3:
            print(f"Invalid threshold override topic: {msg.topic}")
            return
        
        person_id = topic_parts[0]
        new_threshold = float(msg.payload.decode("utf-8"))
        
        # Validate range
        if not (0.10 <= new_threshold <= 0.90):
            print(f"Invalid threshold value for {person_id}: {new_threshold}")
            return
        
        # Update cache
        person_thresholds[person_id] = new_threshold
        print(f"Custom threshold for {person_id}: {new_threshold:.2f}")
        
        # Echo back to state topic
        client.publish(f"{person_id}/threshold_override", str(new_threshold), qos=1, retain=True)
        
    except ValueError:
        print(f"Invalid threshold value received: {msg.payload}")
    except Exception as e:
        print(f"Error handling person threshold change: {e}")


def on_connect(client, userdata, flags, reason_code, properties):
    global inject_identity_enabled
    
    if reason_code == 0:
        print(f"Connected to MQTT broker at {BROKER}:{PORT}")
        
        client.subscribe(REQUEST_TOPIC, qos=1)
        print(f"Subscribed to {REQUEST_TOPIC}")
        
        client.subscribe(INJECT_STATE_TOPIC, qos=1)
        print(f"Subscribed to {INJECT_STATE_TOPIC}")
        
        client.subscribe("voicebm/blocklist/+", qos=1)
        print("Subscribed to voicebm/blocklist/+ (blocklist states)")
        
        client.subscribe(PENDING_ENROLL_TOPIC, qos=1)
        client.subscribe(PENDING_REJECT_TOPIC, qos=1)
        client.subscribe(PENDING_CLEAR_TOPIC, qos=1)
        print("Subscribed to pending command topics")
        
        client.subscribe("voicebm/pending_active/person_name/set", qos=1)
        client.subscribe("voicebm/pending_active/enroll_btn", qos=1)
        client.subscribe("voicebm/pending_active/reject_btn", qos=1)
        client.subscribe("voicebm/pending_active/play_btn", qos=1)
        print("Subscribed to pending UI control topics")
        
        client.subscribe("voicebm/active/threshold/set", qos=1)
        print("Subscribed to active threshold control")
        
        # Subscribe to per-person threshold overrides
        client.subscribe("+/threshold_override/set", qos=1)
        print("Subscribed to per-person threshold overrides (+/threshold_override/set)")
        
        publish_discovery(client)
        publish_pending_status(client)
        
    else:
        print(f"Failed to connect, reason code: {reason_code}")


def on_message(client, userdata, msg):
    global inject_identity_enabled, pending_person_name
    
    topic = msg.topic
    
    if topic.startswith("voicebm/blocklist/") and not topic.endswith("/set"):
        handle_blocklist_state(client, userdata, msg)
    elif topic == REQUEST_TOPIC:
        handle_analysis_request(client, userdata, msg)
    elif topic == INJECT_STATE_TOPIC:
        try:
            state = msg.payload.decode("utf-8")
            new_enabled = state == "ON"
            if inject_identity_enabled != new_enabled:
                inject_identity_enabled = new_enabled
                print(f"Injection state updated: {state} (enabled={new_enabled})")
                # Write settings to filesystem for dashboard
                write_settings_file()
        except Exception as e:
            print(f"Failed to parse injection state: {e}")
    elif topic == PENDING_ENROLL_TOPIC:
        handle_pending_enroll(client, userdata, msg)
    elif topic == PENDING_REJECT_TOPIC:
        handle_pending_reject(client, userdata, msg)
    elif topic == PENDING_CLEAR_TOPIC:
        handle_pending_clear(client, userdata, msg)
    elif topic == "voicebm/pending_active/person_name/set":
        handle_person_name_set(client, userdata, msg)
    elif topic == "voicebm/pending_active/enroll_btn":
        handle_enroll_button(client, userdata, msg)
    elif topic == "voicebm/pending_active/reject_btn":
        handle_reject_button(client, userdata, msg)
    elif topic == "voicebm/pending_active/play_btn":
        handle_play_button(client, userdata, msg)
    elif topic == "voicebm/active/threshold/set":
        handle_active_threshold_set(client, userdata, msg)
    elif topic.endswith("/threshold_override/set"):
        handle_person_threshold_set(client, userdata, msg)


def main():
    global inject_identity_enabled
    
    print("=" * 60)
    print("Voice Biometrics MQTT Service (ACTIVE PIPELINE)")
    print("=" * 60)
    print(f"MQTT Broker: {BROKER}:{PORT}")
    print(f"Request Topic: {REQUEST_TOPIC}")
    print(f"Response Topic: {RESPONSE_TOPIC}")
    print(f"Pending Buffer Size: {PENDING_BUFFER_SIZE}")
    print("=" * 60)
    
    setup_pending_dirs()
    
    # Write initial settings for dashboard
    print("\nInitializing dashboard state files...")
    write_settings_file()
    
    print("\nLoading enrollment gallery...")
    gallery = load_gallery()
    
    if not gallery:
        print("Warning: No enrolled speakers found!")
    
    client = mqtt.Client(callback_api_version=mqtt.CallbackAPIVersion.VERSION2)
    client.username_pw_set(USER, PASS)
    client.user_data_set({"gallery": gallery})
    client.on_connect = on_connect
    client.on_message = on_message
    
    try:
        client.connect(BROKER, PORT, 60)
    except Exception as e:
        print(f"MQTT connection failed: {e}")
        return
    
    print("\nVoice biometrics service ready")
    print("Press Ctrl+C to exit\n")
    
    try:
        client.loop_forever()
    except KeyboardInterrupt:
        print("\n\nShutting down...")
        client.disconnect()
        print("Service stopped")


if __name__ == "__main__":
    main()


